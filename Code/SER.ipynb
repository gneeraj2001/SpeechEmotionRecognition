{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWNtLOS-IjWA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "N73VE8jUJQVs",
        "outputId": "66489072-3223-4900-a06e-e91b8996ea18"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-01074d7678fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#importing the mfcc,,mel_spec dataset dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmfcc_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mfcc_melspec.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mfcc_melspec.csv'"
          ]
        }
      ],
      "source": [
        "#importing the mfcc,,mel_spec dataset dataset\n",
        "\n",
        "mfcc_dataset = pd.read_csv('mfcc_melspec.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kprR1pGLJ0wl"
      },
      "outputs": [],
      "source": [
        "mfcc_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoNiQBMYUu5f"
      },
      "outputs": [],
      "source": [
        "emotions = mfcc_dataset['labels'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW7JP9uaKb8r"
      },
      "outputs": [],
      "source": [
        "X = mfcc_dataset.iloc[:,1:-1].values\n",
        "y = mfcc_dataset.iloc[:,-1].values\n",
        "\n",
        "def encode_labels(dataset):\n",
        "    labels = dataset['labels']\n",
        "    labels = [index for val in labels for index,value in enumerate(emotions) if val == value]\n",
        "    return labels\n",
        "\n",
        "#labels = encode_labels(mfcc_dataset)\n",
        "#mfcc_dataset['labels'] = labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjoJhdZ1VNwV"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n",
        "mfcc_dataset['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSf32_GGLdeb"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Function to split the data into train and test set and perform scaling of all features\n",
        "\n",
        "def split_scale(X,y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=25)\n",
        "\n",
        "\n",
        "   # X_train = StandardScaler().fit_transform(X_train)\n",
        "   # X_test = StandardScaler().fit_transform(X_test)\n",
        "    \n",
        "    return X_train,X_test,y_train,y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b_bibWrLmyo"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = split_scale(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dr9e6zs9NdCa"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mk8SBsylNv-U"
      },
      "outputs": [],
      "source": [
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYHOv1byPXku"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 5,padding='same',input_shape=(141,1)))        \n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Conv1D(128, 5,padding='same',))                           \n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(8))                                                 \n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = optimizers.RMSprop(lr=0.00005,rho=0.9, epsilon=None, decay=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqGod6k_Qs5x"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAnVaS2FQ1z8"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIds8CivQ2lp"
      },
      "outputs": [],
      "source": [
        "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=5, min_lr=0.0000001)\n",
        "#cnn=model.fit(X_train, y_train, batch_size=20, epochs=350, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XROyCrLidpWD"
      },
      "outputs": [],
      "source": [
        "'''fig, ax = plt.subplots(figsize=(12, 6))\n",
        "plt.plot(cnn.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(cnn.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.legend()\n",
        "plt.show()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Hxm3h2Id78I"
      },
      "outputs": [],
      "source": [
        "'''fig, ax = plt.subplots(figsize=(12, 6))\n",
        "plt.plot(cnn.history[\"accuracy\"], label=\"accuracy\")\n",
        "plt.plot(cnn.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rDkja4IOAvx"
      },
      "source": [
        "MFCC+MEL Sprectrogram+Chroma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFtVa1riOD8z"
      },
      "outputs": [],
      "source": [
        "mfcc_mel_chroma_dataset = pd.read_csv('dataset1.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PltRUL1sbHdG"
      },
      "outputs": [],
      "source": [
        "mfcc_mel_chroma_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJjPDuZWbPIz"
      },
      "outputs": [],
      "source": [
        "X = mfcc_mel_chroma_dataset.iloc[:,1:-1].values\n",
        "y = mfcc_mel_chroma_dataset.iloc[:,-1].values\n",
        "X.shape,y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF8gqJdEbh41"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n",
        "mfcc_dataset['labels']\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3CIPC41bjCK"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = split_scale(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOpoBb8_bsVu"
      },
      "outputs": [],
      "source": [
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYM-Rrpwbutu"
      },
      "outputs": [],
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Conv1D(128, 3,padding='same',input_shape=(187,1)))        \n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling1D(pool_size=(2)))\n",
        "model2.add(Dropout(0.1))\n",
        "\n",
        "model2.add(Conv1D(256, 3,padding='same',))                           \n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling1D(pool_size=(2)))\n",
        "model2.add(Dropout(0.1))\n",
        "\n",
        "model2.add(Conv1D(512, 3,padding='same',))                           \n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling1D(pool_size=(2)))\n",
        "model2.add(Dropout(0.1))\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(8))                                                 \n",
        "model2.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "opt = optimizers.RMSprop(lr=0.0005, rho=0.9, epsilon=None, decay=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stx-WdKob6Ri"
      },
      "outputs": [],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbuVVg-wb70_"
      },
      "outputs": [],
      "source": [
        "model2.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68x32xQrcjWE"
      },
      "outputs": [],
      "source": [
        "cnn2=model2.fit(X_train, y_train, batch_size=20, epochs=35, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XODddzJtdEil"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "plt.plot(cnn2.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(cnn2.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo9DKteqdIaB"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "plt.plot(cnn2.history[\"accuracy\"], label=\"accuracy\")\n",
        "plt.plot(cnn2.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYu2mrjMl02O"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report \n",
        "from sklearn.metrics import confusion_matrix \n",
        "predictions = model.predict(X_test)\n",
        "print(pred)\n",
        "print(classification_report(y_test,predictions))\n",
        "print(confusion_matrix(y_test,predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqmV0HSVoaBl"
      },
      "outputs": [],
      "source": [
        "loss, acc = model2.evaluate(X_test, y_test)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEdymO5lkB6Y"
      },
      "source": [
        "6-7 SPectral Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r42NKJrRkFFx"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('dataset3.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "vESjLe0-kMYX",
        "outputId": "85834660-782e-4074-9684-bbd000df9483"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-304fa4ce4ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9TaVXPikT0n",
        "outputId": "14b36d62-5053-4316-ec85-fba5105ebed2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1440, 198), (1440,))"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X2 = data.iloc[:,1:-1].values\n",
        "y2 = data.iloc[:,-1].values\n",
        "\n",
        "X2.shape,y2.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4_iRljBkS0k",
        "outputId": "e3aea677-c6fb-4772-bb2f-cf18ce78205b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7 5 2 ... 6 2 0]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y2 = encoder.fit_transform(y2)\n",
        "data['labels']\n",
        "print(y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7B9dSf2vkiPb"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = split_scale(X2,y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIr2I5yukrPV",
        "outputId": "652cf805-6cac-4f23-d819-faff0cec4c2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1008, 198, 1)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLkQTL63kr_o",
        "outputId": "0e904cf3-2a5f-45fb-cd26-34f88426a324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_33 (Conv1D)          (None, 198, 128)          512       \n",
            "                                                                 \n",
            " activation_45 (Activation)  (None, 198, 128)          0         \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 198, 128)          0         \n",
            "                                                                 \n",
            " max_pooling1d_29 (MaxPoolin  (None, 99, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_34 (Conv1D)          (None, 99, 128)           49280     \n",
            "                                                                 \n",
            " activation_46 (Activation)  (None, 99, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_30 (MaxPoolin  (None, 49, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 49, 128)           0         \n",
            "                                                                 \n",
            " conv1d_35 (Conv1D)          (None, 49, 128)           49280     \n",
            "                                                                 \n",
            " activation_47 (Activation)  (None, 49, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_31 (MaxPoolin  (None, 24, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 24, 128)           0         \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 8)                 24584     \n",
            "                                                                 \n",
            " activation_48 (Activation)  (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 123,656\n",
            "Trainable params: 123,656\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model3 = Sequential()\n",
        "\n",
        "model3.add(Conv1D(128, 3,padding='same',input_shape=(198,1)))        \n",
        "model3.add(Activation('relu'))\n",
        "model3.add(Dropout(0.1))\n",
        "model3.add(MaxPooling1D(pool_size=(2)))\n",
        "\n",
        "model3.add(Conv1D(128, 3,padding='same'))        \n",
        "model3.add(Activation('relu'))\n",
        "model3.add(MaxPooling1D(pool_size=(2)))\n",
        "model3.add(Dropout(0.1))\n",
        "\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(8))                                                 \n",
        "model3.add(Activation('softmax'))\n",
        "\n",
        "opt = optimizers.RMSprop(lr=0.00005, rho=0.9, epsilon=None, decay=0.0)\n",
        "model3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7xmLSatlFpE"
      },
      "outputs": [],
      "source": [
        "model3.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ijxi-lSulM7l",
        "outputId": "2bbde322-c4d8-461a-cf11-8005b6373b2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "68/68 [==============================] - 4s 45ms/step - loss: 3.4050 - accuracy: 0.1240 - val_loss: 2.2500 - val_accuracy: 0.2037\n",
            "Epoch 2/300\n",
            "68/68 [==============================] - 3s 40ms/step - loss: 2.7255 - accuracy: 0.1815 - val_loss: 2.1429 - val_accuracy: 0.2083\n",
            "Epoch 3/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 2.5466 - accuracy: 0.1964 - val_loss: 2.2380 - val_accuracy: 0.2199\n",
            "Epoch 4/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 2.3924 - accuracy: 0.1944 - val_loss: 2.0222 - val_accuracy: 0.2778\n",
            "Epoch 5/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 2.2657 - accuracy: 0.2133 - val_loss: 1.9084 - val_accuracy: 0.2269\n",
            "Epoch 6/300\n",
            "68/68 [==============================] - 3s 40ms/step - loss: 2.1703 - accuracy: 0.2331 - val_loss: 1.8885 - val_accuracy: 0.2523\n",
            "Epoch 7/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 2.0703 - accuracy: 0.2609 - val_loss: 1.8781 - val_accuracy: 0.2315\n",
            "Epoch 8/300\n",
            "68/68 [==============================] - 4s 54ms/step - loss: 1.9949 - accuracy: 0.2520 - val_loss: 1.9085 - val_accuracy: 0.2222\n",
            "Epoch 9/300\n",
            "68/68 [==============================] - 3s 46ms/step - loss: 2.0218 - accuracy: 0.2391 - val_loss: 1.8129 - val_accuracy: 0.3194\n",
            "Epoch 10/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.9512 - accuracy: 0.2817 - val_loss: 1.7872 - val_accuracy: 0.3380\n",
            "Epoch 11/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.8837 - accuracy: 0.3026 - val_loss: 1.7976 - val_accuracy: 0.2778\n",
            "Epoch 12/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.8504 - accuracy: 0.2867 - val_loss: 1.7808 - val_accuracy: 0.2986\n",
            "Epoch 13/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.8434 - accuracy: 0.3085 - val_loss: 1.7637 - val_accuracy: 0.3264\n",
            "Epoch 14/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.8052 - accuracy: 0.3105 - val_loss: 1.7597 - val_accuracy: 0.3426\n",
            "Epoch 15/300\n",
            "68/68 [==============================] - 3s 40ms/step - loss: 1.8049 - accuracy: 0.3145 - val_loss: 1.7506 - val_accuracy: 0.2940\n",
            "Epoch 16/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.7576 - accuracy: 0.3343 - val_loss: 1.7104 - val_accuracy: 0.3472\n",
            "Epoch 17/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.7674 - accuracy: 0.3234 - val_loss: 1.7372 - val_accuracy: 0.2963\n",
            "Epoch 18/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.7054 - accuracy: 0.3522 - val_loss: 1.7125 - val_accuracy: 0.3542\n",
            "Epoch 19/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.7183 - accuracy: 0.3442 - val_loss: 1.6743 - val_accuracy: 0.4028\n",
            "Epoch 20/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.7062 - accuracy: 0.3591 - val_loss: 1.6969 - val_accuracy: 0.3819\n",
            "Epoch 21/300\n",
            "68/68 [==============================] - 3s 40ms/step - loss: 1.6745 - accuracy: 0.3740 - val_loss: 1.6988 - val_accuracy: 0.3310\n",
            "Epoch 22/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.6802 - accuracy: 0.3581 - val_loss: 1.6537 - val_accuracy: 0.3981\n",
            "Epoch 23/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.6469 - accuracy: 0.3839 - val_loss: 1.6517 - val_accuracy: 0.4028\n",
            "Epoch 24/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.6353 - accuracy: 0.3889 - val_loss: 1.6208 - val_accuracy: 0.4028\n",
            "Epoch 25/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.6212 - accuracy: 0.3849 - val_loss: 1.6340 - val_accuracy: 0.4028\n",
            "Epoch 26/300\n",
            "68/68 [==============================] - 3s 39ms/step - loss: 1.6015 - accuracy: 0.3909 - val_loss: 1.6068 - val_accuracy: 0.4236\n",
            "Epoch 27/300\n",
            "68/68 [==============================] - 3s 40ms/step - loss: 1.5883 - accuracy: 0.4087 - val_loss: 1.5928 - val_accuracy: 0.4167\n",
            "Epoch 28/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.5680 - accuracy: 0.4097 - val_loss: 1.6072 - val_accuracy: 0.4005\n",
            "Epoch 29/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.5687 - accuracy: 0.4008 - val_loss: 1.5758 - val_accuracy: 0.4421\n",
            "Epoch 30/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.5511 - accuracy: 0.4087 - val_loss: 1.5954 - val_accuracy: 0.4167\n",
            "Epoch 31/300\n",
            "68/68 [==============================] - 4s 58ms/step - loss: 1.5396 - accuracy: 0.4345 - val_loss: 1.5743 - val_accuracy: 0.4329\n",
            "Epoch 32/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.5400 - accuracy: 0.4196 - val_loss: 1.5737 - val_accuracy: 0.4375\n",
            "Epoch 33/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.5216 - accuracy: 0.4355 - val_loss: 1.5771 - val_accuracy: 0.4259\n",
            "Epoch 34/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.5158 - accuracy: 0.4365 - val_loss: 1.5407 - val_accuracy: 0.4259\n",
            "Epoch 35/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.5203 - accuracy: 0.4246 - val_loss: 1.5295 - val_accuracy: 0.4167\n",
            "Epoch 36/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.4985 - accuracy: 0.4385 - val_loss: 1.5331 - val_accuracy: 0.4398\n",
            "Epoch 37/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.4925 - accuracy: 0.4325 - val_loss: 1.5626 - val_accuracy: 0.4560\n",
            "Epoch 38/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.5061 - accuracy: 0.4276 - val_loss: 1.5330 - val_accuracy: 0.4491\n",
            "Epoch 39/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.4757 - accuracy: 0.4474 - val_loss: 1.5113 - val_accuracy: 0.4468\n",
            "Epoch 40/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.4820 - accuracy: 0.4444 - val_loss: 1.5030 - val_accuracy: 0.4514\n",
            "Epoch 41/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.4711 - accuracy: 0.4375 - val_loss: 1.5061 - val_accuracy: 0.4560\n",
            "Epoch 42/300\n",
            "68/68 [==============================] - 3s 40ms/step - loss: 1.4786 - accuracy: 0.4444 - val_loss: 1.5142 - val_accuracy: 0.4444\n",
            "Epoch 43/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.4463 - accuracy: 0.4524 - val_loss: 1.5063 - val_accuracy: 0.4421\n",
            "Epoch 44/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.4603 - accuracy: 0.4454 - val_loss: 1.5012 - val_accuracy: 0.4583\n",
            "Epoch 45/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.4378 - accuracy: 0.4831 - val_loss: 1.5082 - val_accuracy: 0.4769\n",
            "Epoch 46/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.4231 - accuracy: 0.4712 - val_loss: 1.4751 - val_accuracy: 0.4676\n",
            "Epoch 47/300\n",
            "68/68 [==============================] - 3s 40ms/step - loss: 1.4244 - accuracy: 0.4663 - val_loss: 1.4896 - val_accuracy: 0.4514\n",
            "Epoch 48/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.4255 - accuracy: 0.4623 - val_loss: 1.4841 - val_accuracy: 0.4630\n",
            "Epoch 49/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.4042 - accuracy: 0.4871 - val_loss: 1.4585 - val_accuracy: 0.4630\n",
            "Epoch 50/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.4092 - accuracy: 0.4802 - val_loss: 1.4680 - val_accuracy: 0.4792\n",
            "Epoch 51/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.3986 - accuracy: 0.4821 - val_loss: 1.4691 - val_accuracy: 0.4630\n",
            "Epoch 52/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.3996 - accuracy: 0.4524 - val_loss: 1.4552 - val_accuracy: 0.4583\n",
            "Epoch 53/300\n",
            "68/68 [==============================] - 4s 60ms/step - loss: 1.3941 - accuracy: 0.4871 - val_loss: 1.4617 - val_accuracy: 0.4792\n",
            "Epoch 54/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.3777 - accuracy: 0.5060 - val_loss: 1.4583 - val_accuracy: 0.4560\n",
            "Epoch 55/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.3875 - accuracy: 0.4821 - val_loss: 1.4478 - val_accuracy: 0.4954\n",
            "Epoch 56/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.3657 - accuracy: 0.5010 - val_loss: 1.4355 - val_accuracy: 0.4861\n",
            "Epoch 57/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.3715 - accuracy: 0.4792 - val_loss: 1.4319 - val_accuracy: 0.4977\n",
            "Epoch 58/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.3558 - accuracy: 0.4931 - val_loss: 1.4307 - val_accuracy: 0.5000\n",
            "Epoch 59/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.3623 - accuracy: 0.5040 - val_loss: 1.4206 - val_accuracy: 0.5046\n",
            "Epoch 60/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.3501 - accuracy: 0.4901 - val_loss: 1.4205 - val_accuracy: 0.5000\n",
            "Epoch 61/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.3415 - accuracy: 0.5159 - val_loss: 1.4269 - val_accuracy: 0.5116\n",
            "Epoch 62/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.3532 - accuracy: 0.4911 - val_loss: 1.4140 - val_accuracy: 0.5093\n",
            "Epoch 63/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.3122 - accuracy: 0.5129 - val_loss: 1.4307 - val_accuracy: 0.4907\n",
            "Epoch 64/300\n",
            "68/68 [==============================] - 3s 39ms/step - loss: 1.3131 - accuracy: 0.5079 - val_loss: 1.4244 - val_accuracy: 0.4884\n",
            "Epoch 65/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.3296 - accuracy: 0.4980 - val_loss: 1.4011 - val_accuracy: 0.5000\n",
            "Epoch 66/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.3184 - accuracy: 0.4970 - val_loss: 1.4276 - val_accuracy: 0.4977\n",
            "Epoch 67/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.3229 - accuracy: 0.5179 - val_loss: 1.4167 - val_accuracy: 0.4792\n",
            "Epoch 68/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.3194 - accuracy: 0.4871 - val_loss: 1.4207 - val_accuracy: 0.4907\n",
            "Epoch 69/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.2975 - accuracy: 0.5139 - val_loss: 1.4102 - val_accuracy: 0.4977\n",
            "Epoch 70/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.2843 - accuracy: 0.5099 - val_loss: 1.3823 - val_accuracy: 0.5069\n",
            "Epoch 71/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.2691 - accuracy: 0.5417 - val_loss: 1.3986 - val_accuracy: 0.5069\n",
            "Epoch 72/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.2907 - accuracy: 0.5109 - val_loss: 1.3922 - val_accuracy: 0.5208\n",
            "Epoch 73/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.2655 - accuracy: 0.5258 - val_loss: 1.3821 - val_accuracy: 0.5139\n",
            "Epoch 74/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.2769 - accuracy: 0.5188 - val_loss: 1.3889 - val_accuracy: 0.5162\n",
            "Epoch 75/300\n",
            "68/68 [==============================] - 4s 61ms/step - loss: 1.2686 - accuracy: 0.5298 - val_loss: 1.3745 - val_accuracy: 0.5185\n",
            "Epoch 76/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.2523 - accuracy: 0.5089 - val_loss: 1.3884 - val_accuracy: 0.4954\n",
            "Epoch 77/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.2560 - accuracy: 0.5288 - val_loss: 1.3663 - val_accuracy: 0.4884\n",
            "Epoch 78/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.2610 - accuracy: 0.5159 - val_loss: 1.3694 - val_accuracy: 0.5278\n",
            "Epoch 79/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.2519 - accuracy: 0.5198 - val_loss: 1.3673 - val_accuracy: 0.5185\n",
            "Epoch 80/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.2364 - accuracy: 0.5417 - val_loss: 1.3699 - val_accuracy: 0.5162\n",
            "Epoch 81/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.2507 - accuracy: 0.5496 - val_loss: 1.3458 - val_accuracy: 0.5324\n",
            "Epoch 82/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.2362 - accuracy: 0.5506 - val_loss: 1.3623 - val_accuracy: 0.5208\n",
            "Epoch 83/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.2100 - accuracy: 0.5565 - val_loss: 1.3456 - val_accuracy: 0.5231\n",
            "Epoch 84/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.2254 - accuracy: 0.5337 - val_loss: 1.3476 - val_accuracy: 0.5347\n",
            "Epoch 85/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.2177 - accuracy: 0.5546 - val_loss: 1.3436 - val_accuracy: 0.5347\n",
            "Epoch 86/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.2069 - accuracy: 0.5575 - val_loss: 1.3314 - val_accuracy: 0.5278\n",
            "Epoch 87/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.1811 - accuracy: 0.5605 - val_loss: 1.3562 - val_accuracy: 0.5093\n",
            "Epoch 88/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.1808 - accuracy: 0.5595 - val_loss: 1.3250 - val_accuracy: 0.5532\n",
            "Epoch 89/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 1.2093 - accuracy: 0.5496 - val_loss: 1.3409 - val_accuracy: 0.5394\n",
            "Epoch 90/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.2023 - accuracy: 0.5486 - val_loss: 1.3277 - val_accuracy: 0.5440\n",
            "Epoch 91/300\n",
            "68/68 [==============================] - 3s 40ms/step - loss: 1.1743 - accuracy: 0.5724 - val_loss: 1.3421 - val_accuracy: 0.5394\n",
            "Epoch 92/300\n",
            "68/68 [==============================] - 3s 40ms/step - loss: 1.1983 - accuracy: 0.5546 - val_loss: 1.3231 - val_accuracy: 0.5417\n",
            "Epoch 93/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.1862 - accuracy: 0.5565 - val_loss: 1.3349 - val_accuracy: 0.5417\n",
            "Epoch 94/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.1802 - accuracy: 0.5605 - val_loss: 1.3303 - val_accuracy: 0.5255\n",
            "Epoch 95/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.1678 - accuracy: 0.5813 - val_loss: 1.3347 - val_accuracy: 0.5463\n",
            "Epoch 96/300\n",
            "68/68 [==============================] - 4s 59ms/step - loss: 1.1669 - accuracy: 0.5506 - val_loss: 1.3211 - val_accuracy: 0.5509\n",
            "Epoch 97/300\n",
            "68/68 [==============================] - 3s 47ms/step - loss: 1.1318 - accuracy: 0.5923 - val_loss: 1.3275 - val_accuracy: 0.5255\n",
            "Epoch 98/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.1295 - accuracy: 0.5833 - val_loss: 1.3156 - val_accuracy: 0.5509\n",
            "Epoch 99/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.1494 - accuracy: 0.5685 - val_loss: 1.3108 - val_accuracy: 0.5301\n",
            "Epoch 100/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.1571 - accuracy: 0.5764 - val_loss: 1.3191 - val_accuracy: 0.5532\n",
            "Epoch 101/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.1601 - accuracy: 0.5516 - val_loss: 1.3137 - val_accuracy: 0.5463\n",
            "Epoch 102/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.1272 - accuracy: 0.5972 - val_loss: 1.3118 - val_accuracy: 0.5394\n",
            "Epoch 103/300\n",
            "68/68 [==============================] - 3s 46ms/step - loss: 1.1327 - accuracy: 0.5655 - val_loss: 1.3162 - val_accuracy: 0.5509\n",
            "Epoch 104/300\n",
            "68/68 [==============================] - 3s 46ms/step - loss: 1.1353 - accuracy: 0.5962 - val_loss: 1.3025 - val_accuracy: 0.5324\n",
            "Epoch 105/300\n",
            "68/68 [==============================] - 3s 46ms/step - loss: 1.1119 - accuracy: 0.5903 - val_loss: 1.3024 - val_accuracy: 0.5440\n",
            "Epoch 106/300\n",
            "68/68 [==============================] - 3s 46ms/step - loss: 1.1152 - accuracy: 0.5982 - val_loss: 1.2824 - val_accuracy: 0.5625\n",
            "Epoch 107/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 1.1392 - accuracy: 0.5804 - val_loss: 1.2998 - val_accuracy: 0.5671\n",
            "Epoch 108/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 1.0865 - accuracy: 0.5913 - val_loss: 1.3450 - val_accuracy: 0.5347\n",
            "Epoch 109/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 1.0994 - accuracy: 0.6012 - val_loss: 1.2921 - val_accuracy: 0.5625\n",
            "Epoch 110/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.0870 - accuracy: 0.5883 - val_loss: 1.2994 - val_accuracy: 0.5509\n",
            "Epoch 111/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.1047 - accuracy: 0.5883 - val_loss: 1.3045 - val_accuracy: 0.5486\n",
            "Epoch 112/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.0776 - accuracy: 0.5942 - val_loss: 1.2850 - val_accuracy: 0.5579\n",
            "Epoch 113/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.0865 - accuracy: 0.6042 - val_loss: 1.2801 - val_accuracy: 0.5671\n",
            "Epoch 114/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.0817 - accuracy: 0.5923 - val_loss: 1.2915 - val_accuracy: 0.5648\n",
            "Epoch 115/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.0858 - accuracy: 0.5942 - val_loss: 1.2886 - val_accuracy: 0.5208\n",
            "Epoch 116/300\n",
            "68/68 [==============================] - 3s 40ms/step - loss: 1.0349 - accuracy: 0.6280 - val_loss: 1.3022 - val_accuracy: 0.5463\n",
            "Epoch 117/300\n",
            "68/68 [==============================] - 4s 59ms/step - loss: 1.0768 - accuracy: 0.6052 - val_loss: 1.2998 - val_accuracy: 0.5185\n",
            "Epoch 118/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 1.0561 - accuracy: 0.6012 - val_loss: 1.2943 - val_accuracy: 0.5648\n",
            "Epoch 119/300\n",
            "68/68 [==============================] - 3s 46ms/step - loss: 1.0620 - accuracy: 0.6141 - val_loss: 1.2736 - val_accuracy: 0.5671\n",
            "Epoch 120/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.0322 - accuracy: 0.6171 - val_loss: 1.2865 - val_accuracy: 0.5509\n",
            "Epoch 121/300\n",
            "68/68 [==============================] - 3s 40ms/step - loss: 1.0260 - accuracy: 0.6329 - val_loss: 1.3080 - val_accuracy: 0.5394\n",
            "Epoch 122/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 1.0218 - accuracy: 0.6319 - val_loss: 1.2933 - val_accuracy: 0.5556\n",
            "Epoch 123/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 1.0181 - accuracy: 0.6339 - val_loss: 1.3087 - val_accuracy: 0.5579\n",
            "Epoch 124/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 1.0215 - accuracy: 0.6091 - val_loss: 1.2811 - val_accuracy: 0.5648\n",
            "Epoch 125/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 1.0347 - accuracy: 0.6240 - val_loss: 1.2685 - val_accuracy: 0.5694\n",
            "Epoch 126/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 1.0038 - accuracy: 0.6190 - val_loss: 1.2660 - val_accuracy: 0.5648\n",
            "Epoch 127/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 1.0078 - accuracy: 0.6339 - val_loss: 1.2584 - val_accuracy: 0.5856\n",
            "Epoch 128/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.0104 - accuracy: 0.6200 - val_loss: 1.2921 - val_accuracy: 0.5532\n",
            "Epoch 129/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.0192 - accuracy: 0.6240 - val_loss: 1.2536 - val_accuracy: 0.5741\n",
            "Epoch 130/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.9814 - accuracy: 0.6359 - val_loss: 1.2582 - val_accuracy: 0.5810\n",
            "Epoch 131/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.9891 - accuracy: 0.6339 - val_loss: 1.2522 - val_accuracy: 0.5694\n",
            "Epoch 132/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 1.0052 - accuracy: 0.6240 - val_loss: 1.2643 - val_accuracy: 0.5880\n",
            "Epoch 133/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.9782 - accuracy: 0.6389 - val_loss: 1.2656 - val_accuracy: 0.5556\n",
            "Epoch 134/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.9569 - accuracy: 0.6528 - val_loss: 1.2429 - val_accuracy: 0.5833\n",
            "Epoch 135/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.9592 - accuracy: 0.6488 - val_loss: 1.2516 - val_accuracy: 0.5694\n",
            "Epoch 136/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.9738 - accuracy: 0.6488 - val_loss: 1.2383 - val_accuracy: 0.5810\n",
            "Epoch 137/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.9499 - accuracy: 0.6567 - val_loss: 1.2674 - val_accuracy: 0.5694\n",
            "Epoch 138/300\n",
            "68/68 [==============================] - 4s 62ms/step - loss: 0.9846 - accuracy: 0.6419 - val_loss: 1.2470 - val_accuracy: 0.5787\n",
            "Epoch 139/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.9597 - accuracy: 0.6587 - val_loss: 1.2441 - val_accuracy: 0.5694\n",
            "Epoch 140/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.9375 - accuracy: 0.6667 - val_loss: 1.2417 - val_accuracy: 0.5787\n",
            "Epoch 141/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.9566 - accuracy: 0.6587 - val_loss: 1.2434 - val_accuracy: 0.5903\n",
            "Epoch 142/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.9357 - accuracy: 0.6637 - val_loss: 1.2471 - val_accuracy: 0.5810\n",
            "Epoch 143/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.9550 - accuracy: 0.6577 - val_loss: 1.2508 - val_accuracy: 0.5741\n",
            "Epoch 144/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.9561 - accuracy: 0.6458 - val_loss: 1.2461 - val_accuracy: 0.5949\n",
            "Epoch 145/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.9425 - accuracy: 0.6597 - val_loss: 1.2537 - val_accuracy: 0.5810\n",
            "Epoch 146/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.9189 - accuracy: 0.6687 - val_loss: 1.2342 - val_accuracy: 0.5810\n",
            "Epoch 147/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.9231 - accuracy: 0.6716 - val_loss: 1.2591 - val_accuracy: 0.5764\n",
            "Epoch 148/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.8811 - accuracy: 0.6796 - val_loss: 1.2436 - val_accuracy: 0.5856\n",
            "Epoch 149/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.8982 - accuracy: 0.6716 - val_loss: 1.2612 - val_accuracy: 0.5856\n",
            "Epoch 150/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.8920 - accuracy: 0.6915 - val_loss: 1.2542 - val_accuracy: 0.5741\n",
            "Epoch 151/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.8947 - accuracy: 0.6835 - val_loss: 1.2476 - val_accuracy: 0.5787\n",
            "Epoch 152/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.8730 - accuracy: 0.6855 - val_loss: 1.2247 - val_accuracy: 0.5926\n",
            "Epoch 153/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.8796 - accuracy: 0.6855 - val_loss: 1.2449 - val_accuracy: 0.5764\n",
            "Epoch 154/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.8898 - accuracy: 0.6806 - val_loss: 1.2394 - val_accuracy: 0.5856\n",
            "Epoch 155/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.8890 - accuracy: 0.6786 - val_loss: 1.2624 - val_accuracy: 0.5764\n",
            "Epoch 156/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.8639 - accuracy: 0.6895 - val_loss: 1.2581 - val_accuracy: 0.5718\n",
            "Epoch 157/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.8551 - accuracy: 0.7004 - val_loss: 1.2347 - val_accuracy: 0.5764\n",
            "Epoch 158/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.8664 - accuracy: 0.6657 - val_loss: 1.2251 - val_accuracy: 0.5787\n",
            "Epoch 159/300\n",
            "68/68 [==============================] - 4s 61ms/step - loss: 0.8415 - accuracy: 0.6925 - val_loss: 1.2238 - val_accuracy: 0.5903\n",
            "Epoch 160/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.8322 - accuracy: 0.7034 - val_loss: 1.2288 - val_accuracy: 0.5972\n",
            "Epoch 161/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 0.8467 - accuracy: 0.6954 - val_loss: 1.2767 - val_accuracy: 0.5509\n",
            "Epoch 162/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.8112 - accuracy: 0.7004 - val_loss: 1.2423 - val_accuracy: 0.5741\n",
            "Epoch 163/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.8589 - accuracy: 0.6835 - val_loss: 1.2586 - val_accuracy: 0.5833\n",
            "Epoch 164/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.8410 - accuracy: 0.6895 - val_loss: 1.2247 - val_accuracy: 0.5810\n",
            "Epoch 165/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.8588 - accuracy: 0.6895 - val_loss: 1.2311 - val_accuracy: 0.5833\n",
            "Epoch 166/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.8290 - accuracy: 0.6944 - val_loss: 1.2021 - val_accuracy: 0.5949\n",
            "Epoch 167/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.8134 - accuracy: 0.7004 - val_loss: 1.2192 - val_accuracy: 0.5926\n",
            "Epoch 168/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.8177 - accuracy: 0.6994 - val_loss: 1.2356 - val_accuracy: 0.5625\n",
            "Epoch 169/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.7618 - accuracy: 0.7440 - val_loss: 1.2347 - val_accuracy: 0.5787\n",
            "Epoch 170/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.8302 - accuracy: 0.6915 - val_loss: 1.2413 - val_accuracy: 0.5694\n",
            "Epoch 171/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.7812 - accuracy: 0.7192 - val_loss: 1.2314 - val_accuracy: 0.5787\n",
            "Epoch 172/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.7844 - accuracy: 0.7153 - val_loss: 1.2097 - val_accuracy: 0.5972\n",
            "Epoch 173/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.7931 - accuracy: 0.7202 - val_loss: 1.2116 - val_accuracy: 0.5880\n",
            "Epoch 174/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.7852 - accuracy: 0.7103 - val_loss: 1.2143 - val_accuracy: 0.5880\n",
            "Epoch 175/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.7707 - accuracy: 0.7163 - val_loss: 1.2344 - val_accuracy: 0.5833\n",
            "Epoch 176/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.7794 - accuracy: 0.7282 - val_loss: 1.2367 - val_accuracy: 0.5787\n",
            "Epoch 177/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.7950 - accuracy: 0.7044 - val_loss: 1.2187 - val_accuracy: 0.5787\n",
            "Epoch 178/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.7581 - accuracy: 0.7242 - val_loss: 1.2544 - val_accuracy: 0.5741\n",
            "Epoch 179/300\n",
            "68/68 [==============================] - 3s 50ms/step - loss: 0.7772 - accuracy: 0.7212 - val_loss: 1.2426 - val_accuracy: 0.5903\n",
            "Epoch 180/300\n",
            "68/68 [==============================] - 4s 52ms/step - loss: 0.7794 - accuracy: 0.7282 - val_loss: 1.2034 - val_accuracy: 0.5926\n",
            "Epoch 181/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.7626 - accuracy: 0.7381 - val_loss: 1.2053 - val_accuracy: 0.5926\n",
            "Epoch 182/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.7398 - accuracy: 0.7351 - val_loss: 1.2080 - val_accuracy: 0.5995\n",
            "Epoch 183/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.7720 - accuracy: 0.7381 - val_loss: 1.2054 - val_accuracy: 0.5926\n",
            "Epoch 184/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.7605 - accuracy: 0.7351 - val_loss: 1.2026 - val_accuracy: 0.6019\n",
            "Epoch 185/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.7131 - accuracy: 0.7530 - val_loss: 1.2216 - val_accuracy: 0.5833\n",
            "Epoch 186/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.7380 - accuracy: 0.7341 - val_loss: 1.2146 - val_accuracy: 0.6019\n",
            "Epoch 187/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.7476 - accuracy: 0.7381 - val_loss: 1.2315 - val_accuracy: 0.5764\n",
            "Epoch 188/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.7168 - accuracy: 0.7550 - val_loss: 1.2501 - val_accuracy: 0.5810\n",
            "Epoch 189/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.7233 - accuracy: 0.7500 - val_loss: 1.2103 - val_accuracy: 0.5833\n",
            "Epoch 190/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.7153 - accuracy: 0.7351 - val_loss: 1.2088 - val_accuracy: 0.6042\n",
            "Epoch 191/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.6989 - accuracy: 0.7520 - val_loss: 1.2183 - val_accuracy: 0.5995\n",
            "Epoch 192/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.7113 - accuracy: 0.7470 - val_loss: 1.2370 - val_accuracy: 0.5741\n",
            "Epoch 193/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.7132 - accuracy: 0.7421 - val_loss: 1.1977 - val_accuracy: 0.6042\n",
            "Epoch 194/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.6855 - accuracy: 0.7698 - val_loss: 1.2328 - val_accuracy: 0.5995\n",
            "Epoch 195/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.7378 - accuracy: 0.7331 - val_loss: 1.2148 - val_accuracy: 0.6019\n",
            "Epoch 196/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.7006 - accuracy: 0.7629 - val_loss: 1.2246 - val_accuracy: 0.5903\n",
            "Epoch 197/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.6869 - accuracy: 0.7609 - val_loss: 1.2252 - val_accuracy: 0.5856\n",
            "Epoch 198/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.6713 - accuracy: 0.7649 - val_loss: 1.2070 - val_accuracy: 0.6134\n",
            "Epoch 199/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.6848 - accuracy: 0.7609 - val_loss: 1.2135 - val_accuracy: 0.6042\n",
            "Epoch 200/300\n",
            "68/68 [==============================] - 4s 61ms/step - loss: 0.6876 - accuracy: 0.7569 - val_loss: 1.2239 - val_accuracy: 0.5903\n",
            "Epoch 201/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.6836 - accuracy: 0.7599 - val_loss: 1.2184 - val_accuracy: 0.5926\n",
            "Epoch 202/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.6589 - accuracy: 0.7698 - val_loss: 1.2354 - val_accuracy: 0.5949\n",
            "Epoch 203/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.6682 - accuracy: 0.7728 - val_loss: 1.2125 - val_accuracy: 0.6134\n",
            "Epoch 204/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.6684 - accuracy: 0.7659 - val_loss: 1.2196 - val_accuracy: 0.6042\n",
            "Epoch 205/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.6543 - accuracy: 0.7758 - val_loss: 1.2110 - val_accuracy: 0.5949\n",
            "Epoch 206/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.6464 - accuracy: 0.7768 - val_loss: 1.2452 - val_accuracy: 0.5856\n",
            "Epoch 207/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.6726 - accuracy: 0.7639 - val_loss: 1.2234 - val_accuracy: 0.5787\n",
            "Epoch 208/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.6639 - accuracy: 0.7679 - val_loss: 1.2179 - val_accuracy: 0.5972\n",
            "Epoch 209/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 0.6384 - accuracy: 0.7778 - val_loss: 1.2052 - val_accuracy: 0.6134\n",
            "Epoch 210/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.6248 - accuracy: 0.7867 - val_loss: 1.2210 - val_accuracy: 0.6019\n",
            "Epoch 211/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.6483 - accuracy: 0.7669 - val_loss: 1.2321 - val_accuracy: 0.6088\n",
            "Epoch 212/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.6283 - accuracy: 0.7857 - val_loss: 1.1966 - val_accuracy: 0.6157\n",
            "Epoch 213/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.6119 - accuracy: 0.7956 - val_loss: 1.2341 - val_accuracy: 0.5995\n",
            "Epoch 214/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 0.6064 - accuracy: 0.7937 - val_loss: 1.2146 - val_accuracy: 0.6088\n",
            "Epoch 215/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 0.6226 - accuracy: 0.7857 - val_loss: 1.2259 - val_accuracy: 0.6019\n",
            "Epoch 216/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 0.6041 - accuracy: 0.8026 - val_loss: 1.2378 - val_accuracy: 0.5995\n",
            "Epoch 217/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.5931 - accuracy: 0.7956 - val_loss: 1.2215 - val_accuracy: 0.5995\n",
            "Epoch 218/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 0.6206 - accuracy: 0.7837 - val_loss: 1.2136 - val_accuracy: 0.6065\n",
            "Epoch 219/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 0.6287 - accuracy: 0.7867 - val_loss: 1.2405 - val_accuracy: 0.6019\n",
            "Epoch 220/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.5645 - accuracy: 0.8105 - val_loss: 1.2400 - val_accuracy: 0.6042\n",
            "Epoch 221/300\n",
            "68/68 [==============================] - 4s 60ms/step - loss: 0.5845 - accuracy: 0.7887 - val_loss: 1.2106 - val_accuracy: 0.6042\n",
            "Epoch 222/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.6048 - accuracy: 0.7808 - val_loss: 1.2135 - val_accuracy: 0.5949\n",
            "Epoch 223/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.5719 - accuracy: 0.7946 - val_loss: 1.2208 - val_accuracy: 0.6019\n",
            "Epoch 224/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.5819 - accuracy: 0.7986 - val_loss: 1.2178 - val_accuracy: 0.6157\n",
            "Epoch 225/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 0.5934 - accuracy: 0.8036 - val_loss: 1.2157 - val_accuracy: 0.5995\n",
            "Epoch 226/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 0.5877 - accuracy: 0.8036 - val_loss: 1.2444 - val_accuracy: 0.6088\n",
            "Epoch 227/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.5711 - accuracy: 0.8095 - val_loss: 1.2264 - val_accuracy: 0.6065\n",
            "Epoch 228/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.6151 - accuracy: 0.7758 - val_loss: 1.2113 - val_accuracy: 0.6134\n",
            "Epoch 229/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.5712 - accuracy: 0.8036 - val_loss: 1.2240 - val_accuracy: 0.6181\n",
            "Epoch 230/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.5829 - accuracy: 0.7907 - val_loss: 1.2144 - val_accuracy: 0.6042\n",
            "Epoch 231/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.5678 - accuracy: 0.7976 - val_loss: 1.2430 - val_accuracy: 0.5949\n",
            "Epoch 232/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.5349 - accuracy: 0.8125 - val_loss: 1.2358 - val_accuracy: 0.6111\n",
            "Epoch 233/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 0.5671 - accuracy: 0.7927 - val_loss: 1.2354 - val_accuracy: 0.6088\n",
            "Epoch 234/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.5747 - accuracy: 0.8016 - val_loss: 1.2277 - val_accuracy: 0.6065\n",
            "Epoch 235/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.5255 - accuracy: 0.8214 - val_loss: 1.2387 - val_accuracy: 0.5995\n",
            "Epoch 236/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.5714 - accuracy: 0.8065 - val_loss: 1.2320 - val_accuracy: 0.6227\n",
            "Epoch 237/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.5540 - accuracy: 0.8165 - val_loss: 1.2341 - val_accuracy: 0.6042\n",
            "Epoch 238/300\n",
            "68/68 [==============================] - 3s 42ms/step - loss: 0.5530 - accuracy: 0.8165 - val_loss: 1.2262 - val_accuracy: 0.6250\n",
            "Epoch 239/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.5319 - accuracy: 0.8264 - val_loss: 1.2269 - val_accuracy: 0.6181\n",
            "Epoch 240/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.5287 - accuracy: 0.8125 - val_loss: 1.2261 - val_accuracy: 0.6227\n",
            "Epoch 241/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.5266 - accuracy: 0.8264 - val_loss: 1.2267 - val_accuracy: 0.6250\n",
            "Epoch 242/300\n",
            "68/68 [==============================] - 4s 61ms/step - loss: 0.5277 - accuracy: 0.8313 - val_loss: 1.2118 - val_accuracy: 0.6250\n",
            "Epoch 243/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.5266 - accuracy: 0.8185 - val_loss: 1.2086 - val_accuracy: 0.6157\n",
            "Epoch 244/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.5097 - accuracy: 0.8254 - val_loss: 1.2484 - val_accuracy: 0.6019\n",
            "Epoch 245/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 0.5120 - accuracy: 0.8175 - val_loss: 1.2225 - val_accuracy: 0.6296\n",
            "Epoch 246/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.4966 - accuracy: 0.8363 - val_loss: 1.2414 - val_accuracy: 0.6134\n",
            "Epoch 247/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.5097 - accuracy: 0.8264 - val_loss: 1.2255 - val_accuracy: 0.6134\n",
            "Epoch 248/300\n",
            "68/68 [==============================] - 3s 41ms/step - loss: 0.4875 - accuracy: 0.8363 - val_loss: 1.2336 - val_accuracy: 0.6111\n",
            "Epoch 249/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.4817 - accuracy: 0.8442 - val_loss: 1.2273 - val_accuracy: 0.6181\n",
            "Epoch 250/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.4861 - accuracy: 0.8383 - val_loss: 1.2396 - val_accuracy: 0.6296\n",
            "Epoch 251/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.4684 - accuracy: 0.8442 - val_loss: 1.2580 - val_accuracy: 0.6134\n",
            "Epoch 252/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.4817 - accuracy: 0.8313 - val_loss: 1.2639 - val_accuracy: 0.6134\n",
            "Epoch 253/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.4946 - accuracy: 0.8333 - val_loss: 1.2370 - val_accuracy: 0.6296\n",
            "Epoch 254/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.4926 - accuracy: 0.8502 - val_loss: 1.2437 - val_accuracy: 0.6204\n",
            "Epoch 255/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.5012 - accuracy: 0.8254 - val_loss: 1.2521 - val_accuracy: 0.6157\n",
            "Epoch 256/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.4722 - accuracy: 0.8393 - val_loss: 1.2629 - val_accuracy: 0.6065\n",
            "Epoch 257/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.4714 - accuracy: 0.8413 - val_loss: 1.2805 - val_accuracy: 0.6065\n",
            "Epoch 258/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.4624 - accuracy: 0.8522 - val_loss: 1.2456 - val_accuracy: 0.6157\n",
            "Epoch 259/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.4633 - accuracy: 0.8442 - val_loss: 1.2634 - val_accuracy: 0.6042\n",
            "Epoch 260/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.4800 - accuracy: 0.8383 - val_loss: 1.2710 - val_accuracy: 0.5995\n",
            "Epoch 261/300\n",
            "68/68 [==============================] - 3s 46ms/step - loss: 0.4469 - accuracy: 0.8581 - val_loss: 1.2580 - val_accuracy: 0.6157\n",
            "Epoch 262/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.4607 - accuracy: 0.8472 - val_loss: 1.2618 - val_accuracy: 0.6111\n",
            "Epoch 263/300\n",
            "68/68 [==============================] - 4s 61ms/step - loss: 0.4442 - accuracy: 0.8542 - val_loss: 1.2463 - val_accuracy: 0.6204\n",
            "Epoch 264/300\n",
            "68/68 [==============================] - 3s 46ms/step - loss: 0.4482 - accuracy: 0.8323 - val_loss: 1.2813 - val_accuracy: 0.6042\n",
            "Epoch 265/300\n",
            "68/68 [==============================] - 3s 45ms/step - loss: 0.4478 - accuracy: 0.8442 - val_loss: 1.2701 - val_accuracy: 0.6111\n",
            "Epoch 266/300\n",
            "68/68 [==============================] - 3s 47ms/step - loss: 0.4542 - accuracy: 0.8492 - val_loss: 1.2804 - val_accuracy: 0.6134\n",
            "Epoch 267/300\n",
            "68/68 [==============================] - 3s 47ms/step - loss: 0.4467 - accuracy: 0.8512 - val_loss: 1.2835 - val_accuracy: 0.6065\n",
            "Epoch 268/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.4171 - accuracy: 0.8681 - val_loss: 1.2916 - val_accuracy: 0.6065\n",
            "Epoch 269/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.4458 - accuracy: 0.8601 - val_loss: 1.2743 - val_accuracy: 0.6088\n",
            "Epoch 270/300\n",
            "68/68 [==============================] - 3s 46ms/step - loss: 0.4262 - accuracy: 0.8571 - val_loss: 1.3087 - val_accuracy: 0.6134\n",
            "Epoch 271/300\n",
            "68/68 [==============================] - 3s 43ms/step - loss: 0.4353 - accuracy: 0.8552 - val_loss: 1.2726 - val_accuracy: 0.6250\n",
            "Epoch 272/300\n",
            "68/68 [==============================] - 3s 47ms/step - loss: 0.4122 - accuracy: 0.8641 - val_loss: 1.2723 - val_accuracy: 0.6111\n",
            "Epoch 273/300\n",
            "68/68 [==============================] - 3s 47ms/step - loss: 0.4271 - accuracy: 0.8492 - val_loss: 1.3009 - val_accuracy: 0.6042\n",
            "Epoch 274/300\n",
            "68/68 [==============================] - 3s 46ms/step - loss: 0.4080 - accuracy: 0.8651 - val_loss: 1.2736 - val_accuracy: 0.6227\n",
            "Epoch 275/300\n",
            "68/68 [==============================] - 3s 47ms/step - loss: 0.4096 - accuracy: 0.8651 - val_loss: 1.2992 - val_accuracy: 0.6042\n",
            "Epoch 276/300\n",
            "68/68 [==============================] - 3s 47ms/step - loss: 0.4199 - accuracy: 0.8770 - val_loss: 1.2756 - val_accuracy: 0.6204\n",
            "Epoch 277/300\n",
            "68/68 [==============================] - 3s 47ms/step - loss: 0.4201 - accuracy: 0.8581 - val_loss: 1.2811 - val_accuracy: 0.6296\n",
            "Epoch 278/300\n",
            "68/68 [==============================] - 3s 47ms/step - loss: 0.4031 - accuracy: 0.8611 - val_loss: 1.2879 - val_accuracy: 0.6296\n",
            "Epoch 279/300\n",
            "68/68 [==============================] - 3s 48ms/step - loss: 0.4285 - accuracy: 0.8542 - val_loss: 1.2818 - val_accuracy: 0.6296\n",
            "Epoch 280/300\n",
            "68/68 [==============================] - 3s 46ms/step - loss: 0.4088 - accuracy: 0.8671 - val_loss: 1.2869 - val_accuracy: 0.6319\n",
            "Epoch 281/300\n",
            "68/68 [==============================] - 3s 48ms/step - loss: 0.4191 - accuracy: 0.8522 - val_loss: 1.2870 - val_accuracy: 0.6111\n",
            "Epoch 282/300\n",
            "68/68 [==============================] - 4s 53ms/step - loss: 0.3969 - accuracy: 0.8710 - val_loss: 1.2917 - val_accuracy: 0.6250\n",
            "Epoch 283/300\n",
            "68/68 [==============================] - 4s 55ms/step - loss: 0.3791 - accuracy: 0.8819 - val_loss: 1.3142 - val_accuracy: 0.6157\n",
            "Epoch 284/300\n",
            "68/68 [==============================] - 3s 46ms/step - loss: 0.4061 - accuracy: 0.8641 - val_loss: 1.2818 - val_accuracy: 0.6204\n",
            "Epoch 285/300\n",
            "68/68 [==============================] - 3s 47ms/step - loss: 0.4102 - accuracy: 0.8571 - val_loss: 1.2837 - val_accuracy: 0.6319\n",
            "Epoch 286/300\n",
            "68/68 [==============================] - 3s 48ms/step - loss: 0.3856 - accuracy: 0.8730 - val_loss: 1.2973 - val_accuracy: 0.6227\n",
            "Epoch 287/300\n",
            "68/68 [==============================] - 3s 46ms/step - loss: 0.3693 - accuracy: 0.8810 - val_loss: 1.2983 - val_accuracy: 0.6319\n",
            "Epoch 288/300\n",
            "68/68 [==============================] - 3s 48ms/step - loss: 0.3750 - accuracy: 0.8829 - val_loss: 1.2873 - val_accuracy: 0.6227\n",
            "Epoch 289/300\n",
            "68/68 [==============================] - 3s 48ms/step - loss: 0.3910 - accuracy: 0.8621 - val_loss: 1.3457 - val_accuracy: 0.6019\n",
            "Epoch 290/300\n",
            "68/68 [==============================] - 3s 48ms/step - loss: 0.3877 - accuracy: 0.8800 - val_loss: 1.3123 - val_accuracy: 0.6250\n",
            "Epoch 291/300\n",
            "68/68 [==============================] - 3s 47ms/step - loss: 0.3654 - accuracy: 0.8859 - val_loss: 1.2928 - val_accuracy: 0.6296\n",
            "Epoch 292/300\n",
            "68/68 [==============================] - 3s 48ms/step - loss: 0.3722 - accuracy: 0.8720 - val_loss: 1.2989 - val_accuracy: 0.6273\n",
            "Epoch 293/300\n",
            "68/68 [==============================] - 3s 48ms/step - loss: 0.3812 - accuracy: 0.8810 - val_loss: 1.3178 - val_accuracy: 0.6088\n",
            "Epoch 294/300\n",
            "68/68 [==============================] - 3s 46ms/step - loss: 0.3789 - accuracy: 0.8780 - val_loss: 1.2712 - val_accuracy: 0.6273\n",
            "Epoch 295/300\n",
            "68/68 [==============================] - 3s 47ms/step - loss: 0.3790 - accuracy: 0.8661 - val_loss: 1.2845 - val_accuracy: 0.6296\n",
            "Epoch 296/300\n",
            "68/68 [==============================] - 3s 48ms/step - loss: 0.3613 - accuracy: 0.8790 - val_loss: 1.2986 - val_accuracy: 0.6204\n",
            "Epoch 297/300\n",
            "68/68 [==============================] - 3s 46ms/step - loss: 0.3602 - accuracy: 0.8790 - val_loss: 1.3483 - val_accuracy: 0.6157\n",
            "Epoch 298/300\n",
            "68/68 [==============================] - 3s 48ms/step - loss: 0.3504 - accuracy: 0.8859 - val_loss: 1.3210 - val_accuracy: 0.6204\n",
            "Epoch 299/300\n",
            "68/68 [==============================] - 3s 44ms/step - loss: 0.3700 - accuracy: 0.8800 - val_loss: 1.3129 - val_accuracy: 0.6366\n",
            "Epoch 300/300\n",
            "68/68 [==============================] - 3s 47ms/step - loss: 0.3664 - accuracy: 0.8770 - val_loss: 1.3077 - val_accuracy: 0.6319\n"
          ]
        }
      ],
      "source": [
        "cnn3=model3.fit(X_train, y_train, batch_size=15, epochs=300, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDXBSHkmrnky",
        "outputId": "91293317-d81f-4935-b265-7029a2bb3531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 16ms/step - loss: 1.3077 - accuracy: 0.6319\n",
            "Accuracy: 63.19%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model3.evaluate(X_test, y_test)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "3LcVhIfIsctC",
        "outputId": "2a7bfb79-90d1-4f0f-ded3-dff3b9d4eb93"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "plt.plot(cnn3.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(cnn3.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "eHI8k0QTsez4",
        "outputId": "c2f2a127-4cac-4c15-da74-734e23b1f028"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "plt.plot(cnn3.history[\"accuracy\"], label=\"loss\")\n",
        "plt.plot(cnn3.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bkB8_D7A3Kn"
      },
      "source": [
        "PDA plus model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "hxwq4DhWA5b5",
        "outputId": "5c392031-8d8e-407b-d99b-04312c09a60f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5QdZZnv8e+vu0OC3MIlYiYBEyDgIIMaI6Kow8WBAA5hUCHIkog5Ro+ogONBOM4MijLLy3hDBzgcyBCQISLiIigKGUQ4owTS4X6VGMAkBogJCQgkpNPP+aPe3b13V+9O9U7vS9O/z2KvXfVW7aqnq5v9pOq9KSIwMzOrRVuzAzAzs+HLScTMzGrmJGJmZjVzEjEzs5o5iZiZWc06mh1Ao+22224xadKkZodhZjasLFmy5M8RMa5v+YhLIpMmTaKzs7PZYZiZDSuSnu6v3I+zzMysZk4iZmZWMycRMzOrmZOImZnVzEnEzMxq5iRiZmY1cxIxM7Oa1S2JSJor6TlJD5WVfUvSY5IekPQzSWPLtp0raamkxyUdVVY+PZUtlXROWflkSXel8h9L2qZeP8v6lzdx4iV3MvuKxfU6hZnZsFTPO5ErgOl9yhYCB0TEgcDvgXMBJO0PzATenD5zkaR2Se3AvwNHA/sDJ6d9Ab4BfDci9gGeB2bX6wfp6u7m7qfWcu/ydfU6hZnZsFS3JBIRdwBr+5TdEhFdaXURMDEtzwDmR8TGiHgSWAoclF5LI2JZRLwKzAdmSBJwOHBd+vw84Ph6/SxtEgDdnsDLzKxCM+tEPg78Mi1PAJaXbVuRyqqV7wqsK0tIpfJ+SZojqVNS5+rVqwcdaE8S6XYSMTMr15QkIulLQBdwdSPOFxGXRsS0iJg2blxu/LAtUlvpOEMcmJnZMNfwARglfQz4AHBE9E7wvhLYo2y3iamMKuVrgLGSOtLdSPn+Q650J7LZWcTMrEJD70QkTQfOBo6LiJfLNi0AZkoaLWkyMAW4G1gMTEktsbYhq3xfkJLPbcCH0udnATfUK+62LIe4TsTMrI96NvG9BrgT2E/SCkmzgR8COwALJd0n6RKAiHgYuBZ4BPgVcHpEbE53GZ8BbgYeBa5N+wJ8Efi8pKVkdSSX1+tn6a1Yr9cZzMyGp7o9zoqIk/sprvpFHxEXABf0U34TcFM/5cvIWm/VXSmJhO9EzMwquMd6Ab2Ps5obh5lZq3ESKcD9RMzM+uckUkDKIUT4kZaZWTknkQIkVSQSMzPLOIkU5EdaZmZ5TiIFuXLdzCzPSaQg+U7EzCzHSaSgNteJmJnlOIkU5DoRM7M8J5GC2j0Io5lZjpNIQT1NfLubG4eZWStxEimorc2Ps8zM+nISKch1ImZmeU4iBbmfiJlZnpNIQfJw8GZmOU4iBflOxMwsz0mkINeJmJnlOYkU5CRiZpbnJFKQh4I3M8tzEinIdyJmZnlOIgW5Yt3MLM9JpKBSj/XNziJmZj2cRApqcz8RM7McJ5GC/DjLzCyvbklE0lxJz0l6qKxsF0kLJT2R3ndO5ZJ0oaSlkh6QNLXsM7PS/k9ImlVW/nZJD6bPXKhSl/I6ccW6mVlePe9ErgCm9yk7B7g1IqYAt6Z1gKOBKek1B7gYsqQDnAe8EzgIOK+UeNI+nyj7XN9zDSlPj2tmlle3JBIRdwBr+xTPAOal5XnA8WXlV0ZmETBW0njgKGBhRKyNiOeBhcD0tG3HiFgUWSXFlWXHqgtPj2tmltfoOpHdI2JVWn4G2D0tTwCWl+23IpUNVL6in/J+SZojqVNS5+rVq2sK3I+zzMzymlaxnu4gGvKNHBGXRsS0iJg2bty4mo7hinUzs7xGJ5Fn06Mo0vtzqXwlsEfZfhNT2UDlE/sprxvXiZiZ5TU6iSwASi2sZgE3lJWfmlppHQysT4+9bgaOlLRzqlA/Erg5bXtB0sGpVdapZceqi946EScRM7OSjnodWNI1wKHAbpJWkLWy+jpwraTZwNPAiWn3m4BjgKXAy8BpABGxVtJXgcVpv/MjolRZ/2myFmDbAr9Mr7rprROp51nMzIaXuiWRiDi5yqYj+tk3gNOrHGcuMLef8k7ggK2JcTB6koiziJlZD/dYL6gtXanNfpxlZtbDSaSg3rGzmhyImVkLcRIpyP1EzMzynEQKkvuJmJnlOIkU5DsRM7M8J5GC3E/EzCzPSaSg3ia+TQ7EzKyFOIkU5GFPzMzynEQK8gCMZmZ5W0wikraT1JaW95V0nKRR9Q+ttXiOdTOzvCJ3IncAYyRNAG4BPko2ZtWIUuqx7jsRM7NeRZKIIuJl4ATgooj4MPDm+obVetzE18wsr1ASkfQu4BTgF6msvX4htSYnETOzvCJJ5EzgXOBnEfGwpL2A2+obVuvprVh3EjEzK9niUPARcTtwu6TXpfVlwOfqHVircT8RM7O8Iq2z3iXpEeCxtP4WSRfVPbIW434iZmZ5RR5nfQ84ClgDEBH3A++rZ1CtqHfYk+bGYWbWSgp1NoyI5X2KNtchlpbminUzs7wi0+Mul/RuIFInwzOAR+sbVutxPxEzs7widyKfIpv/fAKwEngrVeZDfy1znYiZWV6R1ll/JusjMqJ5KHgzs7wirbPmSRpbtr6zpLn1Dav19NaJNDkQM7MWUuRx1oERsa60EhHPA2+rX0ityRXrZmZ5RZJIm6SdSyuSdqFYhXxVks6S9LCkhyRdI2mMpMmS7pK0VNKPJW2T9h2d1pem7ZPKjnNuKn9c0lFbE9OW+E7EzCyvSBL5NnCnpK9K+hrwO+CbtZ4wjQb8OWBaRBxANg7XTOAbwHcjYh/geWB2+shs4PlU/t20H5L2T597MzAduEhS3cb06hn2xFnEzKzHFpNIRFwJfBB4FngGOCEirtrK83YA20rqAF4HrAIOB65L2+cBx6flGWmdtP0IZU2lZgDzI2JjRDwJLAUO2sq4qmpr8+MsM7O+ij6Weozs7qADQNKeEfHHWk4YESsl/RvwR+AVsjlKlgDrIqIr7baCrEkx6X15+myXpPXArql8Udmhyz8z5OSZDc3McraYRCR9FjiP7E5kMyAggANrOWGqX5kBTAbWAT8hexxVN5LmAHMA9txzz5qO4Yp1M7O8InciZwD7RcSaITrn+4EnI2I1gKTrgUOAsZI60t3IRLKOjaT3PYAV6fHXTmTjeJXKS8o/UyEiLgUuBZg2bVpNWcD9RMzM8opUrC8H1g/hOf8IHCzpdalu4wjgEbI5Sj6U9pkF3JCWF6R10vZfR/ZNvgCYmVpvTQamAHcPYZwV3DrLzCyvyJ3IMuA3kn4BbCwVRsR3ajlhRNwl6TrgHqALuJfsLuEXwPzUAuxe4PL0kcuBqyQtBdaStcgiTZB1LVkC6gJOj4i6DQzpYU/MzPKKJJE/ptc26bXVIuI8snqWcsvop3VVRGwAPlzlOBcAFwxFTFvS5op1M7OcImNnfaURgbS60uMs14mYmfUq0jprHHA2Wae+MaXyiDi8jnG1HM+xbmaWV6Ri/WqyfiKTga8ATwGL6xhTS5Ir1s3McookkV0j4nJgU0TcHhEfJ+tdPqK0u8e6mVlOkYr1Tel9laRjgT8Bu9QvpNbksbPMzPKKJJGvSdoJ+EfgB8COwFl1jaoFuZ+ImVlekdZZP0+L64HD6htO63I/ETOzvKpJRNLZEfFNST8gGyurQkR8rq6RtZjeYU+aG4eZWSsZ6E7k0fTe2YhAWp0HYDQzy6uaRCLixjTJ099ExBcaGFNLcj8RM7O8AZv4prGoDmlQLC3N/UTMzPKKtM66T9ICsnk/XioVRsT1dYuqBXnYEzOzvCJJZAzZ/B3lHQwDGGFJJHvv7m5uHGZmraRIE9/TGhFIq3PFuplZXpEBGMcAs8kPwPjxOsbVctraXCdiZtZXkbGzrgLeABwF3E42De2L9QyqFXl6XDOzvCJJZJ+I+GfgpYiYBxwLvLO+YbWe0uOszU4iZmY9iiSR0gCM6yQdAOwEvL5+IbUmeWZDM7OcIq2zLpW0M/DPwAJg+7Q8orhi3cwsb6Cxsx4B/hO4JiKeJ6sP2atRgbUa9xMxM8sb6HHWycB2wC2S7pZ0lqTxDYqr5bifiJlZXtUkEhH3R8S5EbE38DlgT+AuSbdJ+kTDImwRHgrezCyvSMU6EbEoIs4CTgXGAj+sa1QtqM0V62ZmOUU6G76D7NHWB4Engf9DNo7WiOI6ETOzvKp3IpL+VdIfgIuAlcAhEXFoRFwSEWu25qSSxkq6TtJjkh6V9C5Ju0haKOmJ9L5z2leSLpS0VNIDkqaWHWdW2v8JSbO2JqYtaUtXyo+zzMx6DfQ4awMwPSLeERHfjogVQ3je7wO/iog3AW8hmwDrHODWiJgC3JrWAY4GpqTXHOBiAEm7AOeRdXw8CDivlHjqwUPBm5nlDVSxfn5EPDHUJ5S0E/A+4PJ0nlcjYh0wA5iXdpsHHJ+WZwBXRmYRMDa1EjsKWBgRa1MT5IXA9KGOt6TdFetmZjmFKtaH2GRgNfAfku6VdJmk7YDdI2JV2ucZYPe0PAFYXvb5FamsWnmOpDmSOiV1rl69uqage+tEavq4mdlrUjOSSAcwFbg4It5GNtHVOeU7RFZ7PWRf1xFxaURMi4hp48aNq+kYnh7XzCxvoB7rU6ttA4iIe2o85wpgRUTcldavI0siz0oaHxGr0uOq59L2lcAeZZ+fmMpWAof2Kf9NjTFtUalOZLMrRczMegzUxPfb6X0MMA24HxBwINAJvKuWE0bEM5KWS9ovIh4HjgAeSa9ZwNfT+w3pIwuAz0iaT1aJvj4lmpuBfy2rTD8SOLeWmIroHQq+XmcwMxt+qiaRiDgMQNL1wNSIeDCtHwB8eSvP+1ngaknbAMuA08gerV0raTbwNHBi2vcm4BhgKfBy2peIWCvpq8DitN/5EbF2K+OqqndSKmcRM7OSIqP47ldKIAAR8ZCkv96ak0bEfWR3N30d0c++AZxe5ThzgblbE0tRrhMxM8srkkQekHQZ8KO0fgrwQP1Cak3uJ2JmllckiZwG/E/gjLR+B6nD30jiYU/MzPK2mEQiYoOkS4CbUkX4iOQBGM3M8rbYT0TSccB9wK/S+lslLah3YK3GMxuameUV6Wx4HtnYVOugp1J8cj2DakWeY93MLK9IEtkUEev7lI24r9L2NteJmJn1VaRi/WFJHwHaJU0hm+Xwd/UNq/X4cZaZWV6RO5HPAm8GNgLXAC8AZ9YzqFbkinUzs7wirbNeBr6UXiNWTz8RZxEzsx5FpsfdF/gCMKl8/4g4vH5htR4/zjIzyytSJ/IT4BLgMmBzfcNpXX6cZWaWVySJdEXEiOuh3pfvRMzM8opUrN8o6dOSxkvapfSqe2QtRh4K3swsp8idyKz0/r/KygLYa+jDaV2+EzEzyyvSOmvE9U7vj5OImVneQNPjHh4Rv5Z0Qn/bI+L6+oXVelyxbmaWN9CdyN8Cvwb+vp9tAYysJOJhT8zMcgaaHve89H5a48JpXW2elMrMLKdIxTqSjiUb+mRMqSwizq9XUK3I0+OameUVmU/kEuAksjG0BHwYeGOd42o5HvbEzCyvSD+Rd0fEqcDzEfEV4F3AvvUNq/W4Yt3MLK9IEnklvb8s6a+ATcD4+oXUmtzE18wsr0idyM8ljQW+BdxD1jLrsrpG1YKcRMzM8op0NvxqWvyppJ8DY/qZ6fA1z9PjmpnlDdTZsN9OhmnbVnc2lNQOdAIrI+IDkiYD84FdgSXARyPiVUmjgSuBtwNrgJMi4ql0jHOB2WSjC38uIm7empgGUroTcT8RM7NeA92J9NfJsGQoOhueATwK7JjWvwF8NyLmpxZhs4GL0/vzEbGPpJlpv5Mk7Q/MJGt6/FfAf0naNyLqMly9K9bNzPIG6mxYt06GkiYCxwIXAJ9X1n72cOAjaZd5wJfJksiMtAxwHfDDtP8MYH5EbASelLQUOAi4sx4xu07EzCyvSD+RXSVdKOkeSUskfV/Srlt53u8BZwPdaX1XYF1EdKX1FcCEtDwBWA6Qtq9P+/eU9/OZvj/DHEmdkjpXr15dU8DlQ8H7kZaZWaZIE9/5wGrgg8CH0vKPaz2hpA8Az0XEklqPMVgRcWlETIuIaePGjavpGJJ6Hmk5h5iZZYo08R1f1kIL4GuSTtqKcx4CHCfpGLJhVHYEvg+MldSR7jYmAivT/iuBPYAVkjqAncgq2EvlJeWfqYs2ie4IuiNoQ/U8lZnZsFDkTuQWSTMltaXXiUDNraAi4tyImBgRk8gqxn8dEacAt5Hd6UA2EdYNaXkBvRNjfSjtH6l8pqTRqWXXFODuWuMqwoMwmplVKnIn8gngTOCqtN4OvCTpk0BExI5VPzk4XwTmS/oacC9weSq/HLgqVZyvJUs8RMTDkq4FHgG6gNPr1TKrRB6E0cysQpHOhjvU6+QR8RvgN2l5GVnrqr77bCAb9LG/z19A1sKrIdxCy8ysUpHWWbP7rLdLOq9+IbUu9xUxM6tUpE7kCEk3SRov6QBgEVC3u5NW5jsRM7NKRR5nfSS1xnoQeAn4SET8tu6RtaCeviLdA+9nZjZSFHmcNYVsiJKfAk8DH5X0unoH1opK86z7TsTMLFPkcdaNwD9HxCeBvwWeABbXNaoW5cdZZmaVijTxPSgiXoCsPS/wbUk31jes1uSKdTOzSlXvRCSdDRARL0jq28T2Y/UMqlXJw8GbmVUY6HHWzLLlc/tsm16HWFpeu3usm5lVGCiJqMpyf+sjQpt7rJuZVRgoiUSV5f7WRwS5Yt3MrMJAFetvkfQC2V3HtmmZtD6m7pG1oLaUcp1DzMwyA81s2N7IQIaDUhPfza4UMTMDivUTscT9RMzMKjmJDILcT8TMrIKTyCC0uZ+ImVkFJ5FBcI91M7NKTiKD4DoRM7NKTiKD4H4iZmaVnEQGod39RMzMKjiJDIIfZ5mZVXISGQR5AEYzswpOIoPgARjNzCo5iQyC+4mYmVVqeBKRtIek2yQ9IulhSWek8l0kLZT0RHrfOZVL0oWSlkp6QNLUsmPNSvs/IWlWvWMv3Yls7q73mczMhodm3Il0Af8YEfsDBwOnS9ofOAe4NSKmALemdYCjgSnpNQe4GLKkA5wHvBM4CDivlHjqxU18zcwqNTyJRMSqiLgnLb8IPApMAGYA89Ju84Dj0/IM4MrILALGShoPHAUsjIi1EfE8sJA6z7joOhEzs0pNrRORNAl4G3AXsHtErEqbngF2T8sTgOVlH1uRyqqV93eeOZI6JXWuXr265nh760RqPoSZ2WtK05KIpO2BnwJnRsQL5dsiq7kesq/qiLg0IqZFxLRx48bVfBz3EzEzq9SUJCJpFFkCuToirk/Fz6bHVKT351L5SmCPso9PTGXVyusYd/bufiJmZplmtM4ScDnwaER8p2zTAqDUwmoWcENZ+ampldbBwPr02Otm4EhJO6cK9SNTWd34TsTMrNJAc6zXyyHAR4EHJd2Xyv438HXgWkmzgaeBE9O2m4BjgKXAy8BpABGxVtJXgcVpv/MjYm09A29vcz8RM7NyDU8iEfHfgKpsPqKf/QM4vcqx5gJzhy66gfW0znI/ETMzwD3WB8X9RMzMKjmJDIJnNjQzq+QkMggeO8vMrJKTyCCUkshmJxEzM8BJZFDcT8TMrJKTyCD4cZaZWSUnkUHwAIxmZpWcRAahp8e6+4mYmQFOIoPifiJmZpWcRAah9DjLOcTMLOMkMgilsbN8J2JmlnESGYTex1lNDsTMrEU4iQyCW2eZmVVyEhkE9xMxM6vkJDIIHoDRzKySk8gguImvmVklJ5FB6BmA0bciZmaAk8iguJ+ImVklJ5FBaGvzUPBmZuWcRAZh/E5jAFjy9PNNjsTMrDU4iQzCsQeOp71N3PbYc6z5y8Zmh2Nm1nROIoPw+h3G8L4pu9HVHdx4/5+aHY6ZWdM5iQzSCVMnAjB/8XJeeXVzk6MxM2suJ5FB+rv9d2e37Ufz2DMv8sGLf8dND67yoy0zG7E03IfwkDQd+D7QDlwWEV8faP9p06ZFZ2fnVp3z8Wde5JNXdfLUmpdTDPCON+7CARN24vU7jmZ0Rxu7bj+aCWPHMH6nbdl1+20Y3dG+Vec0M2smSUsiYlqufDgnEUntwO+BvwNWAIuBkyPikWqfGYokArD+lU38aNHT3PmHNdz95Fpe3TzwdIdjRrWx07aj2G50B6M72hkzqo3RHW2MGdXO6I42Rne0M6q9jVHtSu9tjOoQ25SW07ZtOrLljrbK5TYJKUtoAEKk/5CU3nu3KW3L9lHZtrR/z2dLP0F5Wf/HI5VVW+/9jMq2FThe2l5+vKGgoTnMEEUztAd7TV8jq9kOY0axTUdtD6CqJZGOrY6quQ4ClkbEMgBJ84EZQNUkMlR22nYUpx+2D6cftg8vbtjEb5eu4ek1L/Hnv2xkY1c3q1/cyJ/WvcKf1m/g+ZdeZcOmbjZs2gj40ZeZNccVp72DQ/d7/ZAec7gnkQnA8rL1FcA7++4kaQ4wB2DPPfcc8iB2GDOK6Qe8oer2iODlVzez7pVNvPJqFxs2dbOxazMbN3WzIb1v7Opm0+ZuNm2O9N7Nq5u76Urrr27uZlNX5bZNm4OutN4dvaMLB1mv+qCsLN1wBpFti7LlnkAry/o7HhE96/njVY5w3PcckT7be67esv6OR5/PlI43FIbqBnwo7+OH7qHAa/ca2dYZ1T701eDDPYkUEhGXApdC9jir0eeXxHajO9hu9Ii43GY2ggz31lkrgT3K1iemMjMza4DhnkQWA1MkTZa0DTATWNDkmMzMRoxh/XwlIrokfQa4mayJ79yIeLjJYZmZjRjDOokARMRNwE3NjsPMbCQa7o+zzMysiZxEzMysZk4iZmZWMycRMzOr2bAeO6sWklYDT9f48d2APw9hOEOpVWNr1bigdWNr1bjAsdWiVeOCwcX2xogY17dwxCWRrSGps78ByFpBq8bWqnFB68bWqnGBY6tFq8YFQxObH2eZmVnNnETMzKxmTiKDc2mzAxhAq8bWqnFB68bWqnGBY6tFq8YFQxCb60TMzKxmvhMxM7OaOYmYmVnNnEQKkDRd0uOSlko6p8mx7CHpNkmPSHpY0hmp/MuSVkq6L72OaVJ8T0l6MMXQmcp2kbRQ0hPpfecGx7Rf2XW5T9ILks5s1jWTNFfSc5IeKivr9xopc2H623tA0tQmxPYtSY+l8/9M0thUPknSK2XX75IGx1X19yfp3HTNHpd0VL3iGiC2H5fF9ZSk+1J5I69Zte+Kof1biwi/BniRDTH/B2AvYBvgfmD/JsYzHpialncAfg/sD3wZ+EILXK+ngN36lH0TOCctnwN8o8m/z2eANzbrmgHvA6YCD23pGgHHAL8EBBwM3NWE2I4EOtLyN8pim1S+XxPi6vf3l/5/uB8YDUxO//+2NzK2Ptu/DfxLE65Zte+KIf1b853Ilh0ELI2IZRHxKjAfmNGsYCJiVUTck5ZfBB4lm2u+lc0A5qXlecDxTYzlCOAPEVHrqAVbLSLuANb2Ka52jWYAV0ZmETBW0vhGxhYRt0REV1pdRDaDaENVuWbVzADmR8TGiHgSWEr2/3HDY5Mk4ETgmnqdv5oBviuG9G/NSWTLJgDLy9ZX0CJf2pImAW8D7kpFn0m3oXMb/cioTAC3SFoiaU4q2z0iVqXlZ4DdmxMakM1+Wf4/dCtcM6h+jVrt7+/jZP9aLZks6V5Jt0t6bxPi6e/310rX7L3AsxHxRFlZw69Zn++KIf1bcxIZpiRtD/wUODMiXgAuBvYG3gqsIruFbob3RMRU4GjgdEnvK98Y2X1zU9qVK5tC+TjgJ6moVa5ZhWZeo4FI+hLQBVydilYBe0bE24DPA/8paccGhtSSv78+TqbyHy0Nv2b9fFf0GIq/NSeRLVsJ7FG2PjGVNY2kUWR/FFdHxPUAEfFsRGyOiG7g/1LH2/eBRMTK9P4c8LMUx7Ol2+L0/lwzYiNLbPdExLMpxpa4Zkm1a9QSf3+SPgZ8ADglffGQHhetSctLyOoe9m1UTAP8/lrlmnUAJwA/LpU1+pr1913BEP+tOYls2WJgiqTJ6V+yM4EFzQomPWO9HHg0Ir5TVl7+7PIfgIf6frYBsW0naYfSMlmF7ENk12tW2m0WcEOjY0sq/lXYCtesTLVrtAA4NbWcORhYX/YooiEkTQfOBo6LiJfLysdJak/LewFTgGUNjKva728BMFPSaEmTU1x3NyquMu8HHouIFaWCRl6zat8VDPXfWiNaCQz3F1mrhd+T/avhS02O5T1kt58PAPel1zHAVcCDqXwBML4Jse1F1irmfuDh0rUCdgVuBZ4A/gvYpQmxbQesAXYqK2vKNSNLZKuATWTPnWdXu0ZkLWX+Pf3tPQhMa0JsS8melZf+3i5J+34w/Z7vA+4B/r7BcVX9/QFfStfsceDoRl+zVH4F8Kk++zbymlX7rhjSvzUPe2JmZjXz4ywzM6uZk4iZmdXMScTMzGrmJGJmZjVzEjEzs5o5iZj1IekNkuZL+kMavuUmSQ3rRDfUJB0q6d3NjsNem5xEzMqkDlo/A34TEXtHxNuBc2nueF9b61DAScTqwknErNJhwKaI6JnnISLuB/5b2bwaDymbL+Uk6PlX/u2SbpC0TNLXJZ0i6e60395pvyskXSKpU9LvJX0glY+R9B9p33slHZbKPybpekm/SvM+fLMUj6QjJd0p6R5JP0ljI5XmcvlKKn9Q0pvSwHufAs5SNn/FeyV9OP0c90u6ozGX1V6rOpodgFmLOQBY0k/5CWQD/b0F2A1YXPYF/Bbgr8mGA18GXBYRBymbBOizwJlpv0lk4zvtDdwmaR/gdLJx8P5G0pvIRkAuPTp7K9nIqxuBxyX9AHgF+Cfg/RHxkqQvkg3kd376zJ8jYqqkT5PNtfE/lE189JeI+DcASQ8CR0XESqUJpsxq5TsRs2LeA1wT2YB/zwK3A+9I2xZHNnfDRrIhI25J5Q+SJY6SayOiO7JhwZcBb0rH/RFARDwGPE3vgHy3RsT6iNgAPEI2kdbBZBML/VbZbHmzUnlJaZC9JX3OXe63wBWSPkE2SZdZzXwnYlbpYeBDg/zMxrLl7rL1bir/H+s7xtCWxhwqP+7mdCwBC6U4jm4AAAEUSURBVCPi5C18prR/TkR8StI7gWOBJZLeHmlkWbPB8p2IWaVfA6PVO6EWkg4E1gEnSWqXNI5sStTBjgz7YUltqZ5kL7LBAf8fcEo6z77Anqm8mkXAIelRWGnk5C21HHuRbHrU0s+zd0TcFRH/Aqymcvhvs0HxnYhZmYgISf8AfC/VN2wgmzf+TGB7shGKAzg7Ip5J9RhF/ZEs8exINrrrBkkXAReneoou4GMRsTFrJNZvfKvT3B7XSBqdiv+JbJTpam4ErpM0g6yO5ixJU8juam5NP5NZTTyKr1kDSLoC+HlEXNfsWMyGkh9nmZlZzXwnYmZmNfOdiJmZ1cxJxMzMauYkYmZmNXMSMTOzmjmJmJlZzf4/6rQ/6x2UXfIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#To find the optimal number of components for pca\n",
        "from sklearn.decomposition import PCA\n",
        "X3 = data.iloc[:,1:-1].values\n",
        "y3 = data.iloc[:,-1].values\n",
        "\n",
        "\n",
        "pca = PCA().fit(X3)\n",
        "plt.plot(pca.explained_variance_, linewidth=2)\n",
        "plt.xlabel('Components')\n",
        "plt.ylabel('Explained Variances')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s2ZQTEOH72a",
        "outputId": "1c4e5066-d2ca-4f37-fe32-8cf429e8a550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8.54116515e-01 3.39298362e-02 1.58442062e-02 1.05523634e-02\n",
            " 8.95183037e-03 6.80148048e-03 5.95965170e-03 5.78208334e-03\n",
            " 4.82638742e-03 4.23975623e-03 3.61046869e-03 3.35380585e-03\n",
            " 3.03754324e-03 2.88988552e-03 2.55269449e-03 2.47512718e-03\n",
            " 2.27648980e-03 2.13583371e-03 1.83852293e-03 1.72670078e-03\n",
            " 1.53203345e-03 1.49968367e-03 1.33184612e-03 1.22360542e-03\n",
            " 1.06325115e-03 9.42160369e-04 9.07429155e-04 8.63369402e-04\n",
            " 8.25203563e-04 7.82547957e-04 7.04602924e-04 6.85535606e-04\n",
            " 6.32397300e-04 6.20727879e-04 5.48578935e-04 5.05277073e-04\n",
            " 4.92569758e-04 4.49972016e-04 4.36531543e-04 4.05251376e-04\n",
            " 3.84316220e-04 3.55954434e-04 3.35058634e-04 3.19972109e-04\n",
            " 3.02160150e-04 2.89754051e-04 2.75757399e-04 2.67373380e-04\n",
            " 2.54905482e-04 2.39738067e-04]\n",
            "[4178.80754243  832.88433061  569.15303172  464.48177717  427.80881816\n",
            "  372.90270881  349.06334791  343.82383779  314.1267352   294.41792927\n",
            "  271.69121868  261.85614471  249.20402046  243.07154959  228.45108815\n",
            "  224.95340445  215.73800822  208.96691381  193.87791298  187.88943172\n",
            "  176.98152521  175.10302202  165.01401617  158.16650071  147.43878425\n",
            "  138.789377    136.20723432  132.8593541   129.88959343  126.48798994\n",
            "  120.0234292   118.38830928  113.70742216  112.65343429  105.90424627\n",
            "  101.63858411  100.35238123   95.91500709   94.47167714   91.02403\n",
            "   88.64171856   85.30824622   82.7664289    80.8816257    78.59816446\n",
            "   76.96771057   75.0857283    73.93547942   72.19105659   70.01035985]\n"
          ]
        }
      ],
      "source": [
        "pca = PCA(n_components=50)\n",
        "X3 = pca.fit_transform(X3)\n",
        "\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a3GweTlIQ9A",
        "outputId": "331f6169-102b-40b5-8ff2-551830911152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7 5 2 ... 6 2 0]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y3 = encoder.fit_transform(y2)\n",
        "data['labels']\n",
        "print(y3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V3SuK80IWnd"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = split_scale(X3,y3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKsYf5vHJ79V"
      },
      "source": [
        "SVM with pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCu5FFFYIZfs",
        "outputId": "581d3b1d-c9e0-42e2-f09e-996b959af7d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5231481481481481\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.60      0.60        57\n",
            "           1       0.68      0.69      0.68        61\n",
            "           2       0.45      0.49      0.46        68\n",
            "           3       0.43      0.53      0.48        47\n",
            "           4       0.54      0.44      0.49        57\n",
            "           5       0.45      0.36      0.40        28\n",
            "           6       0.39      0.42      0.40        55\n",
            "           7       0.63      0.58      0.60        59\n",
            "\n",
            "    accuracy                           0.52       432\n",
            "   macro avg       0.52      0.51      0.51       432\n",
            "weighted avg       0.53      0.52      0.52       432\n",
            "\n",
            "[[34  1 10  4  3  1  1  3]\n",
            " [ 3 42  3  3  0  3  7  0]\n",
            " [ 6  7 33  4  4  1  9  4]\n",
            " [ 3  1  3 25  6  1  4  4]\n",
            " [ 7  0  7  8 25  0  6  4]\n",
            " [ 0  5  4  0  1 10  8  0]\n",
            " [ 4  6  3  7  4  3 23  5]\n",
            " [ 0  0 11  7  3  3  1 34]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC \n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train) \n",
        "svm_predictions = svm_model_linear.predict(X_test) \n",
        "\n",
        "\n",
        "print(accuracy_score(y_true=y_test,y_pred=svm_predictions))\n",
        "print(classification_report(y_test,svm_predictions)) \n",
        "# creating a confusion matrix \n",
        "print(confusion_matrix(y_test, svm_predictions) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzRjykJYJ-YZ"
      },
      "source": [
        "SVM without pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZHo4asZKAG1",
        "outputId": "fd22e435-ee56-4fdc-e56b-c804b1a6fbd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7 5 2 ... 6 2 0]\n",
            "0.5162037037037037\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.58      0.59        57\n",
            "           1       0.64      0.77      0.70        61\n",
            "           2       0.42      0.38      0.40        68\n",
            "           3       0.39      0.51      0.44        47\n",
            "           4       0.49      0.47      0.48        57\n",
            "           5       0.42      0.36      0.38        28\n",
            "           6       0.37      0.31      0.34        55\n",
            "           7       0.70      0.66      0.68        59\n",
            "\n",
            "    accuracy                           0.52       432\n",
            "   macro avg       0.50      0.51      0.50       432\n",
            "weighted avg       0.51      0.52      0.51       432\n",
            "\n",
            "[[33  2 10  1  6  0  0  5]\n",
            " [ 1 47  1  2  1  4  5  0]\n",
            " [ 8  9 26  8  5  3  6  3]\n",
            " [ 4  1  5 24  5  0  4  4]\n",
            " [ 5  0  4  9 27  2  6  4]\n",
            " [ 0  5  3  1  2 10  7  0]\n",
            " [ 3  8  5 11  7  3 17  1]\n",
            " [ 1  1  8  5  2  2  1 39]]\n"
          ]
        }
      ],
      "source": [
        "X3 = data.iloc[:,1:-1].values\n",
        "y3 = data.iloc[:,-1].values\n",
        "encoder = LabelEncoder()\n",
        "y3 = encoder.fit_transform(y2)\n",
        "data['labels']\n",
        "print(y3)\n",
        "X_train, X_test, y_train, y_test = split_scale(X3,y3)\n",
        "\n",
        "\n",
        "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train) \n",
        "svm_predictions = svm_model_linear.predict(X_test) \n",
        "\n",
        "\n",
        "print(accuracy_score(y_true=y_test,y_pred=svm_predictions))\n",
        "print(classification_report(y_test,svm_predictions)) \n",
        "# creating a confusion matrix \n",
        "print(confusion_matrix(y_test, svm_predictions) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y65QDKsf-H00"
      },
      "source": [
        "Added features-sound data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgEoCaB9-VSd"
      },
      "outputs": [],
      "source": [
        "dataset4 = pd.read_csv('dataset4.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KDYjOrg-J9H",
        "outputId": "6a0eff60-ada5-4491-b3ea-37bd705a81f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2452, 198), (2452,))"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X4 = dataset4.iloc[:,1:-1].values\n",
        "y4 = dataset4.iloc[:,-1].values\n",
        "\n",
        "X4.shape,y4.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnWAfcw1-jg9",
        "outputId": "88af9a4d-68cf-4a34-e175-50af88b1709d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4 4 5 ... 1 0 4]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y4 = encoder.fit_transform(y4)\n",
        "\n",
        "print(y4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiNCBqkK-omJ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = split_scale(X4,y4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fyeNsAr9PXL",
        "outputId": "e5f546d5-74ad-43f3-de2b-8bce1b7bf0d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1839, 198, 1)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN9s5_xX-zEq",
        "outputId": "19a4fa98-ff0b-4827-d11c-cd3f591c4a55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_17 (Conv1D)          (None, 198, 128)          512       \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 198, 128)          0         \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 198, 128)          0         \n",
            "                                                                 \n",
            " max_pooling1d_13 (MaxPoolin  (None, 99, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_18 (Conv1D)          (None, 99, 128)           49280     \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 99, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_14 (MaxPoolin  (None, 49, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 49, 128)           0         \n",
            "                                                                 \n",
            " conv1d_19 (Conv1D)          (None, 49, 128)           49280     \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 49, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_15 (MaxPoolin  (None, 24, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 24, 128)           0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 8)                 24584     \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 123,656\n",
            "Trainable params: 123,656\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model4 = Sequential()\n",
        "\n",
        "model4.add(Conv1D(128, 3,padding='same',input_shape=(198,1)))        \n",
        "model4.add(Activation('relu'))\n",
        "model4.add(Dropout(0.1))\n",
        "model4.add(MaxPooling1D(pool_size=(2)))\n",
        "\n",
        "model4.add(Conv1D(128, 3,padding='same'))        \n",
        "model4.add(Activation('relu'))\n",
        "model4.add(MaxPooling1D(pool_size=(2)))\n",
        "model4.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model4.add(Conv1D(128, 3,padding='same'))                          \n",
        "model4.add(Activation('relu'))\n",
        "model4.add(MaxPooling1D(pool_size=(2)))\n",
        "model4.add(Dropout(0.1))\n",
        "\n",
        "model4.add(Flatten())\n",
        "model4.add(Dense(8))                                                 \n",
        "model4.add(Activation('softmax'))\n",
        "\n",
        "opt = optimizers.RMSprop(lr=0.00005, rho=0.9, epsilon=None, decay=0.0)\n",
        "model4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0YAxLlc-_2J"
      },
      "outputs": [],
      "source": [
        "model4.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vChCUcGr_IFM",
        "outputId": "58f6466a-c664-4390-daf3-bfecf8e46c32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "123/123 [==============================] - 6s 40ms/step - loss: 2.7311 - accuracy: 0.1659 - val_loss: 1.8764 - val_accuracy: 0.2284\n",
            "Epoch 2/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 2.3524 - accuracy: 0.2077 - val_loss: 1.8780 - val_accuracy: 0.2235\n",
            "Epoch 3/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 2.1231 - accuracy: 0.2431 - val_loss: 1.7819 - val_accuracy: 0.3002\n",
            "Epoch 4/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 2.0209 - accuracy: 0.2567 - val_loss: 1.7216 - val_accuracy: 0.3442\n",
            "Epoch 5/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.9378 - accuracy: 0.2757 - val_loss: 1.7159 - val_accuracy: 0.3507\n",
            "Epoch 6/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.8625 - accuracy: 0.2811 - val_loss: 1.6654 - val_accuracy: 0.3915\n",
            "Epoch 7/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.7922 - accuracy: 0.3061 - val_loss: 1.6389 - val_accuracy: 0.3883\n",
            "Epoch 8/300\n",
            "123/123 [==============================] - 6s 48ms/step - loss: 1.7378 - accuracy: 0.3382 - val_loss: 1.5980 - val_accuracy: 0.4388\n",
            "Epoch 9/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.6731 - accuracy: 0.3507 - val_loss: 1.5518 - val_accuracy: 0.4682\n",
            "Epoch 10/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.6529 - accuracy: 0.3741 - val_loss: 1.5159 - val_accuracy: 0.4666\n",
            "Epoch 11/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.6096 - accuracy: 0.3828 - val_loss: 1.5007 - val_accuracy: 0.4812\n",
            "Epoch 12/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.5600 - accuracy: 0.4051 - val_loss: 1.4618 - val_accuracy: 0.5122\n",
            "Epoch 13/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.5458 - accuracy: 0.4323 - val_loss: 1.4311 - val_accuracy: 0.5302\n",
            "Epoch 14/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.5012 - accuracy: 0.4399 - val_loss: 1.4173 - val_accuracy: 0.5171\n",
            "Epoch 15/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.4715 - accuracy: 0.4405 - val_loss: 1.3915 - val_accuracy: 0.5155\n",
            "Epoch 16/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.4464 - accuracy: 0.4709 - val_loss: 1.3559 - val_accuracy: 0.5449\n",
            "Epoch 17/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.4337 - accuracy: 0.4769 - val_loss: 1.3560 - val_accuracy: 0.5432\n",
            "Epoch 18/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.3976 - accuracy: 0.4845 - val_loss: 1.3376 - val_accuracy: 0.5400\n",
            "Epoch 19/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.3759 - accuracy: 0.4970 - val_loss: 1.3145 - val_accuracy: 0.5530\n",
            "Epoch 20/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.3496 - accuracy: 0.5052 - val_loss: 1.3038 - val_accuracy: 0.5530\n",
            "Epoch 21/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.3308 - accuracy: 0.5014 - val_loss: 1.3010 - val_accuracy: 0.5465\n",
            "Epoch 22/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.3349 - accuracy: 0.4954 - val_loss: 1.2964 - val_accuracy: 0.5383\n",
            "Epoch 23/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.2978 - accuracy: 0.5362 - val_loss: 1.2469 - val_accuracy: 0.5824\n",
            "Epoch 24/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.2745 - accuracy: 0.5324 - val_loss: 1.2741 - val_accuracy: 0.5367\n",
            "Epoch 25/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.2625 - accuracy: 0.5329 - val_loss: 1.2351 - val_accuracy: 0.5775\n",
            "Epoch 26/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.2584 - accuracy: 0.5389 - val_loss: 1.2589 - val_accuracy: 0.5530\n",
            "Epoch 27/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.2350 - accuracy: 0.5454 - val_loss: 1.2438 - val_accuracy: 0.5432\n",
            "Epoch 28/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.2319 - accuracy: 0.5481 - val_loss: 1.1951 - val_accuracy: 0.5791\n",
            "Epoch 29/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.2192 - accuracy: 0.5546 - val_loss: 1.1842 - val_accuracy: 0.5889\n",
            "Epoch 30/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.1961 - accuracy: 0.5759 - val_loss: 1.1996 - val_accuracy: 0.5693\n",
            "Epoch 31/300\n",
            "123/123 [==============================] - 6s 48ms/step - loss: 1.1892 - accuracy: 0.5546 - val_loss: 1.1913 - val_accuracy: 0.5710\n",
            "Epoch 32/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.1900 - accuracy: 0.5672 - val_loss: 1.1935 - val_accuracy: 0.5579\n",
            "Epoch 33/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.1637 - accuracy: 0.5780 - val_loss: 1.1686 - val_accuracy: 0.5824\n",
            "Epoch 34/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.1412 - accuracy: 0.5759 - val_loss: 1.1688 - val_accuracy: 0.5677\n",
            "Epoch 35/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.1454 - accuracy: 0.5867 - val_loss: 1.1498 - val_accuracy: 0.5922\n",
            "Epoch 36/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.1446 - accuracy: 0.5726 - val_loss: 1.1370 - val_accuracy: 0.5987\n",
            "Epoch 37/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.1188 - accuracy: 0.5856 - val_loss: 1.1513 - val_accuracy: 0.5905\n",
            "Epoch 38/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.1063 - accuracy: 0.5949 - val_loss: 1.1200 - val_accuracy: 0.6117\n",
            "Epoch 39/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.0916 - accuracy: 0.6063 - val_loss: 1.1187 - val_accuracy: 0.5922\n",
            "Epoch 40/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.0956 - accuracy: 0.6020 - val_loss: 1.1131 - val_accuracy: 0.6069\n",
            "Epoch 41/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.0790 - accuracy: 0.6128 - val_loss: 1.1326 - val_accuracy: 0.5873\n",
            "Epoch 42/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.0867 - accuracy: 0.6020 - val_loss: 1.1123 - val_accuracy: 0.6069\n",
            "Epoch 43/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.0717 - accuracy: 0.6166 - val_loss: 1.1126 - val_accuracy: 0.6003\n",
            "Epoch 44/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.0642 - accuracy: 0.6112 - val_loss: 1.1048 - val_accuracy: 0.6052\n",
            "Epoch 45/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.0320 - accuracy: 0.6107 - val_loss: 1.0859 - val_accuracy: 0.6069\n",
            "Epoch 46/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.0422 - accuracy: 0.6085 - val_loss: 1.1075 - val_accuracy: 0.5987\n",
            "Epoch 47/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.0325 - accuracy: 0.6134 - val_loss: 1.0842 - val_accuracy: 0.6232\n",
            "Epoch 48/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.0264 - accuracy: 0.6150 - val_loss: 1.1000 - val_accuracy: 0.5954\n",
            "Epoch 49/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.0274 - accuracy: 0.6139 - val_loss: 1.0973 - val_accuracy: 0.6069\n",
            "Epoch 50/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.0209 - accuracy: 0.6302 - val_loss: 1.0929 - val_accuracy: 0.6183\n",
            "Epoch 51/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 1.0010 - accuracy: 0.6291 - val_loss: 1.0677 - val_accuracy: 0.6330\n",
            "Epoch 52/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 1.0021 - accuracy: 0.6357 - val_loss: 1.0859 - val_accuracy: 0.6134\n",
            "Epoch 53/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 0.9887 - accuracy: 0.6302 - val_loss: 1.0676 - val_accuracy: 0.6199\n",
            "Epoch 54/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.9836 - accuracy: 0.6395 - val_loss: 1.0838 - val_accuracy: 0.6166\n",
            "Epoch 55/300\n",
            "123/123 [==============================] - 6s 48ms/step - loss: 0.9880 - accuracy: 0.6351 - val_loss: 1.0635 - val_accuracy: 0.6248\n",
            "Epoch 56/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.9867 - accuracy: 0.6373 - val_loss: 1.0695 - val_accuracy: 0.6069\n",
            "Epoch 57/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.9683 - accuracy: 0.6514 - val_loss: 1.0726 - val_accuracy: 0.6150\n",
            "Epoch 58/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.9670 - accuracy: 0.6346 - val_loss: 1.0447 - val_accuracy: 0.6134\n",
            "Epoch 59/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.9716 - accuracy: 0.6368 - val_loss: 1.0294 - val_accuracy: 0.6199\n",
            "Epoch 60/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.9525 - accuracy: 0.6514 - val_loss: 1.0592 - val_accuracy: 0.6150\n",
            "Epoch 61/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 0.9460 - accuracy: 0.6493 - val_loss: 1.0656 - val_accuracy: 0.6150\n",
            "Epoch 62/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 0.9376 - accuracy: 0.6574 - val_loss: 1.0654 - val_accuracy: 0.6101\n",
            "Epoch 63/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 0.9202 - accuracy: 0.6531 - val_loss: 1.0186 - val_accuracy: 0.6281\n",
            "Epoch 64/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.9172 - accuracy: 0.6672 - val_loss: 1.0459 - val_accuracy: 0.6199\n",
            "Epoch 65/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.9297 - accuracy: 0.6547 - val_loss: 1.0381 - val_accuracy: 0.6232\n",
            "Epoch 66/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 0.9050 - accuracy: 0.6694 - val_loss: 1.0659 - val_accuracy: 0.6166\n",
            "Epoch 67/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.9182 - accuracy: 0.6585 - val_loss: 1.0121 - val_accuracy: 0.6264\n",
            "Epoch 68/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 0.9113 - accuracy: 0.6650 - val_loss: 1.0124 - val_accuracy: 0.6134\n",
            "Epoch 69/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8833 - accuracy: 0.6688 - val_loss: 1.0125 - val_accuracy: 0.6297\n",
            "Epoch 70/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 0.8994 - accuracy: 0.6639 - val_loss: 1.0148 - val_accuracy: 0.6183\n",
            "Epoch 71/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8787 - accuracy: 0.6900 - val_loss: 1.0226 - val_accuracy: 0.6281\n",
            "Epoch 72/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8868 - accuracy: 0.6721 - val_loss: 1.0317 - val_accuracy: 0.6134\n",
            "Epoch 73/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8849 - accuracy: 0.6601 - val_loss: 1.0214 - val_accuracy: 0.6313\n",
            "Epoch 74/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8645 - accuracy: 0.6852 - val_loss: 0.9942 - val_accuracy: 0.6411\n",
            "Epoch 75/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8590 - accuracy: 0.6890 - val_loss: 1.0215 - val_accuracy: 0.6232\n",
            "Epoch 76/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8556 - accuracy: 0.6857 - val_loss: 1.0231 - val_accuracy: 0.6264\n",
            "Epoch 77/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8587 - accuracy: 0.6857 - val_loss: 1.0233 - val_accuracy: 0.6281\n",
            "Epoch 78/300\n",
            "123/123 [==============================] - 6s 48ms/step - loss: 0.8336 - accuracy: 0.6911 - val_loss: 1.0028 - val_accuracy: 0.6313\n",
            "Epoch 79/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8540 - accuracy: 0.6911 - val_loss: 1.0216 - val_accuracy: 0.6215\n",
            "Epoch 80/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8426 - accuracy: 0.6960 - val_loss: 0.9888 - val_accuracy: 0.6427\n",
            "Epoch 81/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8310 - accuracy: 0.6922 - val_loss: 1.0024 - val_accuracy: 0.6313\n",
            "Epoch 82/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8360 - accuracy: 0.6873 - val_loss: 0.9999 - val_accuracy: 0.6378\n",
            "Epoch 83/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8205 - accuracy: 0.7074 - val_loss: 1.0024 - val_accuracy: 0.6362\n",
            "Epoch 84/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8115 - accuracy: 0.6998 - val_loss: 0.9939 - val_accuracy: 0.6248\n",
            "Epoch 85/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8202 - accuracy: 0.7009 - val_loss: 0.9938 - val_accuracy: 0.6509\n",
            "Epoch 86/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8116 - accuracy: 0.7096 - val_loss: 1.0034 - val_accuracy: 0.6362\n",
            "Epoch 87/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8011 - accuracy: 0.7102 - val_loss: 0.9831 - val_accuracy: 0.6542\n",
            "Epoch 88/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.8140 - accuracy: 0.7020 - val_loss: 0.9880 - val_accuracy: 0.6362\n",
            "Epoch 89/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7989 - accuracy: 0.7026 - val_loss: 0.9941 - val_accuracy: 0.6493\n",
            "Epoch 90/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7997 - accuracy: 0.7085 - val_loss: 0.9703 - val_accuracy: 0.6427\n",
            "Epoch 91/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7880 - accuracy: 0.7058 - val_loss: 0.9708 - val_accuracy: 0.6509\n",
            "Epoch 92/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7804 - accuracy: 0.7134 - val_loss: 1.0088 - val_accuracy: 0.6346\n",
            "Epoch 93/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7807 - accuracy: 0.7080 - val_loss: 0.9629 - val_accuracy: 0.6509\n",
            "Epoch 94/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7836 - accuracy: 0.7107 - val_loss: 0.9684 - val_accuracy: 0.6411\n",
            "Epoch 95/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7641 - accuracy: 0.7210 - val_loss: 0.9713 - val_accuracy: 0.6558\n",
            "Epoch 96/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7711 - accuracy: 0.7134 - val_loss: 0.9711 - val_accuracy: 0.6623\n",
            "Epoch 97/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7595 - accuracy: 0.7243 - val_loss: 0.9863 - val_accuracy: 0.6509\n",
            "Epoch 98/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7625 - accuracy: 0.7123 - val_loss: 0.9691 - val_accuracy: 0.6411\n",
            "Epoch 99/300\n",
            "123/123 [==============================] - 5s 38ms/step - loss: 0.7542 - accuracy: 0.7254 - val_loss: 0.9547 - val_accuracy: 0.6623\n",
            "Epoch 100/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7462 - accuracy: 0.7379 - val_loss: 0.9419 - val_accuracy: 0.6509\n",
            "Epoch 101/300\n",
            "123/123 [==============================] - 6s 48ms/step - loss: 0.7504 - accuracy: 0.7205 - val_loss: 0.9603 - val_accuracy: 0.6639\n",
            "Epoch 102/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7405 - accuracy: 0.7336 - val_loss: 0.9782 - val_accuracy: 0.6558\n",
            "Epoch 103/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7533 - accuracy: 0.7221 - val_loss: 0.9382 - val_accuracy: 0.6607\n",
            "Epoch 104/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7324 - accuracy: 0.7384 - val_loss: 0.9704 - val_accuracy: 0.6476\n",
            "Epoch 105/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7189 - accuracy: 0.7281 - val_loss: 0.9693 - val_accuracy: 0.6411\n",
            "Epoch 106/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7144 - accuracy: 0.7433 - val_loss: 0.9449 - val_accuracy: 0.6803\n",
            "Epoch 107/300\n",
            "123/123 [==============================] - 8s 69ms/step - loss: 0.7122 - accuracy: 0.7412 - val_loss: 0.9445 - val_accuracy: 0.6639\n",
            "Epoch 108/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.7217 - accuracy: 0.7330 - val_loss: 0.9544 - val_accuracy: 0.6493\n",
            "Epoch 109/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7158 - accuracy: 0.7330 - val_loss: 0.9638 - val_accuracy: 0.6574\n",
            "Epoch 110/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7085 - accuracy: 0.7450 - val_loss: 0.9444 - val_accuracy: 0.6591\n",
            "Epoch 111/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.7043 - accuracy: 0.7428 - val_loss: 0.9326 - val_accuracy: 0.6607\n",
            "Epoch 112/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6943 - accuracy: 0.7444 - val_loss: 0.9283 - val_accuracy: 0.6493\n",
            "Epoch 113/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6931 - accuracy: 0.7466 - val_loss: 0.9388 - val_accuracy: 0.6754\n",
            "Epoch 114/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6978 - accuracy: 0.7455 - val_loss: 0.9378 - val_accuracy: 0.6591\n",
            "Epoch 115/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6708 - accuracy: 0.7564 - val_loss: 0.9334 - val_accuracy: 0.6623\n",
            "Epoch 116/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6898 - accuracy: 0.7428 - val_loss: 0.9422 - val_accuracy: 0.6754\n",
            "Epoch 117/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6896 - accuracy: 0.7433 - val_loss: 0.9378 - val_accuracy: 0.6688\n",
            "Epoch 118/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6755 - accuracy: 0.7618 - val_loss: 0.9301 - val_accuracy: 0.6754\n",
            "Epoch 119/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6820 - accuracy: 0.7613 - val_loss: 0.9473 - val_accuracy: 0.6509\n",
            "Epoch 120/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6689 - accuracy: 0.7580 - val_loss: 0.9267 - val_accuracy: 0.6737\n",
            "Epoch 121/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6629 - accuracy: 0.7569 - val_loss: 0.9511 - val_accuracy: 0.6656\n",
            "Epoch 122/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6670 - accuracy: 0.7515 - val_loss: 0.9280 - val_accuracy: 0.6688\n",
            "Epoch 123/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.6445 - accuracy: 0.7629 - val_loss: 0.9148 - val_accuracy: 0.6786\n",
            "Epoch 124/300\n",
            "123/123 [==============================] - 6s 48ms/step - loss: 0.6577 - accuracy: 0.7635 - val_loss: 0.9295 - val_accuracy: 0.6656\n",
            "Epoch 125/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6680 - accuracy: 0.7580 - val_loss: 0.9314 - val_accuracy: 0.6721\n",
            "Epoch 126/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6326 - accuracy: 0.7651 - val_loss: 0.9236 - val_accuracy: 0.6672\n",
            "Epoch 127/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6592 - accuracy: 0.7635 - val_loss: 0.9023 - val_accuracy: 0.6754\n",
            "Epoch 128/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6303 - accuracy: 0.7640 - val_loss: 0.9423 - val_accuracy: 0.6770\n",
            "Epoch 129/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6340 - accuracy: 0.7705 - val_loss: 0.9400 - val_accuracy: 0.6672\n",
            "Epoch 130/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6327 - accuracy: 0.7662 - val_loss: 0.9287 - val_accuracy: 0.6672\n",
            "Epoch 131/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6097 - accuracy: 0.7754 - val_loss: 0.9395 - val_accuracy: 0.6639\n",
            "Epoch 132/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6454 - accuracy: 0.7716 - val_loss: 0.9117 - val_accuracy: 0.6754\n",
            "Epoch 133/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6208 - accuracy: 0.7771 - val_loss: 0.9337 - val_accuracy: 0.6639\n",
            "Epoch 134/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6195 - accuracy: 0.7722 - val_loss: 0.9200 - val_accuracy: 0.6656\n",
            "Epoch 135/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6144 - accuracy: 0.7863 - val_loss: 0.9301 - val_accuracy: 0.6786\n",
            "Epoch 136/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.6018 - accuracy: 0.7809 - val_loss: 0.9359 - val_accuracy: 0.6688\n",
            "Epoch 137/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.6105 - accuracy: 0.7787 - val_loss: 0.9092 - val_accuracy: 0.6819\n",
            "Epoch 138/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6142 - accuracy: 0.7749 - val_loss: 0.9378 - val_accuracy: 0.6770\n",
            "Epoch 139/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6034 - accuracy: 0.7819 - val_loss: 0.9087 - val_accuracy: 0.6819\n",
            "Epoch 140/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.6053 - accuracy: 0.7694 - val_loss: 0.9464 - val_accuracy: 0.6770\n",
            "Epoch 141/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.5820 - accuracy: 0.7814 - val_loss: 0.9230 - val_accuracy: 0.6754\n",
            "Epoch 142/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5736 - accuracy: 0.7961 - val_loss: 0.8992 - val_accuracy: 0.6917\n",
            "Epoch 143/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5925 - accuracy: 0.7819 - val_loss: 0.8991 - val_accuracy: 0.6966\n",
            "Epoch 144/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5850 - accuracy: 0.7798 - val_loss: 0.9084 - val_accuracy: 0.6737\n",
            "Epoch 145/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5859 - accuracy: 0.7890 - val_loss: 0.9117 - val_accuracy: 0.6819\n",
            "Epoch 146/300\n",
            "123/123 [==============================] - 5s 42ms/step - loss: 0.5735 - accuracy: 0.7885 - val_loss: 0.9426 - val_accuracy: 0.6623\n",
            "Epoch 147/300\n",
            "123/123 [==============================] - 6s 46ms/step - loss: 0.5704 - accuracy: 0.7983 - val_loss: 0.9136 - val_accuracy: 0.6803\n",
            "Epoch 148/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5855 - accuracy: 0.7858 - val_loss: 0.9317 - val_accuracy: 0.6705\n",
            "Epoch 149/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5643 - accuracy: 0.7917 - val_loss: 0.9362 - val_accuracy: 0.6607\n",
            "Epoch 150/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5653 - accuracy: 0.7917 - val_loss: 0.9173 - val_accuracy: 0.6770\n",
            "Epoch 151/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5670 - accuracy: 0.7983 - val_loss: 0.9379 - val_accuracy: 0.6705\n",
            "Epoch 152/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5524 - accuracy: 0.8048 - val_loss: 0.9135 - val_accuracy: 0.6835\n",
            "Epoch 153/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5614 - accuracy: 0.7896 - val_loss: 0.9375 - val_accuracy: 0.6705\n",
            "Epoch 154/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5724 - accuracy: 0.7912 - val_loss: 0.9286 - val_accuracy: 0.6737\n",
            "Epoch 155/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5492 - accuracy: 0.8124 - val_loss: 0.9426 - val_accuracy: 0.6623\n",
            "Epoch 156/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5461 - accuracy: 0.8021 - val_loss: 0.9080 - val_accuracy: 0.6884\n",
            "Epoch 157/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5439 - accuracy: 0.8053 - val_loss: 0.9260 - val_accuracy: 0.6737\n",
            "Epoch 158/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5488 - accuracy: 0.8048 - val_loss: 0.9254 - val_accuracy: 0.6786\n",
            "Epoch 159/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5452 - accuracy: 0.7945 - val_loss: 0.9120 - val_accuracy: 0.6884\n",
            "Epoch 160/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5468 - accuracy: 0.8004 - val_loss: 0.9120 - val_accuracy: 0.6868\n",
            "Epoch 161/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5176 - accuracy: 0.7983 - val_loss: 0.9372 - val_accuracy: 0.6770\n",
            "Epoch 162/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5215 - accuracy: 0.8080 - val_loss: 0.9387 - val_accuracy: 0.6754\n",
            "Epoch 163/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5251 - accuracy: 0.8091 - val_loss: 0.9354 - val_accuracy: 0.6688\n",
            "Epoch 164/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5284 - accuracy: 0.8151 - val_loss: 0.9087 - val_accuracy: 0.6884\n",
            "Epoch 165/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5102 - accuracy: 0.8206 - val_loss: 0.9058 - val_accuracy: 0.6966\n",
            "Epoch 166/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5154 - accuracy: 0.8167 - val_loss: 0.9337 - val_accuracy: 0.6852\n",
            "Epoch 167/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5134 - accuracy: 0.8108 - val_loss: 0.9153 - val_accuracy: 0.6852\n",
            "Epoch 168/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5079 - accuracy: 0.8184 - val_loss: 0.9098 - val_accuracy: 0.6998\n",
            "Epoch 169/300\n",
            "123/123 [==============================] - 5s 42ms/step - loss: 0.5116 - accuracy: 0.8167 - val_loss: 0.9165 - val_accuracy: 0.6933\n",
            "Epoch 170/300\n",
            "123/123 [==============================] - 6s 46ms/step - loss: 0.5010 - accuracy: 0.8195 - val_loss: 0.9314 - val_accuracy: 0.6786\n",
            "Epoch 171/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5071 - accuracy: 0.8200 - val_loss: 0.9039 - val_accuracy: 0.6884\n",
            "Epoch 172/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4948 - accuracy: 0.8244 - val_loss: 0.9102 - val_accuracy: 0.6900\n",
            "Epoch 173/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.5069 - accuracy: 0.8271 - val_loss: 0.9279 - val_accuracy: 0.6868\n",
            "Epoch 174/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4996 - accuracy: 0.8200 - val_loss: 0.9123 - val_accuracy: 0.6852\n",
            "Epoch 175/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4847 - accuracy: 0.8206 - val_loss: 0.9250 - val_accuracy: 0.6737\n",
            "Epoch 176/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.4835 - accuracy: 0.8271 - val_loss: 0.9015 - val_accuracy: 0.6868\n",
            "Epoch 177/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4922 - accuracy: 0.8314 - val_loss: 0.9058 - val_accuracy: 0.6933\n",
            "Epoch 178/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4734 - accuracy: 0.8407 - val_loss: 0.8907 - val_accuracy: 0.6998\n",
            "Epoch 179/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4639 - accuracy: 0.8390 - val_loss: 0.9257 - val_accuracy: 0.6998\n",
            "Epoch 180/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4763 - accuracy: 0.8265 - val_loss: 0.9066 - val_accuracy: 0.7015\n",
            "Epoch 181/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4643 - accuracy: 0.8358 - val_loss: 0.9236 - val_accuracy: 0.6917\n",
            "Epoch 182/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4778 - accuracy: 0.8276 - val_loss: 0.8969 - val_accuracy: 0.6917\n",
            "Epoch 183/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4639 - accuracy: 0.8341 - val_loss: 0.9676 - val_accuracy: 0.6754\n",
            "Epoch 184/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4639 - accuracy: 0.8287 - val_loss: 0.9361 - val_accuracy: 0.6803\n",
            "Epoch 185/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.4620 - accuracy: 0.8341 - val_loss: 0.9206 - val_accuracy: 0.6884\n",
            "Epoch 186/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4526 - accuracy: 0.8374 - val_loss: 0.8882 - val_accuracy: 0.7047\n",
            "Epoch 187/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.4487 - accuracy: 0.8412 - val_loss: 0.9082 - val_accuracy: 0.6933\n",
            "Epoch 188/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4483 - accuracy: 0.8390 - val_loss: 0.9282 - val_accuracy: 0.6998\n",
            "Epoch 189/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4397 - accuracy: 0.8494 - val_loss: 0.9098 - val_accuracy: 0.6933\n",
            "Epoch 190/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4558 - accuracy: 0.8320 - val_loss: 0.9150 - val_accuracy: 0.6998\n",
            "Epoch 191/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.4483 - accuracy: 0.8428 - val_loss: 0.9113 - val_accuracy: 0.6900\n",
            "Epoch 192/300\n",
            "123/123 [==============================] - 6s 49ms/step - loss: 0.4420 - accuracy: 0.8390 - val_loss: 0.9007 - val_accuracy: 0.6998\n",
            "Epoch 193/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.4312 - accuracy: 0.8369 - val_loss: 0.8918 - val_accuracy: 0.7015\n",
            "Epoch 194/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4329 - accuracy: 0.8456 - val_loss: 0.9033 - val_accuracy: 0.6933\n",
            "Epoch 195/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.4233 - accuracy: 0.8510 - val_loss: 0.9145 - val_accuracy: 0.6917\n",
            "Epoch 196/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.4262 - accuracy: 0.8428 - val_loss: 0.9117 - val_accuracy: 0.6868\n",
            "Epoch 197/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.4115 - accuracy: 0.8581 - val_loss: 0.9294 - val_accuracy: 0.6900\n",
            "Epoch 198/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.4296 - accuracy: 0.8554 - val_loss: 0.9018 - val_accuracy: 0.6982\n",
            "Epoch 199/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.4211 - accuracy: 0.8477 - val_loss: 0.9146 - val_accuracy: 0.6966\n",
            "Epoch 200/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4018 - accuracy: 0.8630 - val_loss: 0.8915 - val_accuracy: 0.6949\n",
            "Epoch 201/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4205 - accuracy: 0.8564 - val_loss: 0.9036 - val_accuracy: 0.7015\n",
            "Epoch 202/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4237 - accuracy: 0.8407 - val_loss: 0.9115 - val_accuracy: 0.7047\n",
            "Epoch 203/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.4203 - accuracy: 0.8456 - val_loss: 0.9474 - val_accuracy: 0.6998\n",
            "Epoch 204/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.4158 - accuracy: 0.8483 - val_loss: 0.9060 - val_accuracy: 0.7096\n",
            "Epoch 205/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4233 - accuracy: 0.8499 - val_loss: 0.9005 - val_accuracy: 0.7064\n",
            "Epoch 206/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.3929 - accuracy: 0.8581 - val_loss: 0.9134 - val_accuracy: 0.6982\n",
            "Epoch 207/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.4107 - accuracy: 0.8461 - val_loss: 0.9110 - val_accuracy: 0.7064\n",
            "Epoch 208/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.4046 - accuracy: 0.8521 - val_loss: 0.9087 - val_accuracy: 0.7047\n",
            "Epoch 209/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.3941 - accuracy: 0.8603 - val_loss: 0.9309 - val_accuracy: 0.6933\n",
            "Epoch 210/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.4008 - accuracy: 0.8570 - val_loss: 0.9066 - val_accuracy: 0.7113\n",
            "Epoch 211/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3948 - accuracy: 0.8603 - val_loss: 0.9263 - val_accuracy: 0.7015\n",
            "Epoch 212/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3871 - accuracy: 0.8613 - val_loss: 0.9201 - val_accuracy: 0.6998\n",
            "Epoch 213/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3748 - accuracy: 0.8700 - val_loss: 0.9091 - val_accuracy: 0.7047\n",
            "Epoch 214/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.3833 - accuracy: 0.8635 - val_loss: 0.9087 - val_accuracy: 0.7113\n",
            "Epoch 215/300\n",
            "123/123 [==============================] - 6s 48ms/step - loss: 0.3853 - accuracy: 0.8673 - val_loss: 0.8958 - val_accuracy: 0.7096\n",
            "Epoch 216/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3844 - accuracy: 0.8673 - val_loss: 0.9173 - val_accuracy: 0.7031\n",
            "Epoch 217/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3776 - accuracy: 0.8662 - val_loss: 0.8887 - val_accuracy: 0.7162\n",
            "Epoch 218/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3660 - accuracy: 0.8777 - val_loss: 0.9151 - val_accuracy: 0.7015\n",
            "Epoch 219/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.3639 - accuracy: 0.8690 - val_loss: 0.9019 - val_accuracy: 0.7080\n",
            "Epoch 220/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.3698 - accuracy: 0.8684 - val_loss: 0.9130 - val_accuracy: 0.7096\n",
            "Epoch 221/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3859 - accuracy: 0.8603 - val_loss: 0.9007 - val_accuracy: 0.7080\n",
            "Epoch 222/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3634 - accuracy: 0.8760 - val_loss: 0.8815 - val_accuracy: 0.7113\n",
            "Epoch 223/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3673 - accuracy: 0.8684 - val_loss: 0.9045 - val_accuracy: 0.7015\n",
            "Epoch 224/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3617 - accuracy: 0.8771 - val_loss: 0.9285 - val_accuracy: 0.6982\n",
            "Epoch 225/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.3464 - accuracy: 0.8771 - val_loss: 0.8966 - val_accuracy: 0.7064\n",
            "Epoch 226/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3583 - accuracy: 0.8766 - val_loss: 0.9001 - val_accuracy: 0.7031\n",
            "Epoch 227/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.3562 - accuracy: 0.8766 - val_loss: 0.8853 - val_accuracy: 0.7080\n",
            "Epoch 228/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3499 - accuracy: 0.8722 - val_loss: 0.8864 - val_accuracy: 0.7210\n",
            "Epoch 229/300\n",
            "123/123 [==============================] - 5s 39ms/step - loss: 0.3578 - accuracy: 0.8733 - val_loss: 0.8969 - val_accuracy: 0.7015\n",
            "Epoch 230/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3481 - accuracy: 0.8787 - val_loss: 0.8639 - val_accuracy: 0.7096\n",
            "Epoch 231/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3574 - accuracy: 0.8744 - val_loss: 0.9006 - val_accuracy: 0.7129\n",
            "Epoch 232/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3247 - accuracy: 0.8874 - val_loss: 0.9253 - val_accuracy: 0.7113\n",
            "Epoch 233/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3384 - accuracy: 0.8798 - val_loss: 0.8969 - val_accuracy: 0.7145\n",
            "Epoch 234/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3379 - accuracy: 0.8798 - val_loss: 0.9002 - val_accuracy: 0.7162\n",
            "Epoch 235/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3278 - accuracy: 0.8869 - val_loss: 0.8856 - val_accuracy: 0.7064\n",
            "Epoch 236/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3412 - accuracy: 0.8804 - val_loss: 0.9248 - val_accuracy: 0.7129\n",
            "Epoch 237/300\n",
            "123/123 [==============================] - 6s 50ms/step - loss: 0.3493 - accuracy: 0.8760 - val_loss: 0.9020 - val_accuracy: 0.7113\n",
            "Epoch 238/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3045 - accuracy: 0.9010 - val_loss: 0.9088 - val_accuracy: 0.7047\n",
            "Epoch 239/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3225 - accuracy: 0.8896 - val_loss: 0.8908 - val_accuracy: 0.7064\n",
            "Epoch 240/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3295 - accuracy: 0.8842 - val_loss: 0.9241 - val_accuracy: 0.7031\n",
            "Epoch 241/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3222 - accuracy: 0.8934 - val_loss: 0.9148 - val_accuracy: 0.7162\n",
            "Epoch 242/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3199 - accuracy: 0.8907 - val_loss: 0.9014 - val_accuracy: 0.7145\n",
            "Epoch 243/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3212 - accuracy: 0.8885 - val_loss: 0.8971 - val_accuracy: 0.7096\n",
            "Epoch 244/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3164 - accuracy: 0.8864 - val_loss: 0.9273 - val_accuracy: 0.7031\n",
            "Epoch 245/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3197 - accuracy: 0.8847 - val_loss: 0.9318 - val_accuracy: 0.7113\n",
            "Epoch 246/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3110 - accuracy: 0.8885 - val_loss: 0.9496 - val_accuracy: 0.7178\n",
            "Epoch 247/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3087 - accuracy: 0.8945 - val_loss: 0.9256 - val_accuracy: 0.7096\n",
            "Epoch 248/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.3031 - accuracy: 0.8918 - val_loss: 0.9167 - val_accuracy: 0.7210\n",
            "Epoch 249/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.2994 - accuracy: 0.9010 - val_loss: 0.9147 - val_accuracy: 0.7178\n",
            "Epoch 250/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.3071 - accuracy: 0.8934 - val_loss: 0.9503 - val_accuracy: 0.7080\n",
            "Epoch 251/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.2988 - accuracy: 0.8961 - val_loss: 0.9381 - val_accuracy: 0.7162\n",
            "Epoch 252/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.2951 - accuracy: 0.8945 - val_loss: 0.9260 - val_accuracy: 0.7080\n",
            "Epoch 253/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.2831 - accuracy: 0.9048 - val_loss: 0.9103 - val_accuracy: 0.7178\n",
            "Epoch 254/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.2907 - accuracy: 0.9005 - val_loss: 0.9218 - val_accuracy: 0.7162\n",
            "Epoch 255/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.2946 - accuracy: 0.8999 - val_loss: 0.9185 - val_accuracy: 0.7194\n",
            "Epoch 256/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.2799 - accuracy: 0.9065 - val_loss: 0.9207 - val_accuracy: 0.7259\n",
            "Epoch 257/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2805 - accuracy: 0.9054 - val_loss: 0.9345 - val_accuracy: 0.7243\n",
            "Epoch 258/300\n",
            "123/123 [==============================] - 5s 42ms/step - loss: 0.2918 - accuracy: 0.9016 - val_loss: 0.9210 - val_accuracy: 0.7194\n",
            "Epoch 259/300\n",
            "123/123 [==============================] - 6s 51ms/step - loss: 0.2723 - accuracy: 0.9097 - val_loss: 0.9279 - val_accuracy: 0.7145\n",
            "Epoch 260/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2805 - accuracy: 0.8929 - val_loss: 0.9219 - val_accuracy: 0.7227\n",
            "Epoch 261/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.2888 - accuracy: 0.8994 - val_loss: 0.9345 - val_accuracy: 0.7276\n",
            "Epoch 262/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2708 - accuracy: 0.9081 - val_loss: 0.9287 - val_accuracy: 0.7243\n",
            "Epoch 263/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2720 - accuracy: 0.9016 - val_loss: 0.9246 - val_accuracy: 0.7129\n",
            "Epoch 264/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2724 - accuracy: 0.9021 - val_loss: 0.9052 - val_accuracy: 0.7243\n",
            "Epoch 265/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.2855 - accuracy: 0.9059 - val_loss: 0.8847 - val_accuracy: 0.7227\n",
            "Epoch 266/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2729 - accuracy: 0.9103 - val_loss: 0.9086 - val_accuracy: 0.7145\n",
            "Epoch 267/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.2716 - accuracy: 0.9135 - val_loss: 0.9170 - val_accuracy: 0.7178\n",
            "Epoch 268/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2724 - accuracy: 0.9065 - val_loss: 0.9238 - val_accuracy: 0.7210\n",
            "Epoch 269/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2765 - accuracy: 0.9097 - val_loss: 0.9311 - val_accuracy: 0.7210\n",
            "Epoch 270/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2578 - accuracy: 0.9097 - val_loss: 0.9422 - val_accuracy: 0.7292\n",
            "Epoch 271/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.2689 - accuracy: 0.9125 - val_loss: 0.9403 - val_accuracy: 0.7194\n",
            "Epoch 272/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2732 - accuracy: 0.9141 - val_loss: 0.9119 - val_accuracy: 0.7259\n",
            "Epoch 273/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2612 - accuracy: 0.9097 - val_loss: 0.9130 - val_accuracy: 0.7162\n",
            "Epoch 274/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2575 - accuracy: 0.9168 - val_loss: 0.9299 - val_accuracy: 0.7178\n",
            "Epoch 275/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2505 - accuracy: 0.9173 - val_loss: 0.9396 - val_accuracy: 0.7113\n",
            "Epoch 276/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2557 - accuracy: 0.9157 - val_loss: 0.9251 - val_accuracy: 0.7178\n",
            "Epoch 277/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.2606 - accuracy: 0.9168 - val_loss: 0.9371 - val_accuracy: 0.7227\n",
            "Epoch 278/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2658 - accuracy: 0.9130 - val_loss: 0.9328 - val_accuracy: 0.7194\n",
            "Epoch 279/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2405 - accuracy: 0.9206 - val_loss: 0.9225 - val_accuracy: 0.7178\n",
            "Epoch 280/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2452 - accuracy: 0.9163 - val_loss: 0.9392 - val_accuracy: 0.7194\n",
            "Epoch 281/300\n",
            "123/123 [==============================] - 6s 50ms/step - loss: 0.2339 - accuracy: 0.9212 - val_loss: 0.9384 - val_accuracy: 0.7243\n",
            "Epoch 282/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2435 - accuracy: 0.9190 - val_loss: 0.9692 - val_accuracy: 0.7227\n",
            "Epoch 283/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2479 - accuracy: 0.9217 - val_loss: 0.9248 - val_accuracy: 0.7243\n",
            "Epoch 284/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2346 - accuracy: 0.9201 - val_loss: 0.9457 - val_accuracy: 0.7113\n",
            "Epoch 285/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.2473 - accuracy: 0.9184 - val_loss: 0.9267 - val_accuracy: 0.7227\n",
            "Epoch 286/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2265 - accuracy: 0.9266 - val_loss: 0.9391 - val_accuracy: 0.7243\n",
            "Epoch 287/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.2388 - accuracy: 0.9228 - val_loss: 0.9439 - val_accuracy: 0.7194\n",
            "Epoch 288/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2304 - accuracy: 0.9228 - val_loss: 0.9724 - val_accuracy: 0.7145\n",
            "Epoch 289/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2327 - accuracy: 0.9190 - val_loss: 0.9605 - val_accuracy: 0.7178\n",
            "Epoch 290/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2370 - accuracy: 0.9239 - val_loss: 0.9524 - val_accuracy: 0.7308\n",
            "Epoch 291/300\n",
            "123/123 [==============================] - 5s 40ms/step - loss: 0.2070 - accuracy: 0.9331 - val_loss: 0.9674 - val_accuracy: 0.7292\n",
            "Epoch 292/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2226 - accuracy: 0.9260 - val_loss: 0.9620 - val_accuracy: 0.7096\n",
            "Epoch 293/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2356 - accuracy: 0.9206 - val_loss: 0.9195 - val_accuracy: 0.7276\n",
            "Epoch 294/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2331 - accuracy: 0.9206 - val_loss: 0.9398 - val_accuracy: 0.7227\n",
            "Epoch 295/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2342 - accuracy: 0.9190 - val_loss: 0.9541 - val_accuracy: 0.7357\n",
            "Epoch 296/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2272 - accuracy: 0.9222 - val_loss: 0.9172 - val_accuracy: 0.7243\n",
            "Epoch 297/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2287 - accuracy: 0.9228 - val_loss: 0.9272 - val_accuracy: 0.7243\n",
            "Epoch 298/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2195 - accuracy: 0.9217 - val_loss: 0.9601 - val_accuracy: 0.7357\n",
            "Epoch 299/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2164 - accuracy: 0.9239 - val_loss: 0.9409 - val_accuracy: 0.7210\n",
            "Epoch 300/300\n",
            "123/123 [==============================] - 5s 41ms/step - loss: 0.2167 - accuracy: 0.9255 - val_loss: 0.9283 - val_accuracy: 0.7259\n"
          ]
        }
      ],
      "source": [
        "cnn4 = model4.fit(X_train, y_train, batch_size=15, epochs=300, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFHG9eEi_M1t",
        "outputId": "f2abbe4b-c5b6-47fa-e53c-91a33155f323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 16ms/step - loss: 0.9283 - accuracy: 0.7259\n",
            "Accuracy: 72.59%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model4.evaluate(X_test, y_test)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "y6hY0yo8_SHF",
        "outputId": "fbdc2d2e-d183-4b41-88b3-edbdbbd16db8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "plt.plot(cnn4.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(cnn4.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "lDICjQPx_Vmc",
        "outputId": "7d02a9c7-4441-472b-fa4e-4bd564a66044"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "plt.plot(cnn4.history[\"accuracy\"], label=\"loss\")\n",
        "plt.plot(cnn4.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srySQ5J8Ei8S",
        "outputId": "b14269da-179d-4f54-ddaa-fe86d936e404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5865580448065173\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.71      0.67        72\n",
            "           1       0.70      0.75      0.72        87\n",
            "           2       0.42      0.47      0.45        36\n",
            "           3       0.56      0.45      0.50        88\n",
            "           4       0.53      0.48      0.51        66\n",
            "           5       0.58      0.50      0.54        38\n",
            "           6       0.53      0.62      0.57        73\n",
            "           7       0.66      0.61      0.63        31\n",
            "\n",
            "    accuracy                           0.59       491\n",
            "   macro avg       0.58      0.57      0.57       491\n",
            "weighted avg       0.59      0.59      0.58       491\n",
            "\n",
            "[[51  1  7  7  2  0  3  1]\n",
            " [ 0 65  1  1  9  5  6  0]\n",
            " [ 7  1 17  2  5  1  2  1]\n",
            " [15  5  3 40  6  3 13  3]\n",
            " [ 5  4  5  6 32  3  8  3]\n",
            " [ 0  4  2  3  2 19  8  0]\n",
            " [ 1 12  2  8  2  1 45  2]\n",
            " [ 1  1  3  4  2  1  0 19]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC \n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "X4 = dataset4.iloc[:,1:-1].values\n",
        "y4 = dataset4.iloc[:,-1].values\n",
        "encoder = LabelEncoder()\n",
        "y4 = encoder.fit_transform(y4)\n",
        "pca = PCA(n_components=50)\n",
        "X4 = pca.fit_transform(X4)\n",
        "\n",
        "X_train, X_test, y_train, y_test = split_scale(X4,y4)\n",
        "\n",
        "\n",
        "svm_model_linear = SVC(kernel = 'linear', C = 1,decision_function_shape='ovo').fit(X_train, y_train) \n",
        "svm_predictions = svm_model_linear.predict(X_test) \n",
        "\n",
        "\n",
        "print(accuracy_score(y_true=y_test,y_pred=svm_predictions))\n",
        "print(classification_report(y_test,svm_predictions)) \n",
        "# creating a confusion matrix \n",
        "print(confusion_matrix(y_test, svm_predictions) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msqu28-sE006",
        "outputId": "4cdc3438-a3e0-4bed-9860-474899d62c95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.600326264274062\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.73      0.75        91\n",
            "           1       0.62      0.84      0.71        88\n",
            "           2       0.37      0.40      0.38        45\n",
            "           3       0.43      0.53      0.48        81\n",
            "           4       0.69      0.50      0.58        98\n",
            "           5       0.84      0.45      0.58        47\n",
            "           6       0.59      0.54      0.56       109\n",
            "           7       0.59      0.70      0.64        54\n",
            "\n",
            "    accuracy                           0.60       613\n",
            "   macro avg       0.61      0.59      0.59       613\n",
            "weighted avg       0.62      0.60      0.60       613\n",
            "\n",
            "[[66  0  7 12  0  1  0  5]\n",
            " [ 0 74  5  1  3  0  5  0]\n",
            " [ 5  2 18  3  5  0  5  7]\n",
            " [ 7  5  1 43  5  1 12  7]\n",
            " [ 4 14  7 18 49  0  5  1]\n",
            " [ 0  8  2  1  3 21 10  2]\n",
            " [ 3 14  5 17  5  2 59  4]\n",
            " [ 1  2  4  4  1  0  4 38]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC \n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "X4 = dataset4.iloc[:,1:-1].values\n",
        "y4 = dataset4.iloc[:,-1].values\n",
        "encoder = LabelEncoder()\n",
        "scaler = MinMaxScaler()\n",
        "X4 = scaler.fit_transform(X4)\n",
        "y4 = encoder.fit_transform(y4)\n",
        "pca = PCA(n_components=50)\n",
        "X4 = pca.fit_transform(X4)\n",
        "\n",
        "X_train, X_test, y_train, y_test = split_scale(X4,y4)\n",
        "\n",
        "\n",
        "svm_model_linear = SVC(kernel = 'linear', C = 1,decision_function_shape='ovo').fit(X_train, y_train) \n",
        "svm_predictions = svm_model_linear.predict(X_test) \n",
        "\n",
        "\n",
        "print(accuracy_score(y_true=y_test,y_pred=svm_predictions))\n",
        "print(classification_report(y_test,svm_predictions)) \n",
        "# creating a confusion matrix \n",
        "print(confusion_matrix(y_test, svm_predictions) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm7IS8GwGLgh"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzbRg8wcGNQq",
        "outputId": "6f3a114a-6050-4ef1-fd03-b8ab4687a58e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7079934747145188\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82        91\n",
            "           1       0.65      0.88      0.75        88\n",
            "           2       0.72      0.58      0.64        45\n",
            "           3       0.57      0.74      0.65        81\n",
            "           4       0.79      0.64      0.71        98\n",
            "           5       0.78      0.53      0.63        47\n",
            "           6       0.76      0.69      0.72       109\n",
            "           7       0.61      0.67      0.64        54\n",
            "\n",
            "    accuracy                           0.71       613\n",
            "   macro avg       0.72      0.69      0.69       613\n",
            "weighted avg       0.72      0.71      0.71       613\n",
            "\n",
            "[[72  1  5  3  3  1  0  6]\n",
            " [ 0 77  1  0  4  2  4  0]\n",
            " [ 3  2 26  2  2  1  4  5]\n",
            " [ 5  3  1 60  0  1  7  4]\n",
            " [ 2 11  1 17 63  0  1  3]\n",
            " [ 0 11  0  2  0 25  6  3]\n",
            " [ 1 11  1 16  3  0 75  2]\n",
            " [ 1  2  1  5  5  2  2 36]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=300,max_features='sqrt',random_state=25)\n",
        "rfc.fit(X_train,y_train)\n",
        "\n",
        "rfc_predict = rfc.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_true=y_test,y_pred=rfc_predict))\n",
        "print(classification_report(y_test,rfc_predict)) \n",
        "# creating a confusion matrix \n",
        "print(confusion_matrix(y_test, rfc_predict) )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZg4KyHhXVna"
      },
      "source": [
        "Multi Layer Perceptron \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sps7Lj3XXh5",
        "outputId": "8d2f9591-340d-4765-8670-5eefdd12cd1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.734094616639478\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.82      0.82        91\n",
            "           1       0.86      0.70      0.78        88\n",
            "           2       0.59      0.60      0.59        45\n",
            "           3       0.67      0.74      0.71        81\n",
            "           4       0.88      0.68      0.77        98\n",
            "           5       0.58      0.81      0.67        47\n",
            "           6       0.80      0.72      0.76       109\n",
            "           7       0.58      0.78      0.67        54\n",
            "\n",
            "    accuracy                           0.73       613\n",
            "   macro avg       0.72      0.73      0.72       613\n",
            "weighted avg       0.75      0.73      0.74       613\n",
            "\n",
            "[[75  0  5  4  0  0  1  6]\n",
            " [ 3 62  3  0  2 12  6  0]\n",
            " [ 4  0 27  1  1  3  1  8]\n",
            " [ 3  0  3 60  3  1  7  4]\n",
            " [ 7  5  1  9 67  1  2  6]\n",
            " [ 0  4  1  0  0 38  2  2]\n",
            " [ 1  1  2 13  1  8 79  4]\n",
            " [ 0  0  4  2  2  3  1 42]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(200,200,200,200),random_state=50,batch_size=200,\n",
        "                    max_iter=500,epsilon=1e-08,learning_rate='adaptive')\n",
        "    \n",
        "mlp.fit(X_train,y_train)\n",
        "mlp_pred = mlp.predict(X_test)\n",
        "mlp.score(X_test,y_test)\n",
        "print(accuracy_score(y_true=y_test,y_pred=mlp_pred))\n",
        "print(classification_report(y_test,mlp_pred)) \n",
        "print(confusion_matrix(y_test, mlp_pred) )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "s5Gg4_nEk_Y5",
        "outputId": "02e4ddb5-ad7b-46b1-a79f-4890977da792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "201\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "loss = mlp.loss_curve_\n",
        "\n",
        "length = len(loss)\n",
        "print(length)\n",
        "x = [i for i in range(1,length+1)]\n",
        "plt.plot(x,loss)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi-wWOERPpf3"
      },
      "source": [
        "RAVDESS + CREMAD\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etOzSw8VPtB8"
      },
      "outputs": [],
      "source": [
        "data_combined = pd.read_csv('dataset5.csv')\n",
        "\n",
        "X5 = data_combined.iloc[:,1:-1].values\n",
        "y5 = data_combined.iloc[:,-1].values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufK9X4XlQnm_",
        "outputId": "b7c65116-12d9-4a45-c5e6-70fccab9cebb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((9894, 198), (9894,))"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X5.shape,y5.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bOOn_cr8OsG",
        "outputId": "67ace991-efe5-4f99-ec14-298cfea5cbb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['neutral' 'angry' 'happy' ... 'fear' 'fear' 'disgust']\n"
          ]
        }
      ],
      "source": [
        "print(y5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oVL_qY-QrEq",
        "outputId": "57241356-d233-42a1-e000-09e358a739ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5 0 4 ... 3 3 2]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y5 = encoder.fit_transform(y5)\n",
        "print(y5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuDg7NnjQ24G"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = split_scale(X5,y5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCTORNECQ-NE",
        "outputId": "ad03f219-0c61-47ec-eb15-2ed65c1bd9f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_20 (Conv1D)          (None, 198, 32)           128       \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 198, 32)           0         \n",
            "                                                                 \n",
            " conv1d_21 (Conv1D)          (None, 198, 32)           3104      \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 198, 32)           0         \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 198, 32)           0         \n",
            "                                                                 \n",
            " max_pooling1d_16 (MaxPoolin  (None, 99, 32)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_22 (Conv1D)          (None, 99, 64)            6208      \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 99, 64)            0         \n",
            "                                                                 \n",
            " conv1d_23 (Conv1D)          (None, 99, 64)            12352     \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 99, 64)            0         \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 99, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d_17 (MaxPoolin  (None, 49, 64)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_24 (Conv1D)          (None, 49, 128)           24704     \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 49, 128)           0         \n",
            "                                                                 \n",
            " conv1d_25 (Conv1D)          (None, 49, 128)           49280     \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 49, 128)           0         \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 49, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_18 (MaxPoolin  (None, 24, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                196672    \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 64)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 8)                 520       \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 292,968\n",
            "Trainable params: 292,968\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model5 = Sequential()\n",
        "\n",
        "model5.add(Conv1D(32, 3,padding='same',input_shape=(198,1)))        \n",
        "model5.add(Activation('relu'))\n",
        "model5.add(Conv1D(32, 3,padding='same'))        \n",
        "model5.add(Activation('relu'))\n",
        "model5.add(Dropout(0.1))\n",
        "model5.add(MaxPooling1D(pool_size=(2)))\n",
        "\n",
        "model5.add(Conv1D(64, 3,padding='same'))        \n",
        "model5.add(Activation('relu'))\n",
        "model5.add(Conv1D(64, 3,padding='same'))        \n",
        "model5.add(Activation('relu'))\n",
        "model5.add(Dropout(0.1))\n",
        "model5.add(MaxPooling1D(pool_size=(2)))\n",
        "\n",
        "model5.add(Conv1D(128, 3,padding='same'))        \n",
        "model5.add(Activation('relu'))\n",
        "model5.add(Conv1D(128, 3,padding='same'))        \n",
        "model5.add(Activation('relu'))\n",
        "model5.add(Dropout(0.1))\n",
        "model5.add(MaxPooling1D(pool_size=(2)))\n",
        "\n",
        "model5.add(Flatten())\n",
        "model5.add(Dense(64))                                                 \n",
        "model5.add(Activation('softmax'))\n",
        "model5.add(Dense(8))                                                 \n",
        "model5.add(Activation('softmax'))\n",
        "\n",
        "opt = optimizers.RMSprop(lr=0.0005, rho=0.9, epsilon=None, decay=0.0)\n",
        "model5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsO0sJCHRPvJ"
      },
      "outputs": [],
      "source": [
        "model5.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "svZ12PC9RU_y",
        "outputId": "1dabc692-eff4-4b7e-999c-aeb7f0bdd131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "371/371 [==============================] - 18s 44ms/step - loss: 1.9722 - accuracy: 0.2323 - val_loss: 1.9463 - val_accuracy: 0.2247\n",
            "Epoch 2/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 1.8961 - accuracy: 0.2499 - val_loss: 1.8624 - val_accuracy: 0.2922\n",
            "Epoch 3/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 1.8342 - accuracy: 0.3020 - val_loss: 1.8041 - val_accuracy: 0.2935\n",
            "Epoch 4/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.7916 - accuracy: 0.2954 - val_loss: 1.7662 - val_accuracy: 0.2959\n",
            "Epoch 5/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.7577 - accuracy: 0.2985 - val_loss: 1.7423 - val_accuracy: 0.2939\n",
            "Epoch 6/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.7277 - accuracy: 0.3034 - val_loss: 1.7275 - val_accuracy: 0.2922\n",
            "Epoch 7/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.7052 - accuracy: 0.3111 - val_loss: 1.6823 - val_accuracy: 0.3137\n",
            "Epoch 8/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 1.6800 - accuracy: 0.3205 - val_loss: 1.6673 - val_accuracy: 0.3266\n",
            "Epoch 9/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.6588 - accuracy: 0.3245 - val_loss: 1.6499 - val_accuracy: 0.3250\n",
            "Epoch 10/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.6364 - accuracy: 0.3332 - val_loss: 1.6356 - val_accuracy: 0.3351\n",
            "Epoch 11/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 1.6143 - accuracy: 0.3415 - val_loss: 1.6145 - val_accuracy: 0.3440\n",
            "Epoch 12/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.5969 - accuracy: 0.3468 - val_loss: 1.5931 - val_accuracy: 0.3436\n",
            "Epoch 13/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.5798 - accuracy: 0.3570 - val_loss: 1.5779 - val_accuracy: 0.3545\n",
            "Epoch 14/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.5629 - accuracy: 0.3574 - val_loss: 1.5631 - val_accuracy: 0.3642\n",
            "Epoch 15/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 1.5548 - accuracy: 0.3621 - val_loss: 1.5524 - val_accuracy: 0.3605\n",
            "Epoch 16/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.5380 - accuracy: 0.3729 - val_loss: 1.5386 - val_accuracy: 0.3650\n",
            "Epoch 17/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 1.5240 - accuracy: 0.3755 - val_loss: 1.5300 - val_accuracy: 0.3646\n",
            "Epoch 18/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.5083 - accuracy: 0.3780 - val_loss: 1.5411 - val_accuracy: 0.3452\n",
            "Epoch 19/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.4991 - accuracy: 0.3880 - val_loss: 1.5103 - val_accuracy: 0.3646\n",
            "Epoch 20/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.4869 - accuracy: 0.3883 - val_loss: 1.5089 - val_accuracy: 0.3703\n",
            "Epoch 21/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 1.4771 - accuracy: 0.3942 - val_loss: 1.4928 - val_accuracy: 0.3824\n",
            "Epoch 22/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 1.4614 - accuracy: 0.4047 - val_loss: 1.4897 - val_accuracy: 0.3844\n",
            "Epoch 23/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.4489 - accuracy: 0.4168 - val_loss: 1.4793 - val_accuracy: 0.3985\n",
            "Epoch 24/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.4339 - accuracy: 0.4220 - val_loss: 1.4756 - val_accuracy: 0.4062\n",
            "Epoch 25/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.4259 - accuracy: 0.4261 - val_loss: 1.4580 - val_accuracy: 0.4123\n",
            "Epoch 26/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.4104 - accuracy: 0.4288 - val_loss: 1.4478 - val_accuracy: 0.4099\n",
            "Epoch 27/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.3997 - accuracy: 0.4449 - val_loss: 1.4510 - val_accuracy: 0.4171\n",
            "Epoch 28/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 1.3869 - accuracy: 0.4460 - val_loss: 1.4690 - val_accuracy: 0.3989\n",
            "Epoch 29/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 1.3713 - accuracy: 0.4469 - val_loss: 1.4396 - val_accuracy: 0.4135\n",
            "Epoch 30/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.3593 - accuracy: 0.4557 - val_loss: 1.4423 - val_accuracy: 0.4038\n",
            "Epoch 31/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.3497 - accuracy: 0.4612 - val_loss: 1.4530 - val_accuracy: 0.4074\n",
            "Epoch 32/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.3366 - accuracy: 0.4709 - val_loss: 1.4356 - val_accuracy: 0.4159\n",
            "Epoch 33/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.3287 - accuracy: 0.4747 - val_loss: 1.4292 - val_accuracy: 0.4220\n",
            "Epoch 34/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.3185 - accuracy: 0.4739 - val_loss: 1.5174 - val_accuracy: 0.3913\n",
            "Epoch 35/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 1.3047 - accuracy: 0.4873 - val_loss: 1.4159 - val_accuracy: 0.4305\n",
            "Epoch 36/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.2884 - accuracy: 0.4931 - val_loss: 1.4267 - val_accuracy: 0.4406\n",
            "Epoch 37/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.2758 - accuracy: 0.4947 - val_loss: 1.4321 - val_accuracy: 0.4402\n",
            "Epoch 38/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.2650 - accuracy: 0.5039 - val_loss: 1.4443 - val_accuracy: 0.4317\n",
            "Epoch 39/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.2510 - accuracy: 0.5120 - val_loss: 1.4291 - val_accuracy: 0.4281\n",
            "Epoch 40/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.2410 - accuracy: 0.5173 - val_loss: 1.4182 - val_accuracy: 0.4406\n",
            "Epoch 41/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 1.2332 - accuracy: 0.5224 - val_loss: 1.4203 - val_accuracy: 0.4382\n",
            "Epoch 42/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 1.2151 - accuracy: 0.5274 - val_loss: 1.4232 - val_accuracy: 0.4301\n",
            "Epoch 43/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.2030 - accuracy: 0.5354 - val_loss: 1.4276 - val_accuracy: 0.4285\n",
            "Epoch 44/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.1917 - accuracy: 0.5381 - val_loss: 1.4054 - val_accuracy: 0.4418\n",
            "Epoch 45/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 1.1721 - accuracy: 0.5477 - val_loss: 1.4365 - val_accuracy: 0.4333\n",
            "Epoch 46/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.1606 - accuracy: 0.5566 - val_loss: 1.4549 - val_accuracy: 0.4357\n",
            "Epoch 47/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 1.1562 - accuracy: 0.5488 - val_loss: 1.4094 - val_accuracy: 0.4446\n",
            "Epoch 48/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 1.1375 - accuracy: 0.5663 - val_loss: 1.4317 - val_accuracy: 0.4458\n",
            "Epoch 49/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 1.1339 - accuracy: 0.5656 - val_loss: 1.4207 - val_accuracy: 0.4475\n",
            "Epoch 50/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 1.1295 - accuracy: 0.5629 - val_loss: 1.4222 - val_accuracy: 0.4519\n",
            "Epoch 51/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 1.1080 - accuracy: 0.5748 - val_loss: 1.4413 - val_accuracy: 0.4382\n",
            "Epoch 52/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 1.0954 - accuracy: 0.5852 - val_loss: 1.4339 - val_accuracy: 0.4394\n",
            "Epoch 53/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 1.0799 - accuracy: 0.5914 - val_loss: 1.4362 - val_accuracy: 0.4446\n",
            "Epoch 54/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 1.0708 - accuracy: 0.5922 - val_loss: 1.4101 - val_accuracy: 0.4499\n",
            "Epoch 55/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 1.0631 - accuracy: 0.5957 - val_loss: 1.4024 - val_accuracy: 0.4604\n",
            "Epoch 56/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 1.0380 - accuracy: 0.6074 - val_loss: 1.4615 - val_accuracy: 0.4483\n",
            "Epoch 57/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.0381 - accuracy: 0.6080 - val_loss: 1.4367 - val_accuracy: 0.4523\n",
            "Epoch 58/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 1.0319 - accuracy: 0.6136 - val_loss: 1.4410 - val_accuracy: 0.4422\n",
            "Epoch 59/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 1.0118 - accuracy: 0.6239 - val_loss: 1.4271 - val_accuracy: 0.4588\n",
            "Epoch 60/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.9981 - accuracy: 0.6264 - val_loss: 1.4597 - val_accuracy: 0.4507\n",
            "Epoch 61/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 0.9951 - accuracy: 0.6307 - val_loss: 1.4377 - val_accuracy: 0.4515\n",
            "Epoch 62/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.9794 - accuracy: 0.6403 - val_loss: 1.4579 - val_accuracy: 0.4487\n",
            "Epoch 63/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.9746 - accuracy: 0.6403 - val_loss: 1.4463 - val_accuracy: 0.4632\n",
            "Epoch 64/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.9538 - accuracy: 0.6493 - val_loss: 1.4578 - val_accuracy: 0.4624\n",
            "Epoch 65/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.9390 - accuracy: 0.6531 - val_loss: 1.4581 - val_accuracy: 0.4636\n",
            "Epoch 66/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.9346 - accuracy: 0.6589 - val_loss: 1.4520 - val_accuracy: 0.4636\n",
            "Epoch 67/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 0.9159 - accuracy: 0.6633 - val_loss: 1.4671 - val_accuracy: 0.4644\n",
            "Epoch 68/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.9141 - accuracy: 0.6613 - val_loss: 1.4634 - val_accuracy: 0.4693\n",
            "Epoch 69/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.9113 - accuracy: 0.6666 - val_loss: 1.4605 - val_accuracy: 0.4665\n",
            "Epoch 70/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.8962 - accuracy: 0.6759 - val_loss: 1.4710 - val_accuracy: 0.4628\n",
            "Epoch 71/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.8809 - accuracy: 0.6869 - val_loss: 1.4840 - val_accuracy: 0.4604\n",
            "Epoch 72/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.8709 - accuracy: 0.6865 - val_loss: 1.4719 - val_accuracy: 0.4665\n",
            "Epoch 73/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.8589 - accuracy: 0.6885 - val_loss: 1.4980 - val_accuracy: 0.4644\n",
            "Epoch 74/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 0.8539 - accuracy: 0.6910 - val_loss: 1.4783 - val_accuracy: 0.4523\n",
            "Epoch 75/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.8406 - accuracy: 0.6996 - val_loss: 1.5330 - val_accuracy: 0.4616\n",
            "Epoch 76/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.8288 - accuracy: 0.7034 - val_loss: 1.4847 - val_accuracy: 0.4685\n",
            "Epoch 77/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.8276 - accuracy: 0.7081 - val_loss: 1.5066 - val_accuracy: 0.4551\n",
            "Epoch 78/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.8089 - accuracy: 0.7132 - val_loss: 1.5212 - val_accuracy: 0.4632\n",
            "Epoch 79/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.8036 - accuracy: 0.7061 - val_loss: 1.5364 - val_accuracy: 0.4596\n",
            "Epoch 80/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.7947 - accuracy: 0.7199 - val_loss: 1.5226 - val_accuracy: 0.4559\n",
            "Epoch 81/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 0.7879 - accuracy: 0.7248 - val_loss: 1.5236 - val_accuracy: 0.4697\n",
            "Epoch 82/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.7797 - accuracy: 0.7216 - val_loss: 1.5295 - val_accuracy: 0.4705\n",
            "Epoch 83/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.7684 - accuracy: 0.7284 - val_loss: 1.5452 - val_accuracy: 0.4669\n",
            "Epoch 84/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.7559 - accuracy: 0.7327 - val_loss: 1.5380 - val_accuracy: 0.4559\n",
            "Epoch 85/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.7559 - accuracy: 0.7361 - val_loss: 1.5636 - val_accuracy: 0.4559\n",
            "Epoch 86/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.7414 - accuracy: 0.7429 - val_loss: 1.5619 - val_accuracy: 0.4568\n",
            "Epoch 87/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 0.7357 - accuracy: 0.7478 - val_loss: 1.5791 - val_accuracy: 0.4660\n",
            "Epoch 88/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.7439 - accuracy: 0.7388 - val_loss: 1.5405 - val_accuracy: 0.4729\n",
            "Epoch 89/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.7278 - accuracy: 0.7484 - val_loss: 1.5260 - val_accuracy: 0.4648\n",
            "Epoch 90/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.7167 - accuracy: 0.7531 - val_loss: 1.5727 - val_accuracy: 0.4705\n",
            "Epoch 91/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.7055 - accuracy: 0.7582 - val_loss: 1.6041 - val_accuracy: 0.4656\n",
            "Epoch 92/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.7202 - accuracy: 0.7501 - val_loss: 1.5739 - val_accuracy: 0.4592\n",
            "Epoch 93/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.6950 - accuracy: 0.7613 - val_loss: 1.5744 - val_accuracy: 0.4636\n",
            "Epoch 94/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.6937 - accuracy: 0.7635 - val_loss: 1.6383 - val_accuracy: 0.4608\n",
            "Epoch 95/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.6824 - accuracy: 0.7663 - val_loss: 1.5816 - val_accuracy: 0.4563\n",
            "Epoch 96/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.6710 - accuracy: 0.7655 - val_loss: 1.6122 - val_accuracy: 0.4705\n",
            "Epoch 97/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.6645 - accuracy: 0.7799 - val_loss: 1.5911 - val_accuracy: 0.4705\n",
            "Epoch 98/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.6528 - accuracy: 0.7834 - val_loss: 1.6129 - val_accuracy: 0.4677\n",
            "Epoch 99/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.6518 - accuracy: 0.7833 - val_loss: 1.6162 - val_accuracy: 0.4620\n",
            "Epoch 100/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 0.6539 - accuracy: 0.7741 - val_loss: 1.6556 - val_accuracy: 0.4644\n",
            "Epoch 101/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.6403 - accuracy: 0.7846 - val_loss: 1.6339 - val_accuracy: 0.4648\n",
            "Epoch 102/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.6229 - accuracy: 0.7867 - val_loss: 1.6753 - val_accuracy: 0.4519\n",
            "Epoch 103/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.6243 - accuracy: 0.7842 - val_loss: 1.6672 - val_accuracy: 0.4604\n",
            "Epoch 104/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.6162 - accuracy: 0.7903 - val_loss: 1.6436 - val_accuracy: 0.4673\n",
            "Epoch 105/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.6113 - accuracy: 0.7968 - val_loss: 1.6611 - val_accuracy: 0.4757\n",
            "Epoch 106/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 0.6115 - accuracy: 0.7927 - val_loss: 1.6451 - val_accuracy: 0.4628\n",
            "Epoch 107/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.6010 - accuracy: 0.7997 - val_loss: 1.6227 - val_accuracy: 0.4762\n",
            "Epoch 108/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.6046 - accuracy: 0.7918 - val_loss: 1.6347 - val_accuracy: 0.4648\n",
            "Epoch 109/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.5893 - accuracy: 0.8046 - val_loss: 1.6522 - val_accuracy: 0.4632\n",
            "Epoch 110/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.5902 - accuracy: 0.8030 - val_loss: 1.6297 - val_accuracy: 0.4685\n",
            "Epoch 111/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.5834 - accuracy: 0.8081 - val_loss: 1.6695 - val_accuracy: 0.4749\n",
            "Epoch 112/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.5688 - accuracy: 0.8077 - val_loss: 1.6556 - val_accuracy: 0.4822\n",
            "Epoch 113/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 0.5748 - accuracy: 0.8096 - val_loss: 1.6436 - val_accuracy: 0.4737\n",
            "Epoch 114/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.5628 - accuracy: 0.8135 - val_loss: 1.6961 - val_accuracy: 0.4717\n",
            "Epoch 115/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.5538 - accuracy: 0.8159 - val_loss: 1.7189 - val_accuracy: 0.4677\n",
            "Epoch 116/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.5556 - accuracy: 0.8199 - val_loss: 1.6871 - val_accuracy: 0.4753\n",
            "Epoch 117/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.5482 - accuracy: 0.8204 - val_loss: 1.6886 - val_accuracy: 0.4656\n",
            "Epoch 118/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.5399 - accuracy: 0.8209 - val_loss: 1.7132 - val_accuracy: 0.4701\n",
            "Epoch 119/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 0.5366 - accuracy: 0.8248 - val_loss: 1.6965 - val_accuracy: 0.4814\n",
            "Epoch 120/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.5342 - accuracy: 0.8236 - val_loss: 1.7062 - val_accuracy: 0.4834\n",
            "Epoch 121/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.5259 - accuracy: 0.8291 - val_loss: 1.7415 - val_accuracy: 0.4798\n",
            "Epoch 122/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.5167 - accuracy: 0.8326 - val_loss: 1.7366 - val_accuracy: 0.4612\n",
            "Epoch 123/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.5147 - accuracy: 0.8321 - val_loss: 1.7730 - val_accuracy: 0.4596\n",
            "Epoch 124/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.5077 - accuracy: 0.8349 - val_loss: 1.7533 - val_accuracy: 0.4749\n",
            "Epoch 125/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.5120 - accuracy: 0.8299 - val_loss: 1.7890 - val_accuracy: 0.4600\n",
            "Epoch 126/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 0.5083 - accuracy: 0.8311 - val_loss: 1.7630 - val_accuracy: 0.4782\n",
            "Epoch 127/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.5045 - accuracy: 0.8317 - val_loss: 1.7621 - val_accuracy: 0.4778\n",
            "Epoch 128/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4983 - accuracy: 0.8354 - val_loss: 1.7556 - val_accuracy: 0.4863\n",
            "Epoch 129/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.5051 - accuracy: 0.8334 - val_loss: 1.7250 - val_accuracy: 0.4786\n",
            "Epoch 130/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4870 - accuracy: 0.8439 - val_loss: 1.7847 - val_accuracy: 0.4794\n",
            "Epoch 131/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.4805 - accuracy: 0.8476 - val_loss: 1.8358 - val_accuracy: 0.4628\n",
            "Epoch 132/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 0.4728 - accuracy: 0.8429 - val_loss: 1.8229 - val_accuracy: 0.4753\n",
            "Epoch 133/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4708 - accuracy: 0.8473 - val_loss: 1.8153 - val_accuracy: 0.4648\n",
            "Epoch 134/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4683 - accuracy: 0.8507 - val_loss: 1.8067 - val_accuracy: 0.4709\n",
            "Epoch 135/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.4651 - accuracy: 0.8496 - val_loss: 1.8524 - val_accuracy: 0.4762\n",
            "Epoch 136/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4643 - accuracy: 0.8468 - val_loss: 1.8242 - val_accuracy: 0.4725\n",
            "Epoch 137/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4573 - accuracy: 0.8554 - val_loss: 1.8833 - val_accuracy: 0.4640\n",
            "Epoch 138/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 0.4553 - accuracy: 0.8516 - val_loss: 1.7968 - val_accuracy: 0.4786\n",
            "Epoch 139/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4557 - accuracy: 0.8518 - val_loss: 1.8186 - val_accuracy: 0.4741\n",
            "Epoch 140/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4517 - accuracy: 0.8526 - val_loss: 1.7932 - val_accuracy: 0.4774\n",
            "Epoch 141/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4294 - accuracy: 0.8620 - val_loss: 1.8282 - val_accuracy: 0.4697\n",
            "Epoch 142/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4526 - accuracy: 0.8505 - val_loss: 1.8609 - val_accuracy: 0.4673\n",
            "Epoch 143/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4500 - accuracy: 0.8570 - val_loss: 1.8380 - val_accuracy: 0.4790\n",
            "Epoch 144/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4307 - accuracy: 0.8650 - val_loss: 1.8202 - val_accuracy: 0.4850\n",
            "Epoch 145/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.4347 - accuracy: 0.8617 - val_loss: 1.8079 - val_accuracy: 0.4749\n",
            "Epoch 146/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4284 - accuracy: 0.8624 - val_loss: 1.8765 - val_accuracy: 0.4786\n",
            "Epoch 147/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4279 - accuracy: 0.8640 - val_loss: 1.8425 - val_accuracy: 0.4790\n",
            "Epoch 148/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4172 - accuracy: 0.8620 - val_loss: 1.8564 - val_accuracy: 0.4721\n",
            "Epoch 149/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4248 - accuracy: 0.8602 - val_loss: 1.8844 - val_accuracy: 0.4725\n",
            "Epoch 150/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4197 - accuracy: 0.8586 - val_loss: 1.8958 - val_accuracy: 0.4555\n",
            "Epoch 151/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.4145 - accuracy: 0.8683 - val_loss: 1.9182 - val_accuracy: 0.4640\n",
            "Epoch 152/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4154 - accuracy: 0.8693 - val_loss: 1.8657 - val_accuracy: 0.4762\n",
            "Epoch 153/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4131 - accuracy: 0.8695 - val_loss: 1.8307 - val_accuracy: 0.4762\n",
            "Epoch 154/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.4046 - accuracy: 0.8712 - val_loss: 1.9298 - val_accuracy: 0.4729\n",
            "Epoch 155/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3997 - accuracy: 0.8720 - val_loss: 1.8429 - val_accuracy: 0.4802\n",
            "Epoch 156/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3941 - accuracy: 0.8745 - val_loss: 1.9247 - val_accuracy: 0.4640\n",
            "Epoch 157/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.3906 - accuracy: 0.8721 - val_loss: 1.9055 - val_accuracy: 0.4749\n",
            "Epoch 158/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3787 - accuracy: 0.8815 - val_loss: 1.9301 - val_accuracy: 0.4596\n",
            "Epoch 159/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.4004 - accuracy: 0.8726 - val_loss: 1.8732 - val_accuracy: 0.4733\n",
            "Epoch 160/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3752 - accuracy: 0.8834 - val_loss: 1.9601 - val_accuracy: 0.4814\n",
            "Epoch 161/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3790 - accuracy: 0.8757 - val_loss: 1.9339 - val_accuracy: 0.4741\n",
            "Epoch 162/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3758 - accuracy: 0.8810 - val_loss: 1.9449 - val_accuracy: 0.4632\n",
            "Epoch 163/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.3812 - accuracy: 0.8763 - val_loss: 1.9534 - val_accuracy: 0.4677\n",
            "Epoch 164/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3765 - accuracy: 0.8813 - val_loss: 1.9244 - val_accuracy: 0.4697\n",
            "Epoch 165/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3775 - accuracy: 0.8729 - val_loss: 1.9803 - val_accuracy: 0.4753\n",
            "Epoch 166/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3727 - accuracy: 0.8822 - val_loss: 1.9003 - val_accuracy: 0.4709\n",
            "Epoch 167/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3607 - accuracy: 0.8834 - val_loss: 1.9534 - val_accuracy: 0.4806\n",
            "Epoch 168/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3630 - accuracy: 0.8836 - val_loss: 1.9576 - val_accuracy: 0.4741\n",
            "Epoch 169/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3742 - accuracy: 0.8786 - val_loss: 1.9146 - val_accuracy: 0.4830\n",
            "Epoch 170/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.3584 - accuracy: 0.8863 - val_loss: 1.9822 - val_accuracy: 0.4749\n",
            "Epoch 171/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3638 - accuracy: 0.8863 - val_loss: 2.0057 - val_accuracy: 0.4798\n",
            "Epoch 172/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3568 - accuracy: 0.8867 - val_loss: 2.0221 - val_accuracy: 0.4689\n",
            "Epoch 173/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.3587 - accuracy: 0.8888 - val_loss: 1.9802 - val_accuracy: 0.4713\n",
            "Epoch 174/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3547 - accuracy: 0.8873 - val_loss: 2.0173 - val_accuracy: 0.4766\n",
            "Epoch 175/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3514 - accuracy: 0.8885 - val_loss: 2.0187 - val_accuracy: 0.4733\n",
            "Epoch 176/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.3411 - accuracy: 0.8908 - val_loss: 2.0524 - val_accuracy: 0.4749\n",
            "Epoch 177/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.3290 - accuracy: 0.8946 - val_loss: 2.0794 - val_accuracy: 0.4685\n",
            "Epoch 178/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3472 - accuracy: 0.8914 - val_loss: 1.9964 - val_accuracy: 0.4749\n",
            "Epoch 179/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.3337 - accuracy: 0.8941 - val_loss: 2.0057 - val_accuracy: 0.4822\n",
            "Epoch 180/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3349 - accuracy: 0.8947 - val_loss: 1.9741 - val_accuracy: 0.4826\n",
            "Epoch 181/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.3427 - accuracy: 0.8938 - val_loss: 2.0271 - val_accuracy: 0.4689\n",
            "Epoch 182/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.3371 - accuracy: 0.8939 - val_loss: 2.0184 - val_accuracy: 0.4705\n",
            "Epoch 183/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3487 - accuracy: 0.8912 - val_loss: 2.0813 - val_accuracy: 0.4749\n",
            "Epoch 184/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.3268 - accuracy: 0.8988 - val_loss: 2.0029 - val_accuracy: 0.4790\n",
            "Epoch 185/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3302 - accuracy: 0.8991 - val_loss: 1.9861 - val_accuracy: 0.4741\n",
            "Epoch 186/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3296 - accuracy: 0.8941 - val_loss: 2.0896 - val_accuracy: 0.4665\n",
            "Epoch 187/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3206 - accuracy: 0.8992 - val_loss: 2.0567 - val_accuracy: 0.4656\n",
            "Epoch 188/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.3224 - accuracy: 0.8946 - val_loss: 2.0583 - val_accuracy: 0.4717\n",
            "Epoch 189/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3209 - accuracy: 0.8989 - val_loss: 2.0564 - val_accuracy: 0.4717\n",
            "Epoch 190/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3246 - accuracy: 0.8993 - val_loss: 2.0175 - val_accuracy: 0.4717\n",
            "Epoch 191/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3241 - accuracy: 0.8989 - val_loss: 2.0491 - val_accuracy: 0.4810\n",
            "Epoch 192/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.3177 - accuracy: 0.8985 - val_loss: 1.9922 - val_accuracy: 0.4689\n",
            "Epoch 193/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3093 - accuracy: 0.9047 - val_loss: 2.0326 - val_accuracy: 0.4628\n",
            "Epoch 194/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.3212 - accuracy: 0.8961 - val_loss: 2.1044 - val_accuracy: 0.4636\n",
            "Epoch 195/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3168 - accuracy: 0.8995 - val_loss: 2.0903 - val_accuracy: 0.4806\n",
            "Epoch 196/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.3146 - accuracy: 0.9004 - val_loss: 2.1004 - val_accuracy: 0.4802\n",
            "Epoch 197/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3124 - accuracy: 0.9022 - val_loss: 2.1039 - val_accuracy: 0.4616\n",
            "Epoch 198/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.3153 - accuracy: 0.9009 - val_loss: 2.1008 - val_accuracy: 0.4628\n",
            "Epoch 199/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3232 - accuracy: 0.9000 - val_loss: 2.1828 - val_accuracy: 0.4588\n",
            "Epoch 200/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.3058 - accuracy: 0.9018 - val_loss: 2.0843 - val_accuracy: 0.4741\n",
            "Epoch 201/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.3100 - accuracy: 0.9012 - val_loss: 2.0914 - val_accuracy: 0.4656\n",
            "Epoch 202/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.3150 - accuracy: 0.9005 - val_loss: 2.0674 - val_accuracy: 0.4770\n",
            "Epoch 203/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3078 - accuracy: 0.9001 - val_loss: 2.1084 - val_accuracy: 0.4818\n",
            "Epoch 204/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2976 - accuracy: 0.9016 - val_loss: 2.1421 - val_accuracy: 0.4701\n",
            "Epoch 205/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2853 - accuracy: 0.9097 - val_loss: 2.1626 - val_accuracy: 0.4600\n",
            "Epoch 206/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.2947 - accuracy: 0.9071 - val_loss: 2.1362 - val_accuracy: 0.4794\n",
            "Epoch 207/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3196 - accuracy: 0.8943 - val_loss: 2.1244 - val_accuracy: 0.4737\n",
            "Epoch 208/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.3031 - accuracy: 0.9040 - val_loss: 2.0973 - val_accuracy: 0.4745\n",
            "Epoch 209/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2946 - accuracy: 0.9082 - val_loss: 2.1482 - val_accuracy: 0.4762\n",
            "Epoch 210/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.3081 - accuracy: 0.9022 - val_loss: 2.1507 - val_accuracy: 0.4818\n",
            "Epoch 211/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.3017 - accuracy: 0.9022 - val_loss: 2.1075 - val_accuracy: 0.4665\n",
            "Epoch 212/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.2873 - accuracy: 0.9102 - val_loss: 2.1140 - val_accuracy: 0.4689\n",
            "Epoch 213/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2964 - accuracy: 0.9069 - val_loss: 2.1503 - val_accuracy: 0.4644\n",
            "Epoch 214/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.3050 - accuracy: 0.9012 - val_loss: 2.2082 - val_accuracy: 0.4644\n",
            "Epoch 215/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2919 - accuracy: 0.9081 - val_loss: 2.1868 - val_accuracy: 0.4689\n",
            "Epoch 216/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2920 - accuracy: 0.9059 - val_loss: 2.1859 - val_accuracy: 0.4523\n",
            "Epoch 217/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2683 - accuracy: 0.9160 - val_loss: 2.1924 - val_accuracy: 0.4660\n",
            "Epoch 218/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.2894 - accuracy: 0.9080 - val_loss: 2.1714 - val_accuracy: 0.4660\n",
            "Epoch 219/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2800 - accuracy: 0.9092 - val_loss: 2.1373 - val_accuracy: 0.4806\n",
            "Epoch 220/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2946 - accuracy: 0.9032 - val_loss: 2.1609 - val_accuracy: 0.4721\n",
            "Epoch 221/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2882 - accuracy: 0.9066 - val_loss: 2.1689 - val_accuracy: 0.4729\n",
            "Epoch 222/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2831 - accuracy: 0.9070 - val_loss: 2.1801 - val_accuracy: 0.4770\n",
            "Epoch 223/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2808 - accuracy: 0.9106 - val_loss: 2.1067 - val_accuracy: 0.4794\n",
            "Epoch 224/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.2918 - accuracy: 0.9085 - val_loss: 2.1593 - val_accuracy: 0.4838\n",
            "Epoch 225/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2911 - accuracy: 0.9062 - val_loss: 2.2179 - val_accuracy: 0.4721\n",
            "Epoch 226/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2871 - accuracy: 0.9074 - val_loss: 2.1304 - val_accuracy: 0.4733\n",
            "Epoch 227/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2679 - accuracy: 0.9109 - val_loss: 2.2129 - val_accuracy: 0.4624\n",
            "Epoch 228/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2614 - accuracy: 0.9163 - val_loss: 2.2229 - val_accuracy: 0.4656\n",
            "Epoch 229/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2700 - accuracy: 0.9162 - val_loss: 2.1813 - val_accuracy: 0.4693\n",
            "Epoch 230/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.2880 - accuracy: 0.9075 - val_loss: 2.1956 - val_accuracy: 0.4580\n",
            "Epoch 231/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2774 - accuracy: 0.9098 - val_loss: 2.2703 - val_accuracy: 0.4673\n",
            "Epoch 232/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2718 - accuracy: 0.9146 - val_loss: 2.1657 - val_accuracy: 0.4863\n",
            "Epoch 233/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2888 - accuracy: 0.9062 - val_loss: 2.2028 - val_accuracy: 0.4729\n",
            "Epoch 234/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2800 - accuracy: 0.9097 - val_loss: 2.2450 - val_accuracy: 0.4725\n",
            "Epoch 235/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2786 - accuracy: 0.9124 - val_loss: 2.2026 - val_accuracy: 0.4766\n",
            "Epoch 236/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.2725 - accuracy: 0.9074 - val_loss: 2.1453 - val_accuracy: 0.4669\n",
            "Epoch 237/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2745 - accuracy: 0.9113 - val_loss: 2.2139 - val_accuracy: 0.4762\n",
            "Epoch 238/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2809 - accuracy: 0.9136 - val_loss: 2.2872 - val_accuracy: 0.4697\n",
            "Epoch 239/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2641 - accuracy: 0.9135 - val_loss: 2.1669 - val_accuracy: 0.4778\n",
            "Epoch 240/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2688 - accuracy: 0.9129 - val_loss: 2.1949 - val_accuracy: 0.4826\n",
            "Epoch 241/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2618 - accuracy: 0.9171 - val_loss: 2.1997 - val_accuracy: 0.4721\n",
            "Epoch 242/500\n",
            "371/371 [==============================] - 17s 46ms/step - loss: 0.2699 - accuracy: 0.9136 - val_loss: 2.3648 - val_accuracy: 0.4721\n",
            "Epoch 243/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2773 - accuracy: 0.9120 - val_loss: 2.2054 - val_accuracy: 0.4802\n",
            "Epoch 244/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2582 - accuracy: 0.9150 - val_loss: 2.2918 - val_accuracy: 0.4620\n",
            "Epoch 245/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2633 - accuracy: 0.9160 - val_loss: 2.3035 - val_accuracy: 0.4741\n",
            "Epoch 246/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2640 - accuracy: 0.9120 - val_loss: 2.2707 - val_accuracy: 0.4697\n",
            "Epoch 247/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2636 - accuracy: 0.9131 - val_loss: 2.2378 - val_accuracy: 0.4644\n",
            "Epoch 248/500\n",
            "371/371 [==============================] - 18s 48ms/step - loss: 0.2498 - accuracy: 0.9204 - val_loss: 2.2155 - val_accuracy: 0.4652\n",
            "Epoch 249/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2595 - accuracy: 0.9175 - val_loss: 2.2725 - val_accuracy: 0.4782\n",
            "Epoch 250/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2575 - accuracy: 0.9174 - val_loss: 2.2286 - val_accuracy: 0.4782\n",
            "Epoch 251/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2634 - accuracy: 0.9159 - val_loss: 2.2413 - val_accuracy: 0.4766\n",
            "Epoch 252/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2678 - accuracy: 0.9143 - val_loss: 2.2828 - val_accuracy: 0.4770\n",
            "Epoch 253/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2614 - accuracy: 0.9159 - val_loss: 2.3175 - val_accuracy: 0.4701\n",
            "Epoch 254/500\n",
            "371/371 [==============================] - 18s 48ms/step - loss: 0.2562 - accuracy: 0.9168 - val_loss: 2.2527 - val_accuracy: 0.4762\n",
            "Epoch 255/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2566 - accuracy: 0.9185 - val_loss: 2.3022 - val_accuracy: 0.4717\n",
            "Epoch 256/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2541 - accuracy: 0.9159 - val_loss: 2.2275 - val_accuracy: 0.4749\n",
            "Epoch 257/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2627 - accuracy: 0.9158 - val_loss: 2.2127 - val_accuracy: 0.4737\n",
            "Epoch 258/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2697 - accuracy: 0.9116 - val_loss: 2.2111 - val_accuracy: 0.4729\n",
            "Epoch 259/500\n",
            "371/371 [==============================] - 17s 47ms/step - loss: 0.2549 - accuracy: 0.9148 - val_loss: 2.3084 - val_accuracy: 0.4709\n",
            "Epoch 260/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2635 - accuracy: 0.9181 - val_loss: 2.2520 - val_accuracy: 0.4656\n",
            "Epoch 261/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2592 - accuracy: 0.9156 - val_loss: 2.3689 - val_accuracy: 0.4757\n",
            "Epoch 262/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2587 - accuracy: 0.9185 - val_loss: 2.2755 - val_accuracy: 0.4669\n",
            "Epoch 263/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2615 - accuracy: 0.9143 - val_loss: 2.2907 - val_accuracy: 0.4741\n",
            "Epoch 264/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2613 - accuracy: 0.9150 - val_loss: 2.2268 - val_accuracy: 0.4741\n",
            "Epoch 265/500\n",
            "371/371 [==============================] - 17s 47ms/step - loss: 0.2531 - accuracy: 0.9206 - val_loss: 2.4200 - val_accuracy: 0.4608\n",
            "Epoch 266/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2468 - accuracy: 0.9201 - val_loss: 2.2642 - val_accuracy: 0.4709\n",
            "Epoch 267/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2434 - accuracy: 0.9228 - val_loss: 2.2782 - val_accuracy: 0.4709\n",
            "Epoch 268/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2517 - accuracy: 0.9162 - val_loss: 2.2586 - val_accuracy: 0.4778\n",
            "Epoch 269/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2645 - accuracy: 0.9136 - val_loss: 2.2984 - val_accuracy: 0.4584\n",
            "Epoch 270/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2522 - accuracy: 0.9177 - val_loss: 2.3827 - val_accuracy: 0.4685\n",
            "Epoch 271/500\n",
            "371/371 [==============================] - 18s 47ms/step - loss: 0.2562 - accuracy: 0.9160 - val_loss: 2.2781 - val_accuracy: 0.4733\n",
            "Epoch 272/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2450 - accuracy: 0.9248 - val_loss: 2.3406 - val_accuracy: 0.4745\n",
            "Epoch 273/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2485 - accuracy: 0.9197 - val_loss: 2.3317 - val_accuracy: 0.4806\n",
            "Epoch 274/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2627 - accuracy: 0.9159 - val_loss: 2.3776 - val_accuracy: 0.4592\n",
            "Epoch 275/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2462 - accuracy: 0.9241 - val_loss: 2.2886 - val_accuracy: 0.4701\n",
            "Epoch 276/500\n",
            "371/371 [==============================] - 18s 48ms/step - loss: 0.2546 - accuracy: 0.9189 - val_loss: 2.2922 - val_accuracy: 0.4737\n",
            "Epoch 277/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2415 - accuracy: 0.9204 - val_loss: 2.3435 - val_accuracy: 0.4648\n",
            "Epoch 278/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2470 - accuracy: 0.9213 - val_loss: 2.3200 - val_accuracy: 0.4697\n",
            "Epoch 279/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2515 - accuracy: 0.9218 - val_loss: 2.4020 - val_accuracy: 0.4741\n",
            "Epoch 280/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2462 - accuracy: 0.9225 - val_loss: 2.3501 - val_accuracy: 0.4697\n",
            "Epoch 281/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2570 - accuracy: 0.9185 - val_loss: 2.2953 - val_accuracy: 0.4778\n",
            "Epoch 282/500\n",
            "371/371 [==============================] - 18s 47ms/step - loss: 0.2351 - accuracy: 0.9236 - val_loss: 2.2990 - val_accuracy: 0.4757\n",
            "Epoch 283/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2544 - accuracy: 0.9191 - val_loss: 2.3445 - val_accuracy: 0.4741\n",
            "Epoch 284/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2412 - accuracy: 0.9216 - val_loss: 2.2858 - val_accuracy: 0.4818\n",
            "Epoch 285/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2394 - accuracy: 0.9205 - val_loss: 2.4336 - val_accuracy: 0.4806\n",
            "Epoch 286/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2447 - accuracy: 0.9228 - val_loss: 2.3763 - val_accuracy: 0.4806\n",
            "Epoch 287/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2425 - accuracy: 0.9210 - val_loss: 2.3569 - val_accuracy: 0.4854\n",
            "Epoch 288/500\n",
            "371/371 [==============================] - 18s 48ms/step - loss: 0.2351 - accuracy: 0.9249 - val_loss: 2.3407 - val_accuracy: 0.4794\n",
            "Epoch 289/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2428 - accuracy: 0.9218 - val_loss: 2.4164 - val_accuracy: 0.4685\n",
            "Epoch 290/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2543 - accuracy: 0.9206 - val_loss: 2.3295 - val_accuracy: 0.4802\n",
            "Epoch 291/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2400 - accuracy: 0.9217 - val_loss: 2.3500 - val_accuracy: 0.4814\n",
            "Epoch 292/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 0.2403 - accuracy: 0.9251 - val_loss: 2.3521 - val_accuracy: 0.4806\n",
            "Epoch 293/500\n",
            "371/371 [==============================] - 18s 48ms/step - loss: 0.2313 - accuracy: 0.9256 - val_loss: 2.3518 - val_accuracy: 0.4689\n",
            "Epoch 294/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2512 - accuracy: 0.9178 - val_loss: 2.4007 - val_accuracy: 0.4806\n",
            "Epoch 295/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2426 - accuracy: 0.9226 - val_loss: 2.2619 - val_accuracy: 0.4826\n",
            "Epoch 296/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2387 - accuracy: 0.9235 - val_loss: 2.3151 - val_accuracy: 0.4737\n",
            "Epoch 297/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2459 - accuracy: 0.9216 - val_loss: 2.3300 - val_accuracy: 0.4782\n",
            "Epoch 298/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2313 - accuracy: 0.9259 - val_loss: 2.3636 - val_accuracy: 0.4782\n",
            "Epoch 299/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 0.2419 - accuracy: 0.9226 - val_loss: 2.4287 - val_accuracy: 0.4725\n",
            "Epoch 300/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2307 - accuracy: 0.9286 - val_loss: 2.3967 - val_accuracy: 0.4677\n",
            "Epoch 301/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2480 - accuracy: 0.9206 - val_loss: 2.5189 - val_accuracy: 0.4737\n",
            "Epoch 302/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2466 - accuracy: 0.9204 - val_loss: 2.5251 - val_accuracy: 0.4628\n",
            "Epoch 303/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2340 - accuracy: 0.9272 - val_loss: 2.4460 - val_accuracy: 0.4709\n",
            "Epoch 304/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2252 - accuracy: 0.9275 - val_loss: 2.4597 - val_accuracy: 0.4640\n",
            "Epoch 305/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2384 - accuracy: 0.9268 - val_loss: 2.4971 - val_accuracy: 0.4713\n",
            "Epoch 306/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2510 - accuracy: 0.9162 - val_loss: 2.4251 - val_accuracy: 0.4685\n",
            "Epoch 307/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2479 - accuracy: 0.9214 - val_loss: 2.3962 - val_accuracy: 0.4766\n",
            "Epoch 308/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2371 - accuracy: 0.9252 - val_loss: 2.4607 - val_accuracy: 0.4665\n",
            "Epoch 309/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2453 - accuracy: 0.9210 - val_loss: 2.4610 - val_accuracy: 0.4681\n",
            "Epoch 310/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2435 - accuracy: 0.9209 - val_loss: 2.4928 - val_accuracy: 0.4733\n",
            "Epoch 311/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2391 - accuracy: 0.9201 - val_loss: 2.4249 - val_accuracy: 0.4677\n",
            "Epoch 312/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2405 - accuracy: 0.9214 - val_loss: 2.3693 - val_accuracy: 0.4677\n",
            "Epoch 313/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2506 - accuracy: 0.9229 - val_loss: 2.3945 - val_accuracy: 0.4677\n",
            "Epoch 314/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2380 - accuracy: 0.9241 - val_loss: 2.4515 - val_accuracy: 0.4757\n",
            "Epoch 315/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2414 - accuracy: 0.9239 - val_loss: 2.4879 - val_accuracy: 0.4665\n",
            "Epoch 316/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2388 - accuracy: 0.9267 - val_loss: 2.3989 - val_accuracy: 0.4854\n",
            "Epoch 317/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2368 - accuracy: 0.9260 - val_loss: 2.5566 - val_accuracy: 0.4580\n",
            "Epoch 318/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2261 - accuracy: 0.9244 - val_loss: 2.4551 - val_accuracy: 0.4770\n",
            "Epoch 319/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2378 - accuracy: 0.9226 - val_loss: 2.3669 - val_accuracy: 0.4794\n",
            "Epoch 320/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2378 - accuracy: 0.9241 - val_loss: 2.4070 - val_accuracy: 0.4733\n",
            "Epoch 321/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2261 - accuracy: 0.9294 - val_loss: 2.4466 - val_accuracy: 0.4725\n",
            "Epoch 322/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2360 - accuracy: 0.9259 - val_loss: 2.5227 - val_accuracy: 0.4697\n",
            "Epoch 323/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2479 - accuracy: 0.9216 - val_loss: 2.5102 - val_accuracy: 0.4636\n",
            "Epoch 324/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2221 - accuracy: 0.9294 - val_loss: 2.5158 - val_accuracy: 0.4745\n",
            "Epoch 325/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2417 - accuracy: 0.9264 - val_loss: 2.4103 - val_accuracy: 0.4705\n",
            "Epoch 326/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2206 - accuracy: 0.9314 - val_loss: 2.4209 - val_accuracy: 0.4770\n",
            "Epoch 327/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2390 - accuracy: 0.9237 - val_loss: 2.4556 - val_accuracy: 0.4798\n",
            "Epoch 328/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2252 - accuracy: 0.9260 - val_loss: 2.4755 - val_accuracy: 0.4818\n",
            "Epoch 329/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2332 - accuracy: 0.9287 - val_loss: 2.5749 - val_accuracy: 0.4685\n",
            "Epoch 330/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2246 - accuracy: 0.9298 - val_loss: 2.5619 - val_accuracy: 0.4774\n",
            "Epoch 331/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2299 - accuracy: 0.9280 - val_loss: 2.5108 - val_accuracy: 0.4766\n",
            "Epoch 332/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2406 - accuracy: 0.9239 - val_loss: 2.4230 - val_accuracy: 0.4766\n",
            "Epoch 333/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2328 - accuracy: 0.9247 - val_loss: 2.6297 - val_accuracy: 0.4766\n",
            "Epoch 334/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2460 - accuracy: 0.9224 - val_loss: 2.5611 - val_accuracy: 0.4701\n",
            "Epoch 335/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2363 - accuracy: 0.9249 - val_loss: 2.5354 - val_accuracy: 0.4705\n",
            "Epoch 336/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2398 - accuracy: 0.9243 - val_loss: 2.5785 - val_accuracy: 0.4612\n",
            "Epoch 337/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2422 - accuracy: 0.9248 - val_loss: 2.5248 - val_accuracy: 0.4798\n",
            "Epoch 338/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2417 - accuracy: 0.9237 - val_loss: 2.4238 - val_accuracy: 0.4721\n",
            "Epoch 339/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2363 - accuracy: 0.9279 - val_loss: 2.5308 - val_accuracy: 0.4725\n",
            "Epoch 340/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2408 - accuracy: 0.9229 - val_loss: 2.5777 - val_accuracy: 0.4717\n",
            "Epoch 341/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2365 - accuracy: 0.9232 - val_loss: 2.5646 - val_accuracy: 0.4741\n",
            "Epoch 342/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2235 - accuracy: 0.9251 - val_loss: 2.6059 - val_accuracy: 0.4737\n",
            "Epoch 343/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2360 - accuracy: 0.9260 - val_loss: 2.5785 - val_accuracy: 0.4656\n",
            "Epoch 344/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2303 - accuracy: 0.9235 - val_loss: 2.4928 - val_accuracy: 0.4786\n",
            "Epoch 345/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2292 - accuracy: 0.9261 - val_loss: 2.5849 - val_accuracy: 0.4568\n",
            "Epoch 346/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2360 - accuracy: 0.9249 - val_loss: 2.4800 - val_accuracy: 0.4685\n",
            "Epoch 347/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2407 - accuracy: 0.9255 - val_loss: 2.5523 - val_accuracy: 0.4665\n",
            "Epoch 348/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2227 - accuracy: 0.9291 - val_loss: 2.5496 - val_accuracy: 0.4697\n",
            "Epoch 349/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2240 - accuracy: 0.9274 - val_loss: 2.4577 - val_accuracy: 0.4838\n",
            "Epoch 350/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2347 - accuracy: 0.9257 - val_loss: 2.5860 - val_accuracy: 0.4725\n",
            "Epoch 351/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2180 - accuracy: 0.9302 - val_loss: 2.5447 - val_accuracy: 0.4838\n",
            "Epoch 352/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2284 - accuracy: 0.9271 - val_loss: 2.5684 - val_accuracy: 0.4721\n",
            "Epoch 353/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2463 - accuracy: 0.9204 - val_loss: 2.6906 - val_accuracy: 0.4737\n",
            "Epoch 354/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2287 - accuracy: 0.9302 - val_loss: 2.7324 - val_accuracy: 0.4721\n",
            "Epoch 355/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2335 - accuracy: 0.9276 - val_loss: 2.6535 - val_accuracy: 0.4612\n",
            "Epoch 356/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2439 - accuracy: 0.9244 - val_loss: 2.6934 - val_accuracy: 0.4669\n",
            "Epoch 357/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2541 - accuracy: 0.9204 - val_loss: 2.7190 - val_accuracy: 0.4665\n",
            "Epoch 358/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2408 - accuracy: 0.9255 - val_loss: 2.6435 - val_accuracy: 0.4709\n",
            "Epoch 359/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2341 - accuracy: 0.9260 - val_loss: 2.6335 - val_accuracy: 0.4681\n",
            "Epoch 360/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2422 - accuracy: 0.9243 - val_loss: 2.5673 - val_accuracy: 0.4689\n",
            "Epoch 361/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2489 - accuracy: 0.9212 - val_loss: 2.6662 - val_accuracy: 0.4681\n",
            "Epoch 362/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2344 - accuracy: 0.9244 - val_loss: 2.6952 - val_accuracy: 0.4596\n",
            "Epoch 363/500\n",
            "371/371 [==============================] - 16s 43ms/step - loss: 0.2274 - accuracy: 0.9276 - val_loss: 2.5799 - val_accuracy: 0.4665\n",
            "Epoch 364/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2319 - accuracy: 0.9247 - val_loss: 2.6609 - val_accuracy: 0.4709\n",
            "Epoch 365/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2295 - accuracy: 0.9290 - val_loss: 2.6292 - val_accuracy: 0.4677\n",
            "Epoch 366/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2501 - accuracy: 0.9249 - val_loss: 2.6003 - val_accuracy: 0.4867\n",
            "Epoch 367/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2338 - accuracy: 0.9241 - val_loss: 2.5483 - val_accuracy: 0.4871\n",
            "Epoch 368/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2184 - accuracy: 0.9309 - val_loss: 2.6366 - val_accuracy: 0.4665\n",
            "Epoch 369/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2334 - accuracy: 0.9261 - val_loss: 2.6541 - val_accuracy: 0.4665\n",
            "Epoch 370/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2377 - accuracy: 0.9264 - val_loss: 2.5542 - val_accuracy: 0.4737\n",
            "Epoch 371/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2375 - accuracy: 0.9240 - val_loss: 2.7305 - val_accuracy: 0.4677\n",
            "Epoch 372/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2241 - accuracy: 0.9272 - val_loss: 2.6404 - val_accuracy: 0.4632\n",
            "Epoch 373/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2460 - accuracy: 0.9228 - val_loss: 2.5973 - val_accuracy: 0.4608\n",
            "Epoch 374/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2339 - accuracy: 0.9237 - val_loss: 2.6425 - val_accuracy: 0.4721\n",
            "Epoch 375/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2418 - accuracy: 0.9247 - val_loss: 2.6637 - val_accuracy: 0.4539\n",
            "Epoch 376/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2415 - accuracy: 0.9244 - val_loss: 2.6981 - val_accuracy: 0.4648\n",
            "Epoch 377/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2539 - accuracy: 0.9178 - val_loss: 2.5914 - val_accuracy: 0.4770\n",
            "Epoch 378/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2447 - accuracy: 0.9213 - val_loss: 2.6656 - val_accuracy: 0.4656\n",
            "Epoch 379/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2493 - accuracy: 0.9228 - val_loss: 2.7087 - val_accuracy: 0.4600\n",
            "Epoch 380/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2316 - accuracy: 0.9232 - val_loss: 2.6217 - val_accuracy: 0.4673\n",
            "Epoch 381/500\n",
            "371/371 [==============================] - 17s 45ms/step - loss: 0.2266 - accuracy: 0.9302 - val_loss: 2.7180 - val_accuracy: 0.4685\n",
            "Epoch 382/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2311 - accuracy: 0.9260 - val_loss: 2.6824 - val_accuracy: 0.4608\n",
            "Epoch 383/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2386 - accuracy: 0.9267 - val_loss: 2.6524 - val_accuracy: 0.4701\n",
            "Epoch 384/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2320 - accuracy: 0.9282 - val_loss: 2.6899 - val_accuracy: 0.4656\n",
            "Epoch 385/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2395 - accuracy: 0.9253 - val_loss: 2.7564 - val_accuracy: 0.4693\n",
            "Epoch 386/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2558 - accuracy: 0.9220 - val_loss: 2.6562 - val_accuracy: 0.4620\n",
            "Epoch 387/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2355 - accuracy: 0.9263 - val_loss: 2.7655 - val_accuracy: 0.4580\n",
            "Epoch 388/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2331 - accuracy: 0.9259 - val_loss: 2.7345 - val_accuracy: 0.4749\n",
            "Epoch 389/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2519 - accuracy: 0.9197 - val_loss: 2.6902 - val_accuracy: 0.4693\n",
            "Epoch 390/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2391 - accuracy: 0.9232 - val_loss: 2.7092 - val_accuracy: 0.4717\n",
            "Epoch 391/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2316 - accuracy: 0.9261 - val_loss: 2.7719 - val_accuracy: 0.4701\n",
            "Epoch 392/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2393 - accuracy: 0.9228 - val_loss: 2.6298 - val_accuracy: 0.4620\n",
            "Epoch 393/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2541 - accuracy: 0.9208 - val_loss: 2.6905 - val_accuracy: 0.4644\n",
            "Epoch 394/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2467 - accuracy: 0.9222 - val_loss: 2.8024 - val_accuracy: 0.4600\n",
            "Epoch 395/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2549 - accuracy: 0.9216 - val_loss: 2.7347 - val_accuracy: 0.4652\n",
            "Epoch 396/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2538 - accuracy: 0.9202 - val_loss: 2.7038 - val_accuracy: 0.4673\n",
            "Epoch 397/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2251 - accuracy: 0.9282 - val_loss: 2.6855 - val_accuracy: 0.4725\n",
            "Epoch 398/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2353 - accuracy: 0.9276 - val_loss: 2.7176 - val_accuracy: 0.4656\n",
            "Epoch 399/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2320 - accuracy: 0.9288 - val_loss: 2.7759 - val_accuracy: 0.4572\n",
            "Epoch 400/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2463 - accuracy: 0.9217 - val_loss: 2.7372 - val_accuracy: 0.4648\n",
            "Epoch 401/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2266 - accuracy: 0.9261 - val_loss: 2.7736 - val_accuracy: 0.4628\n",
            "Epoch 402/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2348 - accuracy: 0.9257 - val_loss: 2.8217 - val_accuracy: 0.4576\n",
            "Epoch 403/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2513 - accuracy: 0.9206 - val_loss: 2.7849 - val_accuracy: 0.4568\n",
            "Epoch 404/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2348 - accuracy: 0.9268 - val_loss: 2.7090 - val_accuracy: 0.4673\n",
            "Epoch 405/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2406 - accuracy: 0.9241 - val_loss: 2.7937 - val_accuracy: 0.4640\n",
            "Epoch 406/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2536 - accuracy: 0.9209 - val_loss: 2.7220 - val_accuracy: 0.4596\n",
            "Epoch 407/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2435 - accuracy: 0.9213 - val_loss: 2.7276 - val_accuracy: 0.4640\n",
            "Epoch 408/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2515 - accuracy: 0.9253 - val_loss: 2.7698 - val_accuracy: 0.4701\n",
            "Epoch 409/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2554 - accuracy: 0.9190 - val_loss: 2.7911 - val_accuracy: 0.4640\n",
            "Epoch 410/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2395 - accuracy: 0.9232 - val_loss: 2.6285 - val_accuracy: 0.4721\n",
            "Epoch 411/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2378 - accuracy: 0.9245 - val_loss: 2.7376 - val_accuracy: 0.4531\n",
            "Epoch 412/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2444 - accuracy: 0.9222 - val_loss: 2.7243 - val_accuracy: 0.4648\n",
            "Epoch 413/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2520 - accuracy: 0.9249 - val_loss: 2.8831 - val_accuracy: 0.4503\n",
            "Epoch 414/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2226 - accuracy: 0.9245 - val_loss: 2.6740 - val_accuracy: 0.4689\n",
            "Epoch 415/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2456 - accuracy: 0.9276 - val_loss: 2.7935 - val_accuracy: 0.4774\n",
            "Epoch 416/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2427 - accuracy: 0.9232 - val_loss: 2.7357 - val_accuracy: 0.4624\n",
            "Epoch 417/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2288 - accuracy: 0.9309 - val_loss: 2.8285 - val_accuracy: 0.4604\n",
            "Epoch 418/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2421 - accuracy: 0.9236 - val_loss: 2.7478 - val_accuracy: 0.4713\n",
            "Epoch 419/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2534 - accuracy: 0.9228 - val_loss: 2.7840 - val_accuracy: 0.4636\n",
            "Epoch 420/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2519 - accuracy: 0.9236 - val_loss: 2.7058 - val_accuracy: 0.4636\n",
            "Epoch 421/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2606 - accuracy: 0.9213 - val_loss: 2.6689 - val_accuracy: 0.4689\n",
            "Epoch 422/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2349 - accuracy: 0.9253 - val_loss: 2.6819 - val_accuracy: 0.4770\n",
            "Epoch 423/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2435 - accuracy: 0.9245 - val_loss: 2.8751 - val_accuracy: 0.4543\n",
            "Epoch 424/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2413 - accuracy: 0.9237 - val_loss: 2.8392 - val_accuracy: 0.4648\n",
            "Epoch 425/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2575 - accuracy: 0.9257 - val_loss: 2.7189 - val_accuracy: 0.4660\n",
            "Epoch 426/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2421 - accuracy: 0.9220 - val_loss: 2.8215 - val_accuracy: 0.4543\n",
            "Epoch 427/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2268 - accuracy: 0.9291 - val_loss: 2.7247 - val_accuracy: 0.4685\n",
            "Epoch 428/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2401 - accuracy: 0.9260 - val_loss: 2.9194 - val_accuracy: 0.4648\n",
            "Epoch 429/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2426 - accuracy: 0.9225 - val_loss: 2.8614 - val_accuracy: 0.4721\n",
            "Epoch 430/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2465 - accuracy: 0.9237 - val_loss: 2.8266 - val_accuracy: 0.4749\n",
            "Epoch 431/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2758 - accuracy: 0.9139 - val_loss: 2.8999 - val_accuracy: 0.4620\n",
            "Epoch 432/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2326 - accuracy: 0.9292 - val_loss: 2.8500 - val_accuracy: 0.4709\n",
            "Epoch 433/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2584 - accuracy: 0.9237 - val_loss: 2.9085 - val_accuracy: 0.4604\n",
            "Epoch 434/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2324 - accuracy: 0.9268 - val_loss: 2.8088 - val_accuracy: 0.4701\n",
            "Epoch 435/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2424 - accuracy: 0.9270 - val_loss: 2.8129 - val_accuracy: 0.4757\n",
            "Epoch 436/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2479 - accuracy: 0.9237 - val_loss: 2.8843 - val_accuracy: 0.4584\n",
            "Epoch 437/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2536 - accuracy: 0.9229 - val_loss: 2.9338 - val_accuracy: 0.4559\n",
            "Epoch 438/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2347 - accuracy: 0.9284 - val_loss: 2.8114 - val_accuracy: 0.4689\n",
            "Epoch 439/500\n",
            "371/371 [==============================] - 15s 41ms/step - loss: 0.2547 - accuracy: 0.9261 - val_loss: 2.8723 - val_accuracy: 0.4753\n",
            "Epoch 440/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2798 - accuracy: 0.9214 - val_loss: 2.9166 - val_accuracy: 0.4685\n",
            "Epoch 441/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2473 - accuracy: 0.9241 - val_loss: 2.8735 - val_accuracy: 0.4503\n",
            "Epoch 442/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2534 - accuracy: 0.9214 - val_loss: 2.8831 - val_accuracy: 0.4737\n",
            "Epoch 443/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2345 - accuracy: 0.9267 - val_loss: 2.9236 - val_accuracy: 0.4547\n",
            "Epoch 444/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2629 - accuracy: 0.9233 - val_loss: 2.7671 - val_accuracy: 0.4628\n",
            "Epoch 445/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2423 - accuracy: 0.9253 - val_loss: 2.8179 - val_accuracy: 0.4620\n",
            "Epoch 446/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2444 - accuracy: 0.9210 - val_loss: 2.9753 - val_accuracy: 0.4648\n",
            "Epoch 447/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2380 - accuracy: 0.9292 - val_loss: 2.8486 - val_accuracy: 0.4644\n",
            "Epoch 448/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2617 - accuracy: 0.9190 - val_loss: 2.8378 - val_accuracy: 0.4563\n",
            "Epoch 449/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2565 - accuracy: 0.9232 - val_loss: 2.9876 - val_accuracy: 0.4757\n",
            "Epoch 450/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2332 - accuracy: 0.9299 - val_loss: 2.8859 - val_accuracy: 0.4729\n",
            "Epoch 451/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2501 - accuracy: 0.9205 - val_loss: 2.9313 - val_accuracy: 0.4709\n",
            "Epoch 452/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2624 - accuracy: 0.9208 - val_loss: 2.8851 - val_accuracy: 0.4592\n",
            "Epoch 453/500\n",
            "371/371 [==============================] - 15s 42ms/step - loss: 0.2595 - accuracy: 0.9230 - val_loss: 2.7904 - val_accuracy: 0.4762\n",
            "Epoch 454/500\n",
            "371/371 [==============================] - 16s 44ms/step - loss: 0.2478 - accuracy: 0.9271 - val_loss: 2.8379 - val_accuracy: 0.4604\n",
            "Epoch 455/500\n",
            "371/371 [==============================] - 16s 42ms/step - loss: 0.2547 - accuracy: 0.9245 - val_loss: 2.9162 - val_accuracy: 0.4766\n",
            "Epoch 456/500\n",
            "245/371 [==================>...........] - ETA: 4s - loss: 0.2379 - accuracy: 0.9280"
          ]
        }
      ],
      "source": [
        "cnn5 = model5.fit(X_train, y_train, batch_size=20, epochs=500, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwJBqQV72feI",
        "outputId": "07b67b4f-ce3e-4a6a-9f7b-ba5f77b47284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.540016168148747\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.72      0.69       400\n",
            "           1       0.71      0.94      0.81       107\n",
            "           2       0.50      0.39      0.44       384\n",
            "           3       0.51      0.40      0.45       402\n",
            "           4       0.52      0.45      0.48       435\n",
            "           5       0.44      0.50      0.47       292\n",
            "           6       0.51      0.62      0.56       406\n",
            "           7       0.57      0.83      0.68        48\n",
            "\n",
            "    accuracy                           0.54      2474\n",
            "   macro avg       0.55      0.61      0.57      2474\n",
            "weighted avg       0.54      0.54      0.53      2474\n",
            "\n",
            "[[289   1  19  26  47  10   6   2]\n",
            " [  0 101   2   1   1   0   2   0]\n",
            " [ 39   3 150  21  43  53  68   7]\n",
            " [ 41   0  28 160  46  30  91   6]\n",
            " [ 61   7  43  60 196  32  27   9]\n",
            " [  2  16  27  19  27 147  51   3]\n",
            " [  2  14  30  27  17  60 253   3]\n",
            " [  0   1   3   0   3   0   1  40]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC \n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "X5 = data_combined.iloc[:,1:-1].values\n",
        "y5 = data_combined.iloc[:,-1].values\n",
        "encoder = LabelEncoder()\n",
        "scaler = MinMaxScaler()\n",
        "X5 = scaler.fit_transform(X5)\n",
        "y5 = encoder.fit_transform(y5)\n",
        "pca = PCA(n_components=50)\n",
        "X5 = pca.fit_transform(X5)\n",
        "\n",
        "X_train, X_test, y_train, y_test = split_scale(X5,y5)\n",
        "\n",
        "\n",
        "svm_model_linear = SVC(kernel = 'rbf', C = 1,decision_function_shape='ovo').fit(X_train, y_train) \n",
        "svm_predictions = svm_model_linear.predict(X_test) \n",
        "\n",
        "\n",
        "print(accuracy_score(y_true=y_test,y_pred=svm_predictions))\n",
        "print(classification_report(y_test,svm_predictions)) \n",
        "# creating a confusion matrix \n",
        "print(confusion_matrix(y_test, svm_predictions) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "TGSApxUWbDrP",
        "outputId": "73b4c178-1b8a-48d5-f46f-d887651cd46b"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-05fbb1cd8928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     max_iter=1000,epsilon=1e-08,learning_rate='adaptive')\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmlp_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \"\"\"\n\u001b[0;32m--> 752\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_pass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, y, incremental, reset)\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m         )\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m             raise ValueError(\n\u001b[1;32m    795\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m             )\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(400,),random_state=50,batch_size=200,\n",
        "                    max_iter=1000,epsilon=1e-08,learning_rate='adaptive')\n",
        "    \n",
        "mlp.fit(X_train,y_train)\n",
        "mlp_pred = mlp.predict(X_test)\n",
        "mlp.score(X_test,y_test)\n",
        "print(accuracy_score(y_true=y_test,y_pred=mlp_pred))\n",
        "print(classification_report(y_test,mlp_pred)) \n",
        "print(confusion_matrix(y_test, mlp_pred) )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "bFlQ_skf5W1Z",
        "outputId": "4eadab84-6d91-4875-a84c-76a206e6e849"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5052546483427648\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.74      0.64       400\n",
            "           1       0.75      0.94      0.83       107\n",
            "           2       0.48      0.29      0.36       384\n",
            "           3       0.52      0.36      0.42       402\n",
            "           4       0.47      0.44      0.45       435\n",
            "           5       0.39      0.47      0.42       292\n",
            "           6       0.49      0.58      0.53       406\n",
            "           7       0.70      0.69      0.69        48\n",
            "\n",
            "    accuracy                           0.51      2474\n",
            "   macro avg       0.54      0.56      0.54      2474\n",
            "weighted avg       0.50      0.51      0.49      2474\n",
            "\n",
            "[[297   2  13  16  47  18   5   2]\n",
            " [  0 101   1   1   1   2   1   0]\n",
            " [ 52   4 113  23  60  56  73   3]\n",
            " [ 60   2  19 144  55  35  84   3]\n",
            " [ 95   7  26  51 191  35  26   4]\n",
            " [  9  10  28  13  36 137  58   1]\n",
            " [ 10   9  35  30  15  72 234   1]\n",
            " [  6   0   2   1   5   0   1  33]]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-ac8ead23b0ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# creating a confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfc_predict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfc_predict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'surprise'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'calm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one label specified must be in y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: At least one label specified must be in y_true"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=600,max_features='sqrt',random_state=25)\n",
        "rfc.fit(X_train,y_train)\n",
        "\n",
        "rfc_predict = rfc.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_true=y_test,y_pred=rfc_predict))\n",
        "print(classification_report(y_test,rfc_predict)) \n",
        "# creating a confusion matrix \n",
        "print(confusion_matrix(y_test, rfc_predict) )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREMA D"
      ],
      "metadata": {
        "id": "fEnbaX6CZbe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_crema = pd.read_csv('dataset6.csv')"
      ],
      "metadata": {
        "id": "eFGNvQbhZc5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X6 = dataset_crema.iloc[:,1:-1].values\n",
        "y6 = dataset_crema.iloc[:,-1].values\n",
        "\n",
        "X6.shape,y6.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vYp8H5M03aj",
        "outputId": "6db5b1d6-5004-43e1-e6b5-f168eef0fbc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7442, 193), (7442,))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y6 = encoder.fit_transform(y6)\n",
        "print(y6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fugt5YZ1HK3",
        "outputId": "816c36b7-6195-4136-cfe6-fbe3a4e8eee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 4 2 ... 5 0 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = split_scale(X6,y6)"
      ],
      "metadata": {
        "id": "geO0XM5L1Ohf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAWBSb_26CPU",
        "outputId": "2f7bc856-2998-4fea-b00f-46b8ff9e96f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5581, 193)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=1000,max_features='sqrt',random_state=25)\n",
        "rfc.fit(X_train,y_train)\n",
        "\n",
        "rfc_predict = rfc.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_true=y_test,y_pred=rfc_predict))\n",
        "print(classification_report(y_test,rfc_predict)) \n",
        "# creating a confusion matrix \n",
        "print(confusion_matrix(y_test, rfc_predict) )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLbXDzhW1TgM",
        "outputId": "62508bf0-72f4-425f-99c9-bc57966dbb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.46695325094035467\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.69      0.64       317\n",
            "           1       0.43      0.26      0.32       319\n",
            "           2       0.57      0.20      0.30       322\n",
            "           3       0.42      0.46      0.44       340\n",
            "           4       0.35      0.52      0.42       258\n",
            "           5       0.49      0.69      0.57       305\n",
            "\n",
            "    accuracy                           0.47      1861\n",
            "   macro avg       0.48      0.47      0.45      1861\n",
            "weighted avg       0.48      0.47      0.45      1861\n",
            "\n",
            "[[219  16   3  64  12   3]\n",
            " [ 26  83   9  60  68  73]\n",
            " [ 48  27  65  50  54  78]\n",
            " [ 70  25  13 157  58  17]\n",
            " [  2  28   9  32 134  53]\n",
            " [  1  15  15   7  56 211]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC \n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "X6 = dataset_crema.iloc[:,1:-1].values\n",
        "y6 = dataset_crema.iloc[:,-1].values\n",
        "encoder = LabelEncoder()\n",
        "scaler = MinMaxScaler()\n",
        "X6 = scaler.fit_transform(X6)\n",
        "y6 = encoder.fit_transform(y6)\n",
        "pca = PCA(n_components=50)\n",
        "X6 = pca.fit_transform(X6)\n",
        "\n",
        "X_train, X_test, y_train, y_test = split_scale(X6,y6)\n",
        "\n",
        "\n",
        "svm_model_linear = SVC(kernel = 'linear', C = 1,decision_function_shape='ovo').fit(X_train, y_train) \n",
        "svm_predictions = svm_model_linear.predict(X_test) \n",
        "\n",
        "\n",
        "print(accuracy_score(y_true=y_test,y_pred=svm_predictions))\n",
        "print(classification_report(y_test,svm_predictions)) \n",
        "# creating a confusion matrix \n",
        "print(confusion_matrix(y_test, svm_predictions) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eDgxpmO22pX",
        "outputId": "048367a4-ae84-43d2-a035-b2b73e9c0259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.43148844707146694\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.62      0.62       317\n",
            "           1       0.36      0.33      0.34       319\n",
            "           2       0.33      0.23      0.27       322\n",
            "           3       0.42      0.39      0.40       340\n",
            "           4       0.33      0.34      0.33       258\n",
            "           5       0.47      0.69      0.56       305\n",
            "\n",
            "    accuracy                           0.43      1861\n",
            "   macro avg       0.42      0.43      0.42      1861\n",
            "weighted avg       0.42      0.43      0.42      1861\n",
            "\n",
            "[[195  26  21  60  12   3]\n",
            " [ 24 106  24  34  55  76]\n",
            " [ 44  32  73  54  33  86]\n",
            " [ 47  60  53 131  34  15]\n",
            " [  3  53  28  27  87  60]\n",
            " [  2  20  24   5  43 211]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "X_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbvCTfKL5raU",
        "outputId": "9960a3e7-90bd-42ed-ea35-8a7dbbe35421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5581, 193, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6 = Sequential()\n",
        "\n",
        "model6.add(Conv1D(32, 3,padding='same',input_shape=(193,1)))        \n",
        "model6.add(Activation('relu'))\n",
        "model6.add(Dropout(0.1))\n",
        "model6.add(MaxPooling1D(pool_size=(2)))\n",
        "\n",
        "model6.add(Conv1D(64, 3,padding='same'))        \n",
        "model6.add(Activation('relu'))\n",
        "model6.add(MaxPooling1D(pool_size=(2)))\n",
        "model6.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model6.add(Conv1D(128, 3,padding='same'))                          \n",
        "model6.add(Activation('relu'))\n",
        "model6.add(MaxPooling1D(pool_size=(2)))\n",
        "model6.add(Dropout(0.1))\n",
        "\n",
        "model6.add(Conv1D(128, 3,padding='same'))                          \n",
        "model6.add(Activation('relu'))\n",
        "model6.add(MaxPooling1D(pool_size=(2)))\n",
        "model6.add(Dropout(0.1))\n",
        "\n",
        "model6.add(Flatten())\n",
        "model6.add(Dense(8))                                                 \n",
        "model6.add(Activation('softmax'))\n",
        "\n",
        "opt = optimizers.RMSprop(lr=0.00005, rho=0.9, epsilon=None, decay=0.0)\n",
        "model6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE0l9mG65xe0",
        "outputId": "4e2b71e4-065b-40cf-9203-1e06a0c62f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_6 (Conv1D)           (None, 193, 32)           128       \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 193, 32)           0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 193, 32)           0         \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPooling  (None, 96, 32)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 96, 64)            6208      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 96, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d_7 (MaxPooling  (None, 48, 64)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 48, 64)            0         \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, 48, 128)           24704     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 48, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_8 (MaxPooling  (None, 24, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 24, 128)           0         \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 24, 128)           49280     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 24, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_9 (MaxPooling  (None, 12, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 12, 128)           0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1536)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 12296     \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92,616\n",
            "Trainable params: 92,616\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NpUG4VMxHZi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn6 = model6.fit(X_train, y_train, batch_size=15, epochs=300, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYl0JSd-Hixk",
        "outputId": "971ee088-f7cc-4462-851a-fd1f2d3edb32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 2.0797 - accuracy: 0.2340 - val_loss: 1.6366 - val_accuracy: 0.3149\n",
            "Epoch 2/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.7332 - accuracy: 0.2799 - val_loss: 1.5881 - val_accuracy: 0.3439\n",
            "Epoch 3/300\n",
            "373/373 [==============================] - 8s 21ms/step - loss: 1.6455 - accuracy: 0.3087 - val_loss: 1.5667 - val_accuracy: 0.3477\n",
            "Epoch 4/300\n",
            "373/373 [==============================] - 8s 21ms/step - loss: 1.6142 - accuracy: 0.3111 - val_loss: 1.5404 - val_accuracy: 0.3595\n",
            "Epoch 5/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.5783 - accuracy: 0.3370 - val_loss: 1.5459 - val_accuracy: 0.3745\n",
            "Epoch 6/300\n",
            "373/373 [==============================] - 8s 21ms/step - loss: 1.5558 - accuracy: 0.3417 - val_loss: 1.5125 - val_accuracy: 0.3939\n",
            "Epoch 7/300\n",
            "373/373 [==============================] - 8s 21ms/step - loss: 1.5395 - accuracy: 0.3537 - val_loss: 1.5154 - val_accuracy: 0.3718\n",
            "Epoch 8/300\n",
            "373/373 [==============================] - 9s 25ms/step - loss: 1.5294 - accuracy: 0.3666 - val_loss: 1.5001 - val_accuracy: 0.4009\n",
            "Epoch 9/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.5181 - accuracy: 0.3723 - val_loss: 1.4827 - val_accuracy: 0.4035\n",
            "Epoch 10/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.5101 - accuracy: 0.3757 - val_loss: 1.4898 - val_accuracy: 0.3992\n",
            "Epoch 11/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.5032 - accuracy: 0.3748 - val_loss: 1.4871 - val_accuracy: 0.4089\n",
            "Epoch 12/300\n",
            "373/373 [==============================] - 8s 21ms/step - loss: 1.4984 - accuracy: 0.3833 - val_loss: 1.4814 - val_accuracy: 0.4100\n",
            "Epoch 13/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 1.4867 - accuracy: 0.3972 - val_loss: 1.4710 - val_accuracy: 0.4132\n",
            "Epoch 14/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.4768 - accuracy: 0.3940 - val_loss: 1.4709 - val_accuracy: 0.4073\n",
            "Epoch 15/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.4758 - accuracy: 0.3920 - val_loss: 1.4654 - val_accuracy: 0.4100\n",
            "Epoch 16/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.4681 - accuracy: 0.4012 - val_loss: 1.4527 - val_accuracy: 0.4229\n",
            "Epoch 17/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.4550 - accuracy: 0.4033 - val_loss: 1.4474 - val_accuracy: 0.4256\n",
            "Epoch 18/300\n",
            "373/373 [==============================] - 8s 21ms/step - loss: 1.4536 - accuracy: 0.4139 - val_loss: 1.4461 - val_accuracy: 0.4213\n",
            "Epoch 19/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.4482 - accuracy: 0.4062 - val_loss: 1.4397 - val_accuracy: 0.4331\n",
            "Epoch 20/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 1.4432 - accuracy: 0.4073 - val_loss: 1.4409 - val_accuracy: 0.4352\n",
            "Epoch 21/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.4411 - accuracy: 0.4152 - val_loss: 1.4406 - val_accuracy: 0.4256\n",
            "Epoch 22/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.4307 - accuracy: 0.4164 - val_loss: 1.4435 - val_accuracy: 0.4331\n",
            "Epoch 23/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.4322 - accuracy: 0.4109 - val_loss: 1.4276 - val_accuracy: 0.4336\n",
            "Epoch 24/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.4230 - accuracy: 0.4266 - val_loss: 1.4290 - val_accuracy: 0.4283\n",
            "Epoch 25/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.4132 - accuracy: 0.4279 - val_loss: 1.4190 - val_accuracy: 0.4369\n",
            "Epoch 26/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 1.4041 - accuracy: 0.4257 - val_loss: 1.4246 - val_accuracy: 0.4277\n",
            "Epoch 27/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.4065 - accuracy: 0.4325 - val_loss: 1.4140 - val_accuracy: 0.4455\n",
            "Epoch 28/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.4033 - accuracy: 0.4358 - val_loss: 1.4169 - val_accuracy: 0.4379\n",
            "Epoch 29/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3829 - accuracy: 0.4426 - val_loss: 1.4071 - val_accuracy: 0.4455\n",
            "Epoch 30/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3926 - accuracy: 0.4363 - val_loss: 1.4111 - val_accuracy: 0.4401\n",
            "Epoch 31/300\n",
            "373/373 [==============================] - 8s 21ms/step - loss: 1.3859 - accuracy: 0.4401 - val_loss: 1.4000 - val_accuracy: 0.4492\n",
            "Epoch 32/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 1.3846 - accuracy: 0.4392 - val_loss: 1.3965 - val_accuracy: 0.4535\n",
            "Epoch 33/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3781 - accuracy: 0.4429 - val_loss: 1.4012 - val_accuracy: 0.4315\n",
            "Epoch 34/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3719 - accuracy: 0.4519 - val_loss: 1.3969 - val_accuracy: 0.4541\n",
            "Epoch 35/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3661 - accuracy: 0.4487 - val_loss: 1.3932 - val_accuracy: 0.4508\n",
            "Epoch 36/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3734 - accuracy: 0.4447 - val_loss: 1.3891 - val_accuracy: 0.4492\n",
            "Epoch 37/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3737 - accuracy: 0.4501 - val_loss: 1.3865 - val_accuracy: 0.4578\n",
            "Epoch 38/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3622 - accuracy: 0.4530 - val_loss: 1.3800 - val_accuracy: 0.4535\n",
            "Epoch 39/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 1.3606 - accuracy: 0.4544 - val_loss: 1.3788 - val_accuracy: 0.4546\n",
            "Epoch 40/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3601 - accuracy: 0.4508 - val_loss: 1.3770 - val_accuracy: 0.4465\n",
            "Epoch 41/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3488 - accuracy: 0.4574 - val_loss: 1.3777 - val_accuracy: 0.4557\n",
            "Epoch 42/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3396 - accuracy: 0.4608 - val_loss: 1.3674 - val_accuracy: 0.4535\n",
            "Epoch 43/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3420 - accuracy: 0.4574 - val_loss: 1.3678 - val_accuracy: 0.4562\n",
            "Epoch 44/300\n",
            "373/373 [==============================] - 9s 25ms/step - loss: 1.3433 - accuracy: 0.4542 - val_loss: 1.3733 - val_accuracy: 0.4487\n",
            "Epoch 45/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3398 - accuracy: 0.4608 - val_loss: 1.3642 - val_accuracy: 0.4551\n",
            "Epoch 46/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3365 - accuracy: 0.4625 - val_loss: 1.3678 - val_accuracy: 0.4551\n",
            "Epoch 47/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3385 - accuracy: 0.4580 - val_loss: 1.3612 - val_accuracy: 0.4637\n",
            "Epoch 48/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3319 - accuracy: 0.4619 - val_loss: 1.3584 - val_accuracy: 0.4653\n",
            "Epoch 49/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3269 - accuracy: 0.4675 - val_loss: 1.3578 - val_accuracy: 0.4600\n",
            "Epoch 50/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3263 - accuracy: 0.4691 - val_loss: 1.3589 - val_accuracy: 0.4627\n",
            "Epoch 51/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3256 - accuracy: 0.4657 - val_loss: 1.3558 - val_accuracy: 0.4627\n",
            "Epoch 52/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3186 - accuracy: 0.4723 - val_loss: 1.3542 - val_accuracy: 0.4605\n",
            "Epoch 53/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3135 - accuracy: 0.4700 - val_loss: 1.3524 - val_accuracy: 0.4605\n",
            "Epoch 54/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3200 - accuracy: 0.4738 - val_loss: 1.3490 - val_accuracy: 0.4670\n",
            "Epoch 55/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3092 - accuracy: 0.4784 - val_loss: 1.3509 - val_accuracy: 0.4664\n",
            "Epoch 56/300\n",
            "373/373 [==============================] - 9s 25ms/step - loss: 1.3100 - accuracy: 0.4795 - val_loss: 1.3440 - val_accuracy: 0.4734\n",
            "Epoch 57/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3089 - accuracy: 0.4743 - val_loss: 1.3495 - val_accuracy: 0.4578\n",
            "Epoch 58/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.3032 - accuracy: 0.4813 - val_loss: 1.3531 - val_accuracy: 0.4675\n",
            "Epoch 59/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2976 - accuracy: 0.4822 - val_loss: 1.3449 - val_accuracy: 0.4750\n",
            "Epoch 60/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2943 - accuracy: 0.4822 - val_loss: 1.3472 - val_accuracy: 0.4610\n",
            "Epoch 61/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2993 - accuracy: 0.4807 - val_loss: 1.3442 - val_accuracy: 0.4696\n",
            "Epoch 62/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2841 - accuracy: 0.4850 - val_loss: 1.3404 - val_accuracy: 0.4686\n",
            "Epoch 63/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2912 - accuracy: 0.4768 - val_loss: 1.3399 - val_accuracy: 0.4653\n",
            "Epoch 64/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2833 - accuracy: 0.4868 - val_loss: 1.3362 - val_accuracy: 0.4653\n",
            "Epoch 65/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2860 - accuracy: 0.4872 - val_loss: 1.3373 - val_accuracy: 0.4680\n",
            "Epoch 66/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2867 - accuracy: 0.4861 - val_loss: 1.3413 - val_accuracy: 0.4675\n",
            "Epoch 67/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2815 - accuracy: 0.4927 - val_loss: 1.3353 - val_accuracy: 0.4723\n",
            "Epoch 68/300\n",
            "373/373 [==============================] - 9s 25ms/step - loss: 1.2773 - accuracy: 0.4870 - val_loss: 1.3315 - val_accuracy: 0.4798\n",
            "Epoch 69/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2857 - accuracy: 0.4915 - val_loss: 1.3320 - val_accuracy: 0.4756\n",
            "Epoch 70/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2796 - accuracy: 0.4897 - val_loss: 1.3415 - val_accuracy: 0.4761\n",
            "Epoch 71/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2716 - accuracy: 0.4987 - val_loss: 1.3341 - val_accuracy: 0.4745\n",
            "Epoch 72/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2698 - accuracy: 0.4915 - val_loss: 1.3362 - val_accuracy: 0.4729\n",
            "Epoch 73/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2748 - accuracy: 0.4942 - val_loss: 1.3333 - val_accuracy: 0.4653\n",
            "Epoch 74/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.2682 - accuracy: 0.4888 - val_loss: 1.3311 - val_accuracy: 0.4825\n",
            "Epoch 75/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2548 - accuracy: 0.4985 - val_loss: 1.3273 - val_accuracy: 0.4809\n",
            "Epoch 76/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2624 - accuracy: 0.4981 - val_loss: 1.3308 - val_accuracy: 0.4766\n",
            "Epoch 77/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2589 - accuracy: 0.4944 - val_loss: 1.3279 - val_accuracy: 0.4825\n",
            "Epoch 78/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.2683 - accuracy: 0.4972 - val_loss: 1.3326 - val_accuracy: 0.4788\n",
            "Epoch 79/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 1.2546 - accuracy: 0.4958 - val_loss: 1.3268 - val_accuracy: 0.4863\n",
            "Epoch 80/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.2605 - accuracy: 0.4990 - val_loss: 1.3247 - val_accuracy: 0.4745\n",
            "Epoch 81/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2538 - accuracy: 0.5031 - val_loss: 1.3256 - val_accuracy: 0.4777\n",
            "Epoch 82/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2512 - accuracy: 0.4999 - val_loss: 1.3194 - val_accuracy: 0.4901\n",
            "Epoch 83/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2445 - accuracy: 0.4974 - val_loss: 1.3203 - val_accuracy: 0.4831\n",
            "Epoch 84/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.2509 - accuracy: 0.4969 - val_loss: 1.3217 - val_accuracy: 0.4777\n",
            "Epoch 85/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2494 - accuracy: 0.5035 - val_loss: 1.3368 - val_accuracy: 0.4761\n",
            "Epoch 86/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2381 - accuracy: 0.5073 - val_loss: 1.3180 - val_accuracy: 0.4696\n",
            "Epoch 87/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2374 - accuracy: 0.5039 - val_loss: 1.3178 - val_accuracy: 0.4815\n",
            "Epoch 88/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2388 - accuracy: 0.5064 - val_loss: 1.3209 - val_accuracy: 0.4734\n",
            "Epoch 89/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2394 - accuracy: 0.5078 - val_loss: 1.3234 - val_accuracy: 0.4686\n",
            "Epoch 90/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.2348 - accuracy: 0.5096 - val_loss: 1.3132 - val_accuracy: 0.4960\n",
            "Epoch 91/300\n",
            "373/373 [==============================] - 9s 25ms/step - loss: 1.2382 - accuracy: 0.5126 - val_loss: 1.3104 - val_accuracy: 0.4922\n",
            "Epoch 92/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2235 - accuracy: 0.5166 - val_loss: 1.3192 - val_accuracy: 0.4874\n",
            "Epoch 93/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.2232 - accuracy: 0.5110 - val_loss: 1.3340 - val_accuracy: 0.4820\n",
            "Epoch 94/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2339 - accuracy: 0.5107 - val_loss: 1.3143 - val_accuracy: 0.4831\n",
            "Epoch 95/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2323 - accuracy: 0.5058 - val_loss: 1.3110 - val_accuracy: 0.4815\n",
            "Epoch 96/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2147 - accuracy: 0.5193 - val_loss: 1.3088 - val_accuracy: 0.4927\n",
            "Epoch 97/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2264 - accuracy: 0.5092 - val_loss: 1.3106 - val_accuracy: 0.4868\n",
            "Epoch 98/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2163 - accuracy: 0.5146 - val_loss: 1.3206 - val_accuracy: 0.4884\n",
            "Epoch 99/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2133 - accuracy: 0.5151 - val_loss: 1.3115 - val_accuracy: 0.4831\n",
            "Epoch 100/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2211 - accuracy: 0.5107 - val_loss: 1.3137 - val_accuracy: 0.4863\n",
            "Epoch 101/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2130 - accuracy: 0.5168 - val_loss: 1.3307 - val_accuracy: 0.4713\n",
            "Epoch 102/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2133 - accuracy: 0.5205 - val_loss: 1.3155 - val_accuracy: 0.4761\n",
            "Epoch 103/300\n",
            "373/373 [==============================] - 9s 25ms/step - loss: 1.2064 - accuracy: 0.5239 - val_loss: 1.3142 - val_accuracy: 0.4804\n",
            "Epoch 104/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2060 - accuracy: 0.5209 - val_loss: 1.3088 - val_accuracy: 0.4933\n",
            "Epoch 105/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2134 - accuracy: 0.5202 - val_loss: 1.3163 - val_accuracy: 0.4809\n",
            "Epoch 106/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2072 - accuracy: 0.5142 - val_loss: 1.3158 - val_accuracy: 0.4841\n",
            "Epoch 107/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1959 - accuracy: 0.5314 - val_loss: 1.3041 - val_accuracy: 0.4960\n",
            "Epoch 108/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2014 - accuracy: 0.5268 - val_loss: 1.3074 - val_accuracy: 0.4917\n",
            "Epoch 109/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.2003 - accuracy: 0.5191 - val_loss: 1.3119 - val_accuracy: 0.4863\n",
            "Epoch 110/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1878 - accuracy: 0.5293 - val_loss: 1.3109 - val_accuracy: 0.4884\n",
            "Epoch 111/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1968 - accuracy: 0.5248 - val_loss: 1.3017 - val_accuracy: 0.4917\n",
            "Epoch 112/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1928 - accuracy: 0.5255 - val_loss: 1.3147 - val_accuracy: 0.4917\n",
            "Epoch 113/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1876 - accuracy: 0.5280 - val_loss: 1.3065 - val_accuracy: 0.4884\n",
            "Epoch 114/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 1.1919 - accuracy: 0.5270 - val_loss: 1.3038 - val_accuracy: 0.4933\n",
            "Epoch 115/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 1.1841 - accuracy: 0.5320 - val_loss: 1.3091 - val_accuracy: 0.4841\n",
            "Epoch 116/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1811 - accuracy: 0.5349 - val_loss: 1.3174 - val_accuracy: 0.4793\n",
            "Epoch 117/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.1891 - accuracy: 0.5295 - val_loss: 1.3117 - val_accuracy: 0.4949\n",
            "Epoch 118/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1763 - accuracy: 0.5361 - val_loss: 1.3040 - val_accuracy: 0.4922\n",
            "Epoch 119/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1827 - accuracy: 0.5318 - val_loss: 1.3066 - val_accuracy: 0.4927\n",
            "Epoch 120/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1899 - accuracy: 0.5261 - val_loss: 1.3038 - val_accuracy: 0.4879\n",
            "Epoch 121/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1727 - accuracy: 0.5327 - val_loss: 1.3047 - val_accuracy: 0.4917\n",
            "Epoch 122/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1800 - accuracy: 0.5420 - val_loss: 1.3056 - val_accuracy: 0.4863\n",
            "Epoch 123/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1791 - accuracy: 0.5336 - val_loss: 1.3038 - val_accuracy: 0.4884\n",
            "Epoch 124/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1780 - accuracy: 0.5395 - val_loss: 1.3032 - val_accuracy: 0.4874\n",
            "Epoch 125/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1688 - accuracy: 0.5440 - val_loss: 1.3040 - val_accuracy: 0.4927\n",
            "Epoch 126/300\n",
            "373/373 [==============================] - 9s 25ms/step - loss: 1.1624 - accuracy: 0.5370 - val_loss: 1.3097 - val_accuracy: 0.4911\n",
            "Epoch 127/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1660 - accuracy: 0.5400 - val_loss: 1.3080 - val_accuracy: 0.4868\n",
            "Epoch 128/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1676 - accuracy: 0.5390 - val_loss: 1.2964 - val_accuracy: 0.5003\n",
            "Epoch 129/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1612 - accuracy: 0.5426 - val_loss: 1.2964 - val_accuracy: 0.4965\n",
            "Epoch 130/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1548 - accuracy: 0.5485 - val_loss: 1.3024 - val_accuracy: 0.4976\n",
            "Epoch 131/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1593 - accuracy: 0.5372 - val_loss: 1.2990 - val_accuracy: 0.4960\n",
            "Epoch 132/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.1629 - accuracy: 0.5409 - val_loss: 1.2968 - val_accuracy: 0.5035\n",
            "Epoch 133/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.1545 - accuracy: 0.5465 - val_loss: 1.3128 - val_accuracy: 0.4911\n",
            "Epoch 134/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1510 - accuracy: 0.5562 - val_loss: 1.3023 - val_accuracy: 0.5046\n",
            "Epoch 135/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1451 - accuracy: 0.5512 - val_loss: 1.3051 - val_accuracy: 0.4970\n",
            "Epoch 136/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.1532 - accuracy: 0.5540 - val_loss: 1.3032 - val_accuracy: 0.4954\n",
            "Epoch 137/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.1416 - accuracy: 0.5512 - val_loss: 1.3011 - val_accuracy: 0.4906\n",
            "Epoch 138/300\n",
            "373/373 [==============================] - 9s 25ms/step - loss: 1.1505 - accuracy: 0.5551 - val_loss: 1.3013 - val_accuracy: 0.4965\n",
            "Epoch 139/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1473 - accuracy: 0.5504 - val_loss: 1.3035 - val_accuracy: 0.4927\n",
            "Epoch 140/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1449 - accuracy: 0.5474 - val_loss: 1.3055 - val_accuracy: 0.5008\n",
            "Epoch 141/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1380 - accuracy: 0.5537 - val_loss: 1.3056 - val_accuracy: 0.4836\n",
            "Epoch 142/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.1393 - accuracy: 0.5524 - val_loss: 1.3076 - val_accuracy: 0.4949\n",
            "Epoch 143/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1401 - accuracy: 0.5621 - val_loss: 1.3032 - val_accuracy: 0.4981\n",
            "Epoch 144/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.1369 - accuracy: 0.5490 - val_loss: 1.3084 - val_accuracy: 0.4944\n",
            "Epoch 145/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1304 - accuracy: 0.5535 - val_loss: 1.3045 - val_accuracy: 0.4890\n",
            "Epoch 146/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1301 - accuracy: 0.5658 - val_loss: 1.3091 - val_accuracy: 0.4987\n",
            "Epoch 147/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.1268 - accuracy: 0.5585 - val_loss: 1.3055 - val_accuracy: 0.4868\n",
            "Epoch 148/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.1226 - accuracy: 0.5583 - val_loss: 1.3022 - val_accuracy: 0.4960\n",
            "Epoch 149/300\n",
            "373/373 [==============================] - 9s 25ms/step - loss: 1.1212 - accuracy: 0.5603 - val_loss: 1.3002 - val_accuracy: 0.4884\n",
            "Epoch 150/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.1199 - accuracy: 0.5642 - val_loss: 1.3078 - val_accuracy: 0.4863\n",
            "Epoch 151/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.1198 - accuracy: 0.5642 - val_loss: 1.3105 - val_accuracy: 0.4890\n",
            "Epoch 152/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.1181 - accuracy: 0.5590 - val_loss: 1.3158 - val_accuracy: 0.4906\n",
            "Epoch 153/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.1254 - accuracy: 0.5615 - val_loss: 1.3103 - val_accuracy: 0.4976\n",
            "Epoch 154/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.1228 - accuracy: 0.5628 - val_loss: 1.3016 - val_accuracy: 0.4987\n",
            "Epoch 155/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.1248 - accuracy: 0.5615 - val_loss: 1.2988 - val_accuracy: 0.4938\n",
            "Epoch 156/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1189 - accuracy: 0.5660 - val_loss: 1.3036 - val_accuracy: 0.4992\n",
            "Epoch 157/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1098 - accuracy: 0.5712 - val_loss: 1.3038 - val_accuracy: 0.4906\n",
            "Epoch 158/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1040 - accuracy: 0.5755 - val_loss: 1.3169 - val_accuracy: 0.4906\n",
            "Epoch 159/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.0924 - accuracy: 0.5746 - val_loss: 1.3084 - val_accuracy: 0.4884\n",
            "Epoch 160/300\n",
            "373/373 [==============================] - 9s 25ms/step - loss: 1.1024 - accuracy: 0.5714 - val_loss: 1.3014 - val_accuracy: 0.4997\n",
            "Epoch 161/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1106 - accuracy: 0.5630 - val_loss: 1.3061 - val_accuracy: 0.5024\n",
            "Epoch 162/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1036 - accuracy: 0.5669 - val_loss: 1.3042 - val_accuracy: 0.4992\n",
            "Epoch 163/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1034 - accuracy: 0.5737 - val_loss: 1.2961 - val_accuracy: 0.5008\n",
            "Epoch 164/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.1004 - accuracy: 0.5721 - val_loss: 1.3040 - val_accuracy: 0.4997\n",
            "Epoch 165/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0987 - accuracy: 0.5696 - val_loss: 1.3115 - val_accuracy: 0.4997\n",
            "Epoch 166/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.0854 - accuracy: 0.5775 - val_loss: 1.3032 - val_accuracy: 0.4960\n",
            "Epoch 167/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.0947 - accuracy: 0.5703 - val_loss: 1.2974 - val_accuracy: 0.4965\n",
            "Epoch 168/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.0826 - accuracy: 0.5775 - val_loss: 1.3074 - val_accuracy: 0.4895\n",
            "Epoch 169/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.0852 - accuracy: 0.5748 - val_loss: 1.3004 - val_accuracy: 0.4987\n",
            "Epoch 170/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.0815 - accuracy: 0.5759 - val_loss: 1.3143 - val_accuracy: 0.4965\n",
            "Epoch 171/300\n",
            "373/373 [==============================] - 9s 25ms/step - loss: 1.0857 - accuracy: 0.5770 - val_loss: 1.3101 - val_accuracy: 0.5030\n",
            "Epoch 172/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.0792 - accuracy: 0.5820 - val_loss: 1.3110 - val_accuracy: 0.4922\n",
            "Epoch 173/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.0744 - accuracy: 0.5888 - val_loss: 1.3046 - val_accuracy: 0.4938\n",
            "Epoch 174/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.0955 - accuracy: 0.5789 - val_loss: 1.3094 - val_accuracy: 0.4938\n",
            "Epoch 175/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.0895 - accuracy: 0.5759 - val_loss: 1.2939 - val_accuracy: 0.4997\n",
            "Epoch 176/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.0893 - accuracy: 0.5761 - val_loss: 1.3181 - val_accuracy: 0.4858\n",
            "Epoch 177/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0754 - accuracy: 0.5839 - val_loss: 1.3081 - val_accuracy: 0.4954\n",
            "Epoch 178/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0703 - accuracy: 0.5861 - val_loss: 1.3020 - val_accuracy: 0.4858\n",
            "Epoch 179/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0708 - accuracy: 0.5870 - val_loss: 1.3112 - val_accuracy: 0.4922\n",
            "Epoch 180/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0685 - accuracy: 0.5843 - val_loss: 1.3149 - val_accuracy: 0.4841\n",
            "Epoch 181/300\n",
            "373/373 [==============================] - 8s 22ms/step - loss: 1.0634 - accuracy: 0.5863 - val_loss: 1.3112 - val_accuracy: 0.4890\n",
            "Epoch 182/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0643 - accuracy: 0.5865 - val_loss: 1.2962 - val_accuracy: 0.5008\n",
            "Epoch 183/300\n",
            "373/373 [==============================] - 9s 25ms/step - loss: 1.0627 - accuracy: 0.5881 - val_loss: 1.3017 - val_accuracy: 0.4922\n",
            "Epoch 184/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0690 - accuracy: 0.5847 - val_loss: 1.3037 - val_accuracy: 0.4890\n",
            "Epoch 185/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0573 - accuracy: 0.5985 - val_loss: 1.3042 - val_accuracy: 0.4938\n",
            "Epoch 186/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0619 - accuracy: 0.5908 - val_loss: 1.3212 - val_accuracy: 0.4804\n",
            "Epoch 187/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0527 - accuracy: 0.5854 - val_loss: 1.3050 - val_accuracy: 0.4976\n",
            "Epoch 188/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0587 - accuracy: 0.5850 - val_loss: 1.3070 - val_accuracy: 0.4965\n",
            "Epoch 189/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0545 - accuracy: 0.5920 - val_loss: 1.3126 - val_accuracy: 0.4906\n",
            "Epoch 190/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0473 - accuracy: 0.5986 - val_loss: 1.3168 - val_accuracy: 0.4906\n",
            "Epoch 191/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0384 - accuracy: 0.6049 - val_loss: 1.3278 - val_accuracy: 0.4798\n",
            "Epoch 192/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0437 - accuracy: 0.6022 - val_loss: 1.3291 - val_accuracy: 0.4798\n",
            "Epoch 193/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0331 - accuracy: 0.6006 - val_loss: 1.3094 - val_accuracy: 0.4911\n",
            "Epoch 194/300\n",
            "373/373 [==============================] - 10s 26ms/step - loss: 1.0475 - accuracy: 0.5895 - val_loss: 1.3133 - val_accuracy: 0.4922\n",
            "Epoch 195/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0443 - accuracy: 0.5949 - val_loss: 1.3102 - val_accuracy: 0.4895\n",
            "Epoch 196/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0466 - accuracy: 0.6022 - val_loss: 1.3129 - val_accuracy: 0.4815\n",
            "Epoch 197/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0408 - accuracy: 0.5960 - val_loss: 1.3283 - val_accuracy: 0.4820\n",
            "Epoch 198/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0382 - accuracy: 0.6017 - val_loss: 1.3187 - val_accuracy: 0.4960\n",
            "Epoch 199/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0283 - accuracy: 0.6026 - val_loss: 1.3105 - val_accuracy: 0.5019\n",
            "Epoch 200/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0233 - accuracy: 0.6101 - val_loss: 1.3090 - val_accuracy: 0.4917\n",
            "Epoch 201/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0346 - accuracy: 0.5911 - val_loss: 1.3061 - val_accuracy: 0.4879\n",
            "Epoch 202/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0107 - accuracy: 0.6126 - val_loss: 1.3073 - val_accuracy: 0.4933\n",
            "Epoch 203/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0313 - accuracy: 0.6006 - val_loss: 1.3134 - val_accuracy: 0.4906\n",
            "Epoch 204/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0179 - accuracy: 0.6081 - val_loss: 1.3137 - val_accuracy: 0.4863\n",
            "Epoch 205/300\n",
            "373/373 [==============================] - 9s 25ms/step - loss: 1.0251 - accuracy: 0.6029 - val_loss: 1.3137 - val_accuracy: 0.4917\n",
            "Epoch 206/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0211 - accuracy: 0.5999 - val_loss: 1.3172 - val_accuracy: 0.4863\n",
            "Epoch 207/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0096 - accuracy: 0.6028 - val_loss: 1.3195 - val_accuracy: 0.4836\n",
            "Epoch 208/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0180 - accuracy: 0.6031 - val_loss: 1.3151 - val_accuracy: 0.4976\n",
            "Epoch 209/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0168 - accuracy: 0.6089 - val_loss: 1.3142 - val_accuracy: 0.4890\n",
            "Epoch 210/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0072 - accuracy: 0.6126 - val_loss: 1.3223 - val_accuracy: 0.4927\n",
            "Epoch 211/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0042 - accuracy: 0.6099 - val_loss: 1.3145 - val_accuracy: 0.4890\n",
            "Epoch 212/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0146 - accuracy: 0.6081 - val_loss: 1.3067 - val_accuracy: 0.4895\n",
            "Epoch 213/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0063 - accuracy: 0.6142 - val_loss: 1.3100 - val_accuracy: 0.4992\n",
            "Epoch 214/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9993 - accuracy: 0.6096 - val_loss: 1.3254 - val_accuracy: 0.4863\n",
            "Epoch 215/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 1.0025 - accuracy: 0.6106 - val_loss: 1.3106 - val_accuracy: 0.4917\n",
            "Epoch 216/300\n",
            "373/373 [==============================] - 9s 25ms/step - loss: 0.9997 - accuracy: 0.6169 - val_loss: 1.3113 - val_accuracy: 0.4960\n",
            "Epoch 217/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 0.9932 - accuracy: 0.6132 - val_loss: 1.3192 - val_accuracy: 0.4906\n",
            "Epoch 218/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 1.0015 - accuracy: 0.6187 - val_loss: 1.3373 - val_accuracy: 0.4895\n",
            "Epoch 219/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9805 - accuracy: 0.6164 - val_loss: 1.3169 - val_accuracy: 0.4927\n",
            "Epoch 220/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 0.9915 - accuracy: 0.6207 - val_loss: 1.3207 - val_accuracy: 0.4970\n",
            "Epoch 221/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 0.9942 - accuracy: 0.6171 - val_loss: 1.3224 - val_accuracy: 0.4858\n",
            "Epoch 222/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 0.9951 - accuracy: 0.6178 - val_loss: 1.3298 - val_accuracy: 0.4874\n",
            "Epoch 223/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9880 - accuracy: 0.6234 - val_loss: 1.3186 - val_accuracy: 0.4895\n",
            "Epoch 224/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 0.9917 - accuracy: 0.6189 - val_loss: 1.3261 - val_accuracy: 0.4927\n",
            "Epoch 225/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9800 - accuracy: 0.6246 - val_loss: 1.3244 - val_accuracy: 0.4944\n",
            "Epoch 226/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9854 - accuracy: 0.6214 - val_loss: 1.3257 - val_accuracy: 0.4933\n",
            "Epoch 227/300\n",
            "373/373 [==============================] - 10s 25ms/step - loss: 0.9782 - accuracy: 0.6257 - val_loss: 1.3244 - val_accuracy: 0.4911\n",
            "Epoch 228/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9764 - accuracy: 0.6286 - val_loss: 1.3346 - val_accuracy: 0.4884\n",
            "Epoch 229/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9829 - accuracy: 0.6255 - val_loss: 1.3179 - val_accuracy: 0.4917\n",
            "Epoch 230/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9768 - accuracy: 0.6289 - val_loss: 1.3265 - val_accuracy: 0.4949\n",
            "Epoch 231/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9670 - accuracy: 0.6275 - val_loss: 1.3364 - val_accuracy: 0.5062\n",
            "Epoch 232/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 0.9683 - accuracy: 0.6255 - val_loss: 1.3248 - val_accuracy: 0.4997\n",
            "Epoch 233/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 0.9720 - accuracy: 0.6291 - val_loss: 1.3304 - val_accuracy: 0.4933\n",
            "Epoch 234/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9625 - accuracy: 0.6273 - val_loss: 1.3327 - val_accuracy: 0.4858\n",
            "Epoch 235/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9721 - accuracy: 0.6264 - val_loss: 1.3316 - val_accuracy: 0.4965\n",
            "Epoch 236/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 0.9650 - accuracy: 0.6271 - val_loss: 1.3455 - val_accuracy: 0.4858\n",
            "Epoch 237/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9664 - accuracy: 0.6289 - val_loss: 1.3255 - val_accuracy: 0.4922\n",
            "Epoch 238/300\n",
            "373/373 [==============================] - 10s 26ms/step - loss: 0.9708 - accuracy: 0.6321 - val_loss: 1.3299 - val_accuracy: 0.5003\n",
            "Epoch 239/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9630 - accuracy: 0.6377 - val_loss: 1.3486 - val_accuracy: 0.4847\n",
            "Epoch 240/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9556 - accuracy: 0.6375 - val_loss: 1.3313 - val_accuracy: 0.4944\n",
            "Epoch 241/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9535 - accuracy: 0.6372 - val_loss: 1.3267 - val_accuracy: 0.4922\n",
            "Epoch 242/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9674 - accuracy: 0.6338 - val_loss: 1.3254 - val_accuracy: 0.5008\n",
            "Epoch 243/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9566 - accuracy: 0.6307 - val_loss: 1.3340 - val_accuracy: 0.4922\n",
            "Epoch 244/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9420 - accuracy: 0.6413 - val_loss: 1.3407 - val_accuracy: 0.4997\n",
            "Epoch 245/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9492 - accuracy: 0.6352 - val_loss: 1.3504 - val_accuracy: 0.4874\n",
            "Epoch 246/300\n",
            "373/373 [==============================] - 8s 23ms/step - loss: 0.9551 - accuracy: 0.6309 - val_loss: 1.3329 - val_accuracy: 0.4906\n",
            "Epoch 247/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9471 - accuracy: 0.6363 - val_loss: 1.3378 - val_accuracy: 0.4922\n",
            "Epoch 248/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9584 - accuracy: 0.6311 - val_loss: 1.3446 - val_accuracy: 0.4858\n",
            "Epoch 249/300\n",
            "373/373 [==============================] - 10s 26ms/step - loss: 0.9525 - accuracy: 0.6436 - val_loss: 1.3329 - val_accuracy: 0.4868\n",
            "Epoch 250/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9308 - accuracy: 0.6440 - val_loss: 1.3442 - val_accuracy: 0.4981\n",
            "Epoch 251/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9329 - accuracy: 0.6409 - val_loss: 1.3447 - val_accuracy: 0.4874\n",
            "Epoch 252/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9309 - accuracy: 0.6422 - val_loss: 1.3490 - val_accuracy: 0.4906\n",
            "Epoch 253/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9355 - accuracy: 0.6486 - val_loss: 1.3585 - val_accuracy: 0.4863\n",
            "Epoch 254/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9238 - accuracy: 0.6540 - val_loss: 1.3477 - val_accuracy: 0.4933\n",
            "Epoch 255/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9337 - accuracy: 0.6377 - val_loss: 1.3444 - val_accuracy: 0.4960\n",
            "Epoch 256/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9367 - accuracy: 0.6429 - val_loss: 1.3365 - val_accuracy: 0.4901\n",
            "Epoch 257/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9238 - accuracy: 0.6510 - val_loss: 1.3426 - val_accuracy: 0.4884\n",
            "Epoch 258/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.9295 - accuracy: 0.6409 - val_loss: 1.3525 - val_accuracy: 0.4927\n",
            "Epoch 259/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.9311 - accuracy: 0.6433 - val_loss: 1.3608 - val_accuracy: 0.4917\n",
            "Epoch 260/300\n",
            "373/373 [==============================] - 10s 26ms/step - loss: 0.9230 - accuracy: 0.6456 - val_loss: 1.3409 - val_accuracy: 0.4938\n",
            "Epoch 261/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.9159 - accuracy: 0.6535 - val_loss: 1.3496 - val_accuracy: 0.4927\n",
            "Epoch 262/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.9138 - accuracy: 0.6538 - val_loss: 1.3580 - val_accuracy: 0.4944\n",
            "Epoch 263/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.9252 - accuracy: 0.6476 - val_loss: 1.3524 - val_accuracy: 0.4960\n",
            "Epoch 264/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.9099 - accuracy: 0.6535 - val_loss: 1.3694 - val_accuracy: 0.4852\n",
            "Epoch 265/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.9095 - accuracy: 0.6619 - val_loss: 1.3590 - val_accuracy: 0.4944\n",
            "Epoch 266/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.9147 - accuracy: 0.6581 - val_loss: 1.3619 - val_accuracy: 0.4911\n",
            "Epoch 267/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.9205 - accuracy: 0.6524 - val_loss: 1.3565 - val_accuracy: 0.4820\n",
            "Epoch 268/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.9085 - accuracy: 0.6553 - val_loss: 1.3584 - val_accuracy: 0.4868\n",
            "Epoch 269/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.9123 - accuracy: 0.6499 - val_loss: 1.3734 - val_accuracy: 0.4901\n",
            "Epoch 270/300\n",
            "373/373 [==============================] - 10s 26ms/step - loss: 0.9197 - accuracy: 0.6515 - val_loss: 1.3659 - val_accuracy: 0.4884\n",
            "Epoch 271/300\n",
            "373/373 [==============================] - 9s 23ms/step - loss: 0.8914 - accuracy: 0.6615 - val_loss: 1.3544 - val_accuracy: 0.4949\n",
            "Epoch 272/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8984 - accuracy: 0.6588 - val_loss: 1.3727 - val_accuracy: 0.4922\n",
            "Epoch 273/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8933 - accuracy: 0.6628 - val_loss: 1.3689 - val_accuracy: 0.4841\n",
            "Epoch 274/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.9030 - accuracy: 0.6581 - val_loss: 1.3717 - val_accuracy: 0.4858\n",
            "Epoch 275/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.9071 - accuracy: 0.6535 - val_loss: 1.3707 - val_accuracy: 0.4858\n",
            "Epoch 276/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8918 - accuracy: 0.6556 - val_loss: 1.3820 - val_accuracy: 0.4927\n",
            "Epoch 277/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8904 - accuracy: 0.6639 - val_loss: 1.3770 - val_accuracy: 0.4863\n",
            "Epoch 278/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8805 - accuracy: 0.6639 - val_loss: 1.3810 - val_accuracy: 0.4911\n",
            "Epoch 279/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8861 - accuracy: 0.6667 - val_loss: 1.3837 - val_accuracy: 0.4852\n",
            "Epoch 280/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8903 - accuracy: 0.6631 - val_loss: 1.3773 - val_accuracy: 0.4901\n",
            "Epoch 281/300\n",
            "373/373 [==============================] - 10s 27ms/step - loss: 0.8802 - accuracy: 0.6635 - val_loss: 1.3699 - val_accuracy: 0.4868\n",
            "Epoch 282/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8819 - accuracy: 0.6665 - val_loss: 1.3746 - val_accuracy: 0.4927\n",
            "Epoch 283/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8994 - accuracy: 0.6592 - val_loss: 1.3718 - val_accuracy: 0.4927\n",
            "Epoch 284/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8769 - accuracy: 0.6694 - val_loss: 1.3821 - val_accuracy: 0.4960\n",
            "Epoch 285/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8788 - accuracy: 0.6683 - val_loss: 1.3893 - val_accuracy: 0.4798\n",
            "Epoch 286/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8641 - accuracy: 0.6692 - val_loss: 1.3703 - val_accuracy: 0.4895\n",
            "Epoch 287/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8838 - accuracy: 0.6628 - val_loss: 1.3734 - val_accuracy: 0.4863\n",
            "Epoch 288/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8751 - accuracy: 0.6649 - val_loss: 1.3774 - val_accuracy: 0.4831\n",
            "Epoch 289/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8778 - accuracy: 0.6671 - val_loss: 1.3862 - val_accuracy: 0.4927\n",
            "Epoch 290/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8640 - accuracy: 0.6751 - val_loss: 1.3861 - val_accuracy: 0.4911\n",
            "Epoch 291/300\n",
            "373/373 [==============================] - 10s 27ms/step - loss: 0.8645 - accuracy: 0.6716 - val_loss: 1.4012 - val_accuracy: 0.4772\n",
            "Epoch 292/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8716 - accuracy: 0.6750 - val_loss: 1.3784 - val_accuracy: 0.4798\n",
            "Epoch 293/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8617 - accuracy: 0.6773 - val_loss: 1.3888 - val_accuracy: 0.4798\n",
            "Epoch 294/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8693 - accuracy: 0.6676 - val_loss: 1.3896 - val_accuracy: 0.4852\n",
            "Epoch 295/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8602 - accuracy: 0.6787 - val_loss: 1.3681 - val_accuracy: 0.4863\n",
            "Epoch 296/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8683 - accuracy: 0.6705 - val_loss: 1.3795 - val_accuracy: 0.4858\n",
            "Epoch 297/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8744 - accuracy: 0.6700 - val_loss: 1.3802 - val_accuracy: 0.4879\n",
            "Epoch 298/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8569 - accuracy: 0.6837 - val_loss: 1.3770 - val_accuracy: 0.4901\n",
            "Epoch 299/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8626 - accuracy: 0.6764 - val_loss: 1.3847 - val_accuracy: 0.4965\n",
            "Epoch 300/300\n",
            "373/373 [==============================] - 9s 24ms/step - loss: 0.8528 - accuracy: 0.6780 - val_loss: 1.3722 - val_accuracy: 0.4960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model6.evaluate(X_test, y_test)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmlKNZuHHpbt",
        "outputId": "59e0a013-e956-41cf-da0e-af3908a1da1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 1s 10ms/step - loss: 1.3722 - accuracy: 0.4960\n",
            "Accuracy: 49.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation (https://www.kaggle.com/code/CVxTz/audio-data-augmentation/notebook)\n"
      ],
      "metadata": {
        "id": "9PuWgM9YbSEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmented = pd.read_csv('dataset7.csv')\n"
      ],
      "metadata": {
        "id": "DgLUmxDLbWXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X7 = data_augmented.iloc[:,1:-1].values\n",
        "y7 = data_augmented.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "F5IfPXL7Iq7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y7 = encoder.fit_transform(y7)\n",
        "print(y7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ufQOuqVI932",
        "outputId": "05c1aed8-c8a4-41a1-8d0c-c65cffbd9129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = split_scale(X7,y7)"
      ],
      "metadata": {
        "id": "dCNiYm15JB7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "X_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPLaVmaRJIpu",
        "outputId": "d5b11350-050a-4b93-e67c-2620aa46c1ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3678, 193, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7 = Sequential()\n",
        "\n",
        "model7.add(Conv1D(128, 3,padding='same',input_shape=(193,1)))        \n",
        "model7.add(Activation('relu'))\n",
        "model7.add(Dropout(0.1))\n",
        "model7.add(MaxPooling1D(pool_size=(2)))\n",
        "\n",
        "model7.add(Conv1D(128, 3,padding='same'))        \n",
        "model7.add(Activation('relu'))\n",
        "model7.add(MaxPooling1D(pool_size=(2)))\n",
        "model7.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model7.add(Conv1D(128, 3,padding='same'))                          \n",
        "model7.add(Activation('relu'))\n",
        "model7.add(MaxPooling1D(pool_size=(2)))\n",
        "model7.add(Dropout(0.1))\n",
        "\n",
        "model7.add(Flatten())\n",
        "model7.add(Dense(8))                                                 \n",
        "model7.add(Activation('softmax'))\n",
        "\n",
        "opt = optimizers.RMSprop(lr=0.00005, rho=0.9, epsilon=None, decay=0.0)\n",
        "model7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJE8ylBpJNMD",
        "outputId": "24daf7ef-86bc-4303-bd32-32675d66c72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 193, 128)          512       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 193, 128)          0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 193, 128)          0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 96, 128)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 96, 128)           49280     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 96, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 48, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 48, 128)           0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 48, 128)           49280     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 48, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 24, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 24, 128)           0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 24584     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 123,656\n",
            "Trainable params: 123,656\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6o6yr2N0JeOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn7 = model7.fit(X_train, y_train, batch_size=20, epochs=400, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-k486bnJhrx",
        "outputId": "29ddcfc2-8a53-40f9-bad2-e5b3e7015fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "184/184 [==============================] - 12s 53ms/step - loss: 2.4094 - accuracy: 0.1794 - val_loss: 1.9074 - val_accuracy: 0.2716\n",
            "Epoch 2/400\n",
            "184/184 [==============================] - 9s 48ms/step - loss: 2.0275 - accuracy: 0.2493 - val_loss: 1.8262 - val_accuracy: 0.2741\n",
            "Epoch 3/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.8873 - accuracy: 0.2716 - val_loss: 1.7483 - val_accuracy: 0.3246\n",
            "Epoch 4/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.7878 - accuracy: 0.3089 - val_loss: 1.7165 - val_accuracy: 0.3426\n",
            "Epoch 5/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.7340 - accuracy: 0.3328 - val_loss: 1.6413 - val_accuracy: 0.3719\n",
            "Epoch 6/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.6567 - accuracy: 0.3801 - val_loss: 1.5857 - val_accuracy: 0.4413\n",
            "Epoch 7/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.6081 - accuracy: 0.3864 - val_loss: 1.5525 - val_accuracy: 0.4445\n",
            "Epoch 8/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.5604 - accuracy: 0.4201 - val_loss: 1.5305 - val_accuracy: 0.4364\n",
            "Epoch 9/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.5142 - accuracy: 0.4391 - val_loss: 1.4796 - val_accuracy: 0.4706\n",
            "Epoch 10/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.4867 - accuracy: 0.4478 - val_loss: 1.4588 - val_accuracy: 0.4943\n",
            "Epoch 11/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 1.4588 - accuracy: 0.4608 - val_loss: 1.4259 - val_accuracy: 0.5008\n",
            "Epoch 12/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.4314 - accuracy: 0.4679 - val_loss: 1.4191 - val_accuracy: 0.4910\n",
            "Epoch 13/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 1.3970 - accuracy: 0.4886 - val_loss: 1.4006 - val_accuracy: 0.4821\n",
            "Epoch 14/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.3708 - accuracy: 0.4935 - val_loss: 1.3632 - val_accuracy: 0.5073\n",
            "Epoch 15/400\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 1.3478 - accuracy: 0.5027 - val_loss: 1.3662 - val_accuracy: 0.5106\n",
            "Epoch 16/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.3420 - accuracy: 0.5035 - val_loss: 1.3222 - val_accuracy: 0.5147\n",
            "Epoch 17/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.3079 - accuracy: 0.5253 - val_loss: 1.3113 - val_accuracy: 0.5277\n",
            "Epoch 18/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 1.2943 - accuracy: 0.5250 - val_loss: 1.2953 - val_accuracy: 0.5261\n",
            "Epoch 19/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.2705 - accuracy: 0.5321 - val_loss: 1.2839 - val_accuracy: 0.5392\n",
            "Epoch 20/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.2654 - accuracy: 0.5372 - val_loss: 1.2692 - val_accuracy: 0.5294\n",
            "Epoch 21/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.2469 - accuracy: 0.5381 - val_loss: 1.2657 - val_accuracy: 0.5424\n",
            "Epoch 22/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.2382 - accuracy: 0.5402 - val_loss: 1.2679 - val_accuracy: 0.5424\n",
            "Epoch 23/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.2235 - accuracy: 0.5421 - val_loss: 1.2511 - val_accuracy: 0.5440\n",
            "Epoch 24/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.2189 - accuracy: 0.5541 - val_loss: 1.2352 - val_accuracy: 0.5555\n",
            "Epoch 25/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 1.2055 - accuracy: 0.5576 - val_loss: 1.2398 - val_accuracy: 0.5481\n",
            "Epoch 26/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.1949 - accuracy: 0.5585 - val_loss: 1.2245 - val_accuracy: 0.5579\n",
            "Epoch 27/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.1772 - accuracy: 0.5696 - val_loss: 1.2260 - val_accuracy: 0.5457\n",
            "Epoch 28/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.1668 - accuracy: 0.5658 - val_loss: 1.2156 - val_accuracy: 0.5481\n",
            "Epoch 29/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.1665 - accuracy: 0.5701 - val_loss: 1.2081 - val_accuracy: 0.5530\n",
            "Epoch 30/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.1541 - accuracy: 0.5710 - val_loss: 1.2405 - val_accuracy: 0.5449\n",
            "Epoch 31/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.1440 - accuracy: 0.5772 - val_loss: 1.1865 - val_accuracy: 0.5579\n",
            "Epoch 32/400\n",
            "184/184 [==============================] - 9s 48ms/step - loss: 1.1321 - accuracy: 0.5835 - val_loss: 1.2132 - val_accuracy: 0.5530\n",
            "Epoch 33/400\n",
            "184/184 [==============================] - 9s 48ms/step - loss: 1.1327 - accuracy: 0.5813 - val_loss: 1.1904 - val_accuracy: 0.5636\n",
            "Epoch 34/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.1196 - accuracy: 0.5862 - val_loss: 1.1771 - val_accuracy: 0.5669\n",
            "Epoch 35/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.1056 - accuracy: 0.5881 - val_loss: 1.1756 - val_accuracy: 0.5628\n",
            "Epoch 36/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.1155 - accuracy: 0.5851 - val_loss: 1.1742 - val_accuracy: 0.5620\n",
            "Epoch 37/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.1071 - accuracy: 0.5832 - val_loss: 1.1861 - val_accuracy: 0.5620\n",
            "Epoch 38/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.0949 - accuracy: 0.5935 - val_loss: 1.1685 - val_accuracy: 0.5718\n",
            "Epoch 39/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.0904 - accuracy: 0.5897 - val_loss: 1.1408 - val_accuracy: 0.5669\n",
            "Epoch 40/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.0812 - accuracy: 0.6047 - val_loss: 1.1730 - val_accuracy: 0.5701\n",
            "Epoch 41/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 1.0615 - accuracy: 0.6120 - val_loss: 1.1548 - val_accuracy: 0.5759\n",
            "Epoch 42/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.0739 - accuracy: 0.6052 - val_loss: 1.1666 - val_accuracy: 0.5775\n",
            "Epoch 43/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 1.0658 - accuracy: 0.5979 - val_loss: 1.1380 - val_accuracy: 0.5840\n",
            "Epoch 44/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 1.0567 - accuracy: 0.6063 - val_loss: 1.1886 - val_accuracy: 0.5759\n",
            "Epoch 45/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.0463 - accuracy: 0.6093 - val_loss: 1.1544 - val_accuracy: 0.5726\n",
            "Epoch 46/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.0470 - accuracy: 0.6120 - val_loss: 1.1310 - val_accuracy: 0.5701\n",
            "Epoch 47/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 1.0355 - accuracy: 0.6126 - val_loss: 1.1263 - val_accuracy: 0.5808\n",
            "Epoch 48/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 1.0336 - accuracy: 0.6142 - val_loss: 1.1225 - val_accuracy: 0.5840\n",
            "Epoch 49/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.0190 - accuracy: 0.6204 - val_loss: 1.1146 - val_accuracy: 0.5954\n",
            "Epoch 50/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 1.0110 - accuracy: 0.6278 - val_loss: 1.1292 - val_accuracy: 0.5889\n",
            "Epoch 51/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 1.0069 - accuracy: 0.6232 - val_loss: 1.1119 - val_accuracy: 0.5938\n",
            "Epoch 52/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 1.0030 - accuracy: 0.6259 - val_loss: 1.1117 - val_accuracy: 0.5897\n",
            "Epoch 53/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.9971 - accuracy: 0.6346 - val_loss: 1.1101 - val_accuracy: 0.5930\n",
            "Epoch 54/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.9866 - accuracy: 0.6316 - val_loss: 1.1336 - val_accuracy: 0.5824\n",
            "Epoch 55/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.9899 - accuracy: 0.6378 - val_loss: 1.0945 - val_accuracy: 0.6036\n",
            "Epoch 56/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.9775 - accuracy: 0.6436 - val_loss: 1.0939 - val_accuracy: 0.5979\n",
            "Epoch 57/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.9879 - accuracy: 0.6338 - val_loss: 1.1032 - val_accuracy: 0.6003\n",
            "Epoch 58/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.9800 - accuracy: 0.6373 - val_loss: 1.1072 - val_accuracy: 0.5979\n",
            "Epoch 59/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.9715 - accuracy: 0.6441 - val_loss: 1.1097 - val_accuracy: 0.6011\n",
            "Epoch 60/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.9754 - accuracy: 0.6444 - val_loss: 1.0796 - val_accuracy: 0.5995\n",
            "Epoch 61/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.9560 - accuracy: 0.6419 - val_loss: 1.0974 - val_accuracy: 0.6060\n",
            "Epoch 62/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 0.9566 - accuracy: 0.6427 - val_loss: 1.0988 - val_accuracy: 0.6028\n",
            "Epoch 63/400\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.9544 - accuracy: 0.6514 - val_loss: 1.1003 - val_accuracy: 0.6052\n",
            "Epoch 64/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.9434 - accuracy: 0.6465 - val_loss: 1.1152 - val_accuracy: 0.5995\n",
            "Epoch 65/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.9355 - accuracy: 0.6569 - val_loss: 1.1026 - val_accuracy: 0.5840\n",
            "Epoch 66/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.9331 - accuracy: 0.6512 - val_loss: 1.0953 - val_accuracy: 0.6060\n",
            "Epoch 67/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.9242 - accuracy: 0.6637 - val_loss: 1.0801 - val_accuracy: 0.6101\n",
            "Epoch 68/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.9313 - accuracy: 0.6563 - val_loss: 1.0715 - val_accuracy: 0.6093\n",
            "Epoch 69/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.9230 - accuracy: 0.6648 - val_loss: 1.0937 - val_accuracy: 0.6134\n",
            "Epoch 70/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.9149 - accuracy: 0.6639 - val_loss: 1.0798 - val_accuracy: 0.6101\n",
            "Epoch 71/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.9076 - accuracy: 0.6729 - val_loss: 1.0686 - val_accuracy: 0.6248\n",
            "Epoch 72/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.9008 - accuracy: 0.6688 - val_loss: 1.0596 - val_accuracy: 0.6199\n",
            "Epoch 73/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.9042 - accuracy: 0.6718 - val_loss: 1.0636 - val_accuracy: 0.6240\n",
            "Epoch 74/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.8953 - accuracy: 0.6710 - val_loss: 1.0786 - val_accuracy: 0.6142\n",
            "Epoch 75/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.8973 - accuracy: 0.6735 - val_loss: 1.0952 - val_accuracy: 0.6044\n",
            "Epoch 76/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.8944 - accuracy: 0.6759 - val_loss: 1.0694 - val_accuracy: 0.6175\n",
            "Epoch 77/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.8774 - accuracy: 0.6789 - val_loss: 1.0661 - val_accuracy: 0.6223\n",
            "Epoch 78/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.8757 - accuracy: 0.6735 - val_loss: 1.0638 - val_accuracy: 0.6281\n",
            "Epoch 79/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.8829 - accuracy: 0.6794 - val_loss: 1.0916 - val_accuracy: 0.6085\n",
            "Epoch 80/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.8685 - accuracy: 0.6876 - val_loss: 1.0551 - val_accuracy: 0.6264\n",
            "Epoch 81/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.8694 - accuracy: 0.6822 - val_loss: 1.0798 - val_accuracy: 0.6134\n",
            "Epoch 82/400\n",
            "184/184 [==============================] - 9s 52ms/step - loss: 0.8723 - accuracy: 0.6813 - val_loss: 1.0794 - val_accuracy: 0.6207\n",
            "Epoch 83/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.8641 - accuracy: 0.6778 - val_loss: 1.0584 - val_accuracy: 0.6297\n",
            "Epoch 84/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.8680 - accuracy: 0.6854 - val_loss: 1.0701 - val_accuracy: 0.6199\n",
            "Epoch 85/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.8523 - accuracy: 0.6900 - val_loss: 1.0594 - val_accuracy: 0.6305\n",
            "Epoch 86/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.8365 - accuracy: 0.6941 - val_loss: 1.0601 - val_accuracy: 0.6240\n",
            "Epoch 87/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.8470 - accuracy: 0.6928 - val_loss: 1.0466 - val_accuracy: 0.6321\n",
            "Epoch 88/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.8300 - accuracy: 0.6939 - val_loss: 1.0508 - val_accuracy: 0.6215\n",
            "Epoch 89/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.8361 - accuracy: 0.6928 - val_loss: 1.0594 - val_accuracy: 0.6281\n",
            "Epoch 90/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.8329 - accuracy: 0.6914 - val_loss: 1.0565 - val_accuracy: 0.6305\n",
            "Epoch 91/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.8192 - accuracy: 0.6993 - val_loss: 1.0508 - val_accuracy: 0.6330\n",
            "Epoch 92/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.8242 - accuracy: 0.6955 - val_loss: 1.0415 - val_accuracy: 0.6289\n",
            "Epoch 93/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 0.8245 - accuracy: 0.6941 - val_loss: 1.0492 - val_accuracy: 0.6232\n",
            "Epoch 94/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.8107 - accuracy: 0.7077 - val_loss: 1.0521 - val_accuracy: 0.6183\n",
            "Epoch 95/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.8206 - accuracy: 0.6966 - val_loss: 1.0714 - val_accuracy: 0.6264\n",
            "Epoch 96/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 0.8168 - accuracy: 0.6982 - val_loss: 1.0589 - val_accuracy: 0.6272\n",
            "Epoch 97/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.7991 - accuracy: 0.7107 - val_loss: 1.0715 - val_accuracy: 0.6289\n",
            "Epoch 98/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.8144 - accuracy: 0.7034 - val_loss: 1.0611 - val_accuracy: 0.6321\n",
            "Epoch 99/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.8018 - accuracy: 0.7094 - val_loss: 1.0414 - val_accuracy: 0.6338\n",
            "Epoch 100/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.8027 - accuracy: 0.7085 - val_loss: 1.0387 - val_accuracy: 0.6305\n",
            "Epoch 101/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.7934 - accuracy: 0.7034 - val_loss: 1.0171 - val_accuracy: 0.6403\n",
            "Epoch 102/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.7968 - accuracy: 0.7055 - val_loss: 1.0507 - val_accuracy: 0.6297\n",
            "Epoch 103/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.7853 - accuracy: 0.7140 - val_loss: 1.0356 - val_accuracy: 0.6330\n",
            "Epoch 104/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.7711 - accuracy: 0.7208 - val_loss: 1.0452 - val_accuracy: 0.6240\n",
            "Epoch 105/400\n",
            "184/184 [==============================] - 9s 52ms/step - loss: 0.7679 - accuracy: 0.7191 - val_loss: 1.0261 - val_accuracy: 0.6313\n",
            "Epoch 106/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.7647 - accuracy: 0.7159 - val_loss: 1.0192 - val_accuracy: 0.6460\n",
            "Epoch 107/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.7629 - accuracy: 0.7251 - val_loss: 1.0422 - val_accuracy: 0.6321\n",
            "Epoch 108/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.7532 - accuracy: 0.7240 - val_loss: 1.0496 - val_accuracy: 0.6281\n",
            "Epoch 109/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.7683 - accuracy: 0.7178 - val_loss: 1.0322 - val_accuracy: 0.6346\n",
            "Epoch 110/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.7686 - accuracy: 0.7189 - val_loss: 1.0532 - val_accuracy: 0.6330\n",
            "Epoch 111/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.7528 - accuracy: 0.7240 - val_loss: 1.0647 - val_accuracy: 0.6150\n",
            "Epoch 112/400\n",
            "184/184 [==============================] - 9s 52ms/step - loss: 0.7479 - accuracy: 0.7175 - val_loss: 1.0440 - val_accuracy: 0.6419\n",
            "Epoch 113/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.7501 - accuracy: 0.7265 - val_loss: 1.0156 - val_accuracy: 0.6501\n",
            "Epoch 114/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.7408 - accuracy: 0.7210 - val_loss: 1.0296 - val_accuracy: 0.6387\n",
            "Epoch 115/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.7500 - accuracy: 0.7287 - val_loss: 1.0432 - val_accuracy: 0.6321\n",
            "Epoch 116/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.7376 - accuracy: 0.7297 - val_loss: 1.0541 - val_accuracy: 0.6305\n",
            "Epoch 117/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.7485 - accuracy: 0.7295 - val_loss: 1.0225 - val_accuracy: 0.6468\n",
            "Epoch 118/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.7358 - accuracy: 0.7306 - val_loss: 1.0245 - val_accuracy: 0.6476\n",
            "Epoch 119/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.7258 - accuracy: 0.7414 - val_loss: 1.0041 - val_accuracy: 0.6542\n",
            "Epoch 120/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.7254 - accuracy: 0.7336 - val_loss: 1.0191 - val_accuracy: 0.6501\n",
            "Epoch 121/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.7232 - accuracy: 0.7412 - val_loss: 1.0201 - val_accuracy: 0.6517\n",
            "Epoch 122/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.7114 - accuracy: 0.7458 - val_loss: 1.0060 - val_accuracy: 0.6485\n",
            "Epoch 123/400\n",
            "184/184 [==============================] - 9s 52ms/step - loss: 0.7054 - accuracy: 0.7414 - val_loss: 1.0218 - val_accuracy: 0.6509\n",
            "Epoch 124/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.7099 - accuracy: 0.7423 - val_loss: 1.0147 - val_accuracy: 0.6452\n",
            "Epoch 125/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.7088 - accuracy: 0.7352 - val_loss: 1.0200 - val_accuracy: 0.6493\n",
            "Epoch 126/400\n",
            "184/184 [==============================] - 9s 52ms/step - loss: 0.7142 - accuracy: 0.7379 - val_loss: 1.0229 - val_accuracy: 0.6493\n",
            "Epoch 127/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.7034 - accuracy: 0.7474 - val_loss: 1.0166 - val_accuracy: 0.6550\n",
            "Epoch 128/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.7090 - accuracy: 0.7398 - val_loss: 1.0184 - val_accuracy: 0.6419\n",
            "Epoch 129/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.6962 - accuracy: 0.7490 - val_loss: 1.0313 - val_accuracy: 0.6378\n",
            "Epoch 130/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.6958 - accuracy: 0.7447 - val_loss: 1.0325 - val_accuracy: 0.6542\n",
            "Epoch 131/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.6978 - accuracy: 0.7526 - val_loss: 1.0347 - val_accuracy: 0.6419\n",
            "Epoch 132/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.6839 - accuracy: 0.7553 - val_loss: 1.0314 - val_accuracy: 0.6362\n",
            "Epoch 133/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.6789 - accuracy: 0.7526 - val_loss: 1.0293 - val_accuracy: 0.6395\n",
            "Epoch 134/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.6903 - accuracy: 0.7537 - val_loss: 1.0346 - val_accuracy: 0.6476\n",
            "Epoch 135/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.6848 - accuracy: 0.7523 - val_loss: 1.0268 - val_accuracy: 0.6419\n",
            "Epoch 136/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.6753 - accuracy: 0.7561 - val_loss: 1.0265 - val_accuracy: 0.6574\n",
            "Epoch 137/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.6695 - accuracy: 0.7529 - val_loss: 1.0200 - val_accuracy: 0.6591\n",
            "Epoch 138/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.6708 - accuracy: 0.7548 - val_loss: 1.0278 - val_accuracy: 0.6452\n",
            "Epoch 139/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.6722 - accuracy: 0.7607 - val_loss: 1.0170 - val_accuracy: 0.6558\n",
            "Epoch 140/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.6759 - accuracy: 0.7542 - val_loss: 1.0018 - val_accuracy: 0.6615\n",
            "Epoch 141/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.6535 - accuracy: 0.7602 - val_loss: 1.0066 - val_accuracy: 0.6656\n",
            "Epoch 142/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.6722 - accuracy: 0.7499 - val_loss: 1.0482 - val_accuracy: 0.6460\n",
            "Epoch 143/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.6555 - accuracy: 0.7694 - val_loss: 1.0149 - val_accuracy: 0.6615\n",
            "Epoch 144/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.6486 - accuracy: 0.7670 - val_loss: 1.0168 - val_accuracy: 0.6639\n",
            "Epoch 145/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.6561 - accuracy: 0.7651 - val_loss: 1.0022 - val_accuracy: 0.6623\n",
            "Epoch 146/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.6524 - accuracy: 0.7618 - val_loss: 1.0302 - val_accuracy: 0.6533\n",
            "Epoch 147/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.6450 - accuracy: 0.7654 - val_loss: 1.0368 - val_accuracy: 0.6444\n",
            "Epoch 148/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.6394 - accuracy: 0.7743 - val_loss: 1.0342 - val_accuracy: 0.6468\n",
            "Epoch 149/400\n",
            "184/184 [==============================] - 9s 52ms/step - loss: 0.6405 - accuracy: 0.7678 - val_loss: 1.0237 - val_accuracy: 0.6517\n",
            "Epoch 150/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.6318 - accuracy: 0.7738 - val_loss: 1.0072 - val_accuracy: 0.6648\n",
            "Epoch 151/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.6470 - accuracy: 0.7613 - val_loss: 1.0151 - val_accuracy: 0.6672\n",
            "Epoch 152/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.6356 - accuracy: 0.7722 - val_loss: 1.0467 - val_accuracy: 0.6427\n",
            "Epoch 153/400\n",
            "184/184 [==============================] - 9s 52ms/step - loss: 0.6281 - accuracy: 0.7749 - val_loss: 1.0051 - val_accuracy: 0.6672\n",
            "Epoch 154/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.6253 - accuracy: 0.7757 - val_loss: 1.0190 - val_accuracy: 0.6550\n",
            "Epoch 155/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.6200 - accuracy: 0.7765 - val_loss: 1.0101 - val_accuracy: 0.6631\n",
            "Epoch 156/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.6143 - accuracy: 0.7762 - val_loss: 1.0236 - val_accuracy: 0.6615\n",
            "Epoch 157/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.6205 - accuracy: 0.7681 - val_loss: 1.0148 - val_accuracy: 0.6664\n",
            "Epoch 158/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.6192 - accuracy: 0.7757 - val_loss: 1.0043 - val_accuracy: 0.6599\n",
            "Epoch 159/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.6122 - accuracy: 0.7822 - val_loss: 1.0164 - val_accuracy: 0.6672\n",
            "Epoch 160/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.6120 - accuracy: 0.7781 - val_loss: 1.0168 - val_accuracy: 0.6591\n",
            "Epoch 161/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.6176 - accuracy: 0.7703 - val_loss: 1.0209 - val_accuracy: 0.6672\n",
            "Epoch 162/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.6038 - accuracy: 0.7838 - val_loss: 1.0054 - val_accuracy: 0.6705\n",
            "Epoch 163/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.6014 - accuracy: 0.7855 - val_loss: 1.0257 - val_accuracy: 0.6542\n",
            "Epoch 164/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.6068 - accuracy: 0.7806 - val_loss: 0.9962 - val_accuracy: 0.6794\n",
            "Epoch 165/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.5982 - accuracy: 0.7830 - val_loss: 0.9877 - val_accuracy: 0.6680\n",
            "Epoch 166/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.5959 - accuracy: 0.7838 - val_loss: 1.0192 - val_accuracy: 0.6688\n",
            "Epoch 167/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.6038 - accuracy: 0.7814 - val_loss: 0.9926 - val_accuracy: 0.6705\n",
            "Epoch 168/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.5951 - accuracy: 0.7811 - val_loss: 1.0271 - val_accuracy: 0.6542\n",
            "Epoch 169/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.5985 - accuracy: 0.7830 - val_loss: 1.0294 - val_accuracy: 0.6688\n",
            "Epoch 170/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.5838 - accuracy: 0.7863 - val_loss: 1.0268 - val_accuracy: 0.6721\n",
            "Epoch 171/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.6040 - accuracy: 0.7838 - val_loss: 0.9943 - val_accuracy: 0.6827\n",
            "Epoch 172/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.5890 - accuracy: 0.7928 - val_loss: 1.0190 - val_accuracy: 0.6582\n",
            "Epoch 173/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5871 - accuracy: 0.7860 - val_loss: 1.0016 - val_accuracy: 0.6770\n",
            "Epoch 174/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.5804 - accuracy: 0.7972 - val_loss: 1.0239 - val_accuracy: 0.6639\n",
            "Epoch 175/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5930 - accuracy: 0.7866 - val_loss: 1.0044 - val_accuracy: 0.6680\n",
            "Epoch 176/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5743 - accuracy: 0.7868 - val_loss: 1.0543 - val_accuracy: 0.6582\n",
            "Epoch 177/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.5671 - accuracy: 0.7988 - val_loss: 1.0353 - val_accuracy: 0.6672\n",
            "Epoch 178/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5616 - accuracy: 0.7917 - val_loss: 1.0242 - val_accuracy: 0.6591\n",
            "Epoch 179/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.5582 - accuracy: 0.7958 - val_loss: 1.0205 - val_accuracy: 0.6754\n",
            "Epoch 180/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.5602 - accuracy: 0.7923 - val_loss: 0.9976 - val_accuracy: 0.6713\n",
            "Epoch 181/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5582 - accuracy: 0.7955 - val_loss: 1.0220 - val_accuracy: 0.6680\n",
            "Epoch 182/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5607 - accuracy: 0.7972 - val_loss: 1.0056 - val_accuracy: 0.6762\n",
            "Epoch 183/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.5553 - accuracy: 0.8013 - val_loss: 1.0048 - val_accuracy: 0.6639\n",
            "Epoch 184/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.5548 - accuracy: 0.8034 - val_loss: 1.0086 - val_accuracy: 0.6607\n",
            "Epoch 185/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5494 - accuracy: 0.8045 - val_loss: 1.0055 - val_accuracy: 0.6786\n",
            "Epoch 186/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.5466 - accuracy: 0.7988 - val_loss: 0.9949 - val_accuracy: 0.6729\n",
            "Epoch 187/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.5450 - accuracy: 0.8075 - val_loss: 0.9904 - val_accuracy: 0.6835\n",
            "Epoch 188/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5514 - accuracy: 0.7993 - val_loss: 0.9924 - val_accuracy: 0.6737\n",
            "Epoch 189/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.5478 - accuracy: 0.8048 - val_loss: 0.9855 - val_accuracy: 0.6754\n",
            "Epoch 190/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5532 - accuracy: 0.8034 - val_loss: 0.9979 - val_accuracy: 0.6721\n",
            "Epoch 191/400\n",
            "184/184 [==============================] - 9s 49ms/step - loss: 0.5491 - accuracy: 0.8059 - val_loss: 1.0207 - val_accuracy: 0.6680\n",
            "Epoch 192/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5415 - accuracy: 0.8075 - val_loss: 1.0056 - val_accuracy: 0.6786\n",
            "Epoch 193/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.5304 - accuracy: 0.8189 - val_loss: 1.0070 - val_accuracy: 0.6811\n",
            "Epoch 194/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.5296 - accuracy: 0.8078 - val_loss: 1.0113 - val_accuracy: 0.6803\n",
            "Epoch 195/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5349 - accuracy: 0.8059 - val_loss: 0.9989 - val_accuracy: 0.6762\n",
            "Epoch 196/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5351 - accuracy: 0.8013 - val_loss: 1.0139 - val_accuracy: 0.6729\n",
            "Epoch 197/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.5203 - accuracy: 0.8105 - val_loss: 1.0093 - val_accuracy: 0.6835\n",
            "Epoch 198/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.5219 - accuracy: 0.8124 - val_loss: 1.0197 - val_accuracy: 0.6811\n",
            "Epoch 199/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.5297 - accuracy: 0.8113 - val_loss: 1.0014 - val_accuracy: 0.6827\n",
            "Epoch 200/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5194 - accuracy: 0.8167 - val_loss: 1.0077 - val_accuracy: 0.6729\n",
            "Epoch 201/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.5261 - accuracy: 0.8187 - val_loss: 1.0322 - val_accuracy: 0.6713\n",
            "Epoch 202/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5125 - accuracy: 0.8181 - val_loss: 1.0139 - val_accuracy: 0.6770\n",
            "Epoch 203/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5217 - accuracy: 0.8129 - val_loss: 0.9985 - val_accuracy: 0.6794\n",
            "Epoch 204/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.5040 - accuracy: 0.8197 - val_loss: 1.0054 - val_accuracy: 0.6803\n",
            "Epoch 205/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.5056 - accuracy: 0.8108 - val_loss: 1.0211 - val_accuracy: 0.6892\n",
            "Epoch 206/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.5143 - accuracy: 0.8138 - val_loss: 1.0083 - val_accuracy: 0.6852\n",
            "Epoch 207/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5182 - accuracy: 0.8157 - val_loss: 0.9862 - val_accuracy: 0.6852\n",
            "Epoch 208/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.5007 - accuracy: 0.8181 - val_loss: 0.9951 - val_accuracy: 0.6860\n",
            "Epoch 209/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.4966 - accuracy: 0.8274 - val_loss: 1.0150 - val_accuracy: 0.6786\n",
            "Epoch 210/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.5047 - accuracy: 0.8249 - val_loss: 1.0046 - val_accuracy: 0.6819\n",
            "Epoch 211/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.5019 - accuracy: 0.8173 - val_loss: 1.0155 - val_accuracy: 0.6933\n",
            "Epoch 212/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4976 - accuracy: 0.8249 - val_loss: 1.0485 - val_accuracy: 0.6680\n",
            "Epoch 213/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.4885 - accuracy: 0.8244 - val_loss: 1.0389 - val_accuracy: 0.6729\n",
            "Epoch 214/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.4997 - accuracy: 0.8233 - val_loss: 1.0536 - val_accuracy: 0.6721\n",
            "Epoch 215/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.4903 - accuracy: 0.8263 - val_loss: 1.0337 - val_accuracy: 0.6794\n",
            "Epoch 216/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.4995 - accuracy: 0.8189 - val_loss: 1.0276 - val_accuracy: 0.6811\n",
            "Epoch 217/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.4890 - accuracy: 0.8287 - val_loss: 1.0412 - val_accuracy: 0.6811\n",
            "Epoch 218/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.4838 - accuracy: 0.8339 - val_loss: 1.0041 - val_accuracy: 0.6868\n",
            "Epoch 219/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.4831 - accuracy: 0.8320 - val_loss: 1.0066 - val_accuracy: 0.6843\n",
            "Epoch 220/400\n",
            "184/184 [==============================] - 9s 50ms/step - loss: 0.4794 - accuracy: 0.8320 - val_loss: 1.0588 - val_accuracy: 0.6599\n",
            "Epoch 221/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4955 - accuracy: 0.8235 - val_loss: 1.0124 - val_accuracy: 0.6892\n",
            "Epoch 222/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.4805 - accuracy: 0.8284 - val_loss: 1.0152 - val_accuracy: 0.6843\n",
            "Epoch 223/400\n",
            "184/184 [==============================] - 9s 52ms/step - loss: 0.4745 - accuracy: 0.8350 - val_loss: 1.0250 - val_accuracy: 0.6770\n",
            "Epoch 224/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4663 - accuracy: 0.8322 - val_loss: 1.0170 - val_accuracy: 0.6860\n",
            "Epoch 225/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4785 - accuracy: 0.8271 - val_loss: 1.0029 - val_accuracy: 0.6892\n",
            "Epoch 226/400\n",
            "184/184 [==============================] - 9s 51ms/step - loss: 0.4728 - accuracy: 0.8298 - val_loss: 1.0322 - val_accuracy: 0.6754\n",
            "Epoch 227/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4713 - accuracy: 0.8336 - val_loss: 1.0208 - val_accuracy: 0.6843\n",
            "Epoch 228/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4679 - accuracy: 0.8306 - val_loss: 1.0111 - val_accuracy: 0.6917\n",
            "Epoch 229/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.4681 - accuracy: 0.8388 - val_loss: 1.0277 - val_accuracy: 0.6827\n",
            "Epoch 230/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.4601 - accuracy: 0.8415 - val_loss: 1.0235 - val_accuracy: 0.6917\n",
            "Epoch 231/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4609 - accuracy: 0.8333 - val_loss: 1.0313 - val_accuracy: 0.6892\n",
            "Epoch 232/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.4451 - accuracy: 0.8407 - val_loss: 1.0236 - val_accuracy: 0.6949\n",
            "Epoch 233/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4590 - accuracy: 0.8377 - val_loss: 1.0228 - val_accuracy: 0.6892\n",
            "Epoch 234/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4500 - accuracy: 0.8382 - val_loss: 1.0148 - val_accuracy: 0.6933\n",
            "Epoch 235/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.4645 - accuracy: 0.8320 - val_loss: 0.9972 - val_accuracy: 0.7007\n",
            "Epoch 236/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4644 - accuracy: 0.8306 - val_loss: 1.0474 - val_accuracy: 0.6811\n",
            "Epoch 237/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.4646 - accuracy: 0.8347 - val_loss: 1.0032 - val_accuracy: 0.6892\n",
            "Epoch 238/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.4451 - accuracy: 0.8423 - val_loss: 1.0317 - val_accuracy: 0.6852\n",
            "Epoch 239/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4571 - accuracy: 0.8309 - val_loss: 1.0063 - val_accuracy: 0.6876\n",
            "Epoch 240/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.4458 - accuracy: 0.8399 - val_loss: 1.0475 - val_accuracy: 0.6843\n",
            "Epoch 241/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.4447 - accuracy: 0.8483 - val_loss: 1.0223 - val_accuracy: 0.6876\n",
            "Epoch 242/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.4484 - accuracy: 0.8374 - val_loss: 1.0179 - val_accuracy: 0.6925\n",
            "Epoch 243/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.4499 - accuracy: 0.8396 - val_loss: 0.9972 - val_accuracy: 0.6909\n",
            "Epoch 244/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4495 - accuracy: 0.8320 - val_loss: 1.0016 - val_accuracy: 0.6966\n",
            "Epoch 245/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4405 - accuracy: 0.8453 - val_loss: 1.0539 - val_accuracy: 0.6827\n",
            "Epoch 246/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.4294 - accuracy: 0.8502 - val_loss: 1.0310 - val_accuracy: 0.6925\n",
            "Epoch 247/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.4405 - accuracy: 0.8409 - val_loss: 1.0237 - val_accuracy: 0.6917\n",
            "Epoch 248/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4296 - accuracy: 0.8494 - val_loss: 1.0026 - val_accuracy: 0.7007\n",
            "Epoch 249/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.4263 - accuracy: 0.8483 - val_loss: 1.0091 - val_accuracy: 0.7039\n",
            "Epoch 250/400\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.4262 - accuracy: 0.8477 - val_loss: 1.0173 - val_accuracy: 0.6941\n",
            "Epoch 251/400\n",
            "184/184 [==============================] - 9s 52ms/step - loss: 0.4367 - accuracy: 0.8448 - val_loss: 1.0077 - val_accuracy: 0.6958\n",
            "Epoch 252/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.4223 - accuracy: 0.8502 - val_loss: 1.0298 - val_accuracy: 0.6941\n",
            "Epoch 253/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4218 - accuracy: 0.8545 - val_loss: 1.0079 - val_accuracy: 0.6958\n",
            "Epoch 254/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.4246 - accuracy: 0.8496 - val_loss: 1.0096 - val_accuracy: 0.6917\n",
            "Epoch 255/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.4199 - accuracy: 0.8510 - val_loss: 1.0265 - val_accuracy: 0.6892\n",
            "Epoch 256/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.4118 - accuracy: 0.8513 - val_loss: 1.0194 - val_accuracy: 0.6949\n",
            "Epoch 257/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.4229 - accuracy: 0.8521 - val_loss: 1.0271 - val_accuracy: 0.6900\n",
            "Epoch 258/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.4128 - accuracy: 0.8486 - val_loss: 1.0304 - val_accuracy: 0.6811\n",
            "Epoch 259/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.4118 - accuracy: 0.8494 - val_loss: 1.0055 - val_accuracy: 0.6966\n",
            "Epoch 260/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.4042 - accuracy: 0.8589 - val_loss: 1.0127 - val_accuracy: 0.7015\n",
            "Epoch 261/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.4050 - accuracy: 0.8559 - val_loss: 1.0240 - val_accuracy: 0.6933\n",
            "Epoch 262/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4086 - accuracy: 0.8518 - val_loss: 1.0370 - val_accuracy: 0.6949\n",
            "Epoch 263/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.4352 - accuracy: 0.8450 - val_loss: 1.0432 - val_accuracy: 0.6958\n",
            "Epoch 264/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.4123 - accuracy: 0.8548 - val_loss: 1.0404 - val_accuracy: 0.6958\n",
            "Epoch 265/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.4037 - accuracy: 0.8564 - val_loss: 1.0388 - val_accuracy: 0.6917\n",
            "Epoch 266/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.4123 - accuracy: 0.8505 - val_loss: 1.0338 - val_accuracy: 0.7023\n",
            "Epoch 267/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.4129 - accuracy: 0.8510 - val_loss: 1.0463 - val_accuracy: 0.6933\n",
            "Epoch 268/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3926 - accuracy: 0.8608 - val_loss: 1.0352 - val_accuracy: 0.6909\n",
            "Epoch 269/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3930 - accuracy: 0.8581 - val_loss: 1.0298 - val_accuracy: 0.6998\n",
            "Epoch 270/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.3916 - accuracy: 0.8616 - val_loss: 1.0130 - val_accuracy: 0.6966\n",
            "Epoch 271/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.3901 - accuracy: 0.8605 - val_loss: 1.0031 - val_accuracy: 0.7039\n",
            "Epoch 272/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3942 - accuracy: 0.8613 - val_loss: 1.0126 - val_accuracy: 0.7047\n",
            "Epoch 273/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.3956 - accuracy: 0.8616 - val_loss: 1.0026 - val_accuracy: 0.7023\n",
            "Epoch 274/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3931 - accuracy: 0.8641 - val_loss: 1.0174 - val_accuracy: 0.6884\n",
            "Epoch 275/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.3972 - accuracy: 0.8616 - val_loss: 0.9940 - val_accuracy: 0.7015\n",
            "Epoch 276/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.3881 - accuracy: 0.8583 - val_loss: 1.0244 - val_accuracy: 0.6941\n",
            "Epoch 277/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3857 - accuracy: 0.8654 - val_loss: 1.0393 - val_accuracy: 0.6786\n",
            "Epoch 278/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.3812 - accuracy: 0.8635 - val_loss: 1.0183 - val_accuracy: 0.7015\n",
            "Epoch 279/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.3913 - accuracy: 0.8622 - val_loss: 1.0338 - val_accuracy: 0.6949\n",
            "Epoch 280/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3949 - accuracy: 0.8564 - val_loss: 1.0403 - val_accuracy: 0.6990\n",
            "Epoch 281/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3888 - accuracy: 0.8649 - val_loss: 1.0302 - val_accuracy: 0.7113\n",
            "Epoch 282/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3811 - accuracy: 0.8649 - val_loss: 1.0204 - val_accuracy: 0.6974\n",
            "Epoch 283/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.3783 - accuracy: 0.8638 - val_loss: 1.0220 - val_accuracy: 0.6966\n",
            "Epoch 284/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3805 - accuracy: 0.8622 - val_loss: 1.0224 - val_accuracy: 0.6982\n",
            "Epoch 285/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.3691 - accuracy: 0.8654 - val_loss: 1.0471 - val_accuracy: 0.6876\n",
            "Epoch 286/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.3733 - accuracy: 0.8665 - val_loss: 1.0017 - val_accuracy: 0.7080\n",
            "Epoch 287/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.3797 - accuracy: 0.8651 - val_loss: 1.0385 - val_accuracy: 0.6868\n",
            "Epoch 288/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.3782 - accuracy: 0.8692 - val_loss: 1.0164 - val_accuracy: 0.6974\n",
            "Epoch 289/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3902 - accuracy: 0.8665 - val_loss: 1.0328 - val_accuracy: 0.6868\n",
            "Epoch 290/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3781 - accuracy: 0.8660 - val_loss: 1.0166 - val_accuracy: 0.6998\n",
            "Epoch 291/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.3788 - accuracy: 0.8624 - val_loss: 0.9951 - val_accuracy: 0.7153\n",
            "Epoch 292/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3674 - accuracy: 0.8709 - val_loss: 1.0456 - val_accuracy: 0.6925\n",
            "Epoch 293/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.3737 - accuracy: 0.8630 - val_loss: 1.0425 - val_accuracy: 0.6958\n",
            "Epoch 294/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3827 - accuracy: 0.8676 - val_loss: 1.0134 - val_accuracy: 0.7104\n",
            "Epoch 295/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.3650 - accuracy: 0.8700 - val_loss: 1.0414 - val_accuracy: 0.6998\n",
            "Epoch 296/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.3749 - accuracy: 0.8703 - val_loss: 1.0441 - val_accuracy: 0.6982\n",
            "Epoch 297/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.3574 - accuracy: 0.8741 - val_loss: 1.0479 - val_accuracy: 0.7039\n",
            "Epoch 298/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.3656 - accuracy: 0.8698 - val_loss: 1.0631 - val_accuracy: 0.6949\n",
            "Epoch 299/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3577 - accuracy: 0.8766 - val_loss: 1.0462 - val_accuracy: 0.7031\n",
            "Epoch 300/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.3653 - accuracy: 0.8709 - val_loss: 1.0479 - val_accuracy: 0.6998\n",
            "Epoch 301/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3706 - accuracy: 0.8722 - val_loss: 1.0444 - val_accuracy: 0.7096\n",
            "Epoch 302/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3683 - accuracy: 0.8673 - val_loss: 1.0573 - val_accuracy: 0.6982\n",
            "Epoch 303/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.3663 - accuracy: 0.8722 - val_loss: 1.0403 - val_accuracy: 0.7113\n",
            "Epoch 304/400\n",
            "184/184 [==============================] - 10s 53ms/step - loss: 0.3639 - accuracy: 0.8635 - val_loss: 1.0547 - val_accuracy: 0.7047\n",
            "Epoch 305/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3362 - accuracy: 0.8785 - val_loss: 1.0648 - val_accuracy: 0.7015\n",
            "Epoch 306/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.3564 - accuracy: 0.8760 - val_loss: 1.1053 - val_accuracy: 0.6860\n",
            "Epoch 307/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.3585 - accuracy: 0.8700 - val_loss: 1.0886 - val_accuracy: 0.6982\n",
            "Epoch 308/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.3447 - accuracy: 0.8722 - val_loss: 1.0589 - val_accuracy: 0.7121\n",
            "Epoch 309/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.3470 - accuracy: 0.8766 - val_loss: 1.0536 - val_accuracy: 0.7031\n",
            "Epoch 310/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3439 - accuracy: 0.8806 - val_loss: 1.0544 - val_accuracy: 0.7015\n",
            "Epoch 311/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3498 - accuracy: 0.8766 - val_loss: 1.0338 - val_accuracy: 0.7080\n",
            "Epoch 312/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.3543 - accuracy: 0.8774 - val_loss: 1.0679 - val_accuracy: 0.7023\n",
            "Epoch 313/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3494 - accuracy: 0.8779 - val_loss: 1.0461 - val_accuracy: 0.7064\n",
            "Epoch 314/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3465 - accuracy: 0.8779 - val_loss: 1.0622 - val_accuracy: 0.7047\n",
            "Epoch 315/400\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.3534 - accuracy: 0.8741 - val_loss: 1.0440 - val_accuracy: 0.6990\n",
            "Epoch 316/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3376 - accuracy: 0.8793 - val_loss: 1.0954 - val_accuracy: 0.6998\n",
            "Epoch 317/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.3442 - accuracy: 0.8757 - val_loss: 1.0723 - val_accuracy: 0.7064\n",
            "Epoch 318/400\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.3534 - accuracy: 0.8823 - val_loss: 1.0809 - val_accuracy: 0.7088\n",
            "Epoch 319/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3403 - accuracy: 0.8820 - val_loss: 1.0540 - val_accuracy: 0.7072\n",
            "Epoch 320/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.3577 - accuracy: 0.8730 - val_loss: 1.0651 - val_accuracy: 0.7080\n",
            "Epoch 321/400\n",
            "184/184 [==============================] - 11s 59ms/step - loss: 0.3415 - accuracy: 0.8825 - val_loss: 1.0739 - val_accuracy: 0.7015\n",
            "Epoch 322/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3418 - accuracy: 0.8755 - val_loss: 1.0602 - val_accuracy: 0.7113\n",
            "Epoch 323/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.3461 - accuracy: 0.8757 - val_loss: 1.0672 - val_accuracy: 0.7104\n",
            "Epoch 324/400\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.3351 - accuracy: 0.8828 - val_loss: 1.0717 - val_accuracy: 0.7055\n",
            "Epoch 325/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.3318 - accuracy: 0.8804 - val_loss: 1.0737 - val_accuracy: 0.7121\n",
            "Epoch 326/400\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.3321 - accuracy: 0.8782 - val_loss: 1.1011 - val_accuracy: 0.6949\n",
            "Epoch 327/400\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.3290 - accuracy: 0.8812 - val_loss: 1.0929 - val_accuracy: 0.7104\n",
            "Epoch 328/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.3339 - accuracy: 0.8809 - val_loss: 1.0992 - val_accuracy: 0.6949\n",
            "Epoch 329/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.3371 - accuracy: 0.8823 - val_loss: 1.0880 - val_accuracy: 0.7080\n",
            "Epoch 330/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.3304 - accuracy: 0.8839 - val_loss: 1.0791 - val_accuracy: 0.7129\n",
            "Epoch 331/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.3282 - accuracy: 0.8853 - val_loss: 1.0698 - val_accuracy: 0.7162\n",
            "Epoch 332/400\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.3223 - accuracy: 0.8912 - val_loss: 1.0766 - val_accuracy: 0.7031\n",
            "Epoch 333/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.3251 - accuracy: 0.8847 - val_loss: 1.0743 - val_accuracy: 0.7104\n",
            "Epoch 334/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.3198 - accuracy: 0.8880 - val_loss: 1.0459 - val_accuracy: 0.7113\n",
            "Epoch 335/400\n",
            "184/184 [==============================] - 11s 59ms/step - loss: 0.3223 - accuracy: 0.8883 - val_loss: 1.0909 - val_accuracy: 0.6974\n",
            "Epoch 336/400\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.3156 - accuracy: 0.8896 - val_loss: 1.0842 - val_accuracy: 0.7104\n",
            "Epoch 337/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.3090 - accuracy: 0.8888 - val_loss: 1.0778 - val_accuracy: 0.7031\n",
            "Epoch 338/400\n",
            "184/184 [==============================] - 11s 60ms/step - loss: 0.3233 - accuracy: 0.8861 - val_loss: 1.0966 - val_accuracy: 0.7039\n",
            "Epoch 339/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.3148 - accuracy: 0.8910 - val_loss: 1.0586 - val_accuracy: 0.7104\n",
            "Epoch 340/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.3207 - accuracy: 0.8899 - val_loss: 1.1188 - val_accuracy: 0.6892\n",
            "Epoch 341/400\n",
            "184/184 [==============================] - 11s 59ms/step - loss: 0.3356 - accuracy: 0.8847 - val_loss: 1.0963 - val_accuracy: 0.7088\n",
            "Epoch 342/400\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.3190 - accuracy: 0.8844 - val_loss: 1.0813 - val_accuracy: 0.7153\n",
            "Epoch 343/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.3132 - accuracy: 0.8893 - val_loss: 1.1225 - val_accuracy: 0.7031\n",
            "Epoch 344/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.3202 - accuracy: 0.8855 - val_loss: 1.1089 - val_accuracy: 0.7047\n",
            "Epoch 345/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.3033 - accuracy: 0.8951 - val_loss: 1.0949 - val_accuracy: 0.7129\n",
            "Epoch 346/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.2959 - accuracy: 0.8912 - val_loss: 1.1277 - val_accuracy: 0.6990\n",
            "Epoch 347/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.3057 - accuracy: 0.8912 - val_loss: 1.1176 - val_accuracy: 0.7104\n",
            "Epoch 348/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.3158 - accuracy: 0.8907 - val_loss: 1.1154 - val_accuracy: 0.7055\n",
            "Epoch 349/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.3175 - accuracy: 0.8858 - val_loss: 1.1074 - val_accuracy: 0.7113\n",
            "Epoch 350/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.3152 - accuracy: 0.8836 - val_loss: 1.1016 - val_accuracy: 0.7162\n",
            "Epoch 351/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.3083 - accuracy: 0.8896 - val_loss: 1.1001 - val_accuracy: 0.7170\n",
            "Epoch 352/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.3081 - accuracy: 0.8918 - val_loss: 1.1056 - val_accuracy: 0.7210\n",
            "Epoch 353/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.3063 - accuracy: 0.8918 - val_loss: 1.1076 - val_accuracy: 0.7137\n",
            "Epoch 354/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.2988 - accuracy: 0.8940 - val_loss: 1.1307 - val_accuracy: 0.7007\n",
            "Epoch 355/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.3120 - accuracy: 0.8907 - val_loss: 1.1170 - val_accuracy: 0.7023\n",
            "Epoch 356/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.2994 - accuracy: 0.8918 - val_loss: 1.0972 - val_accuracy: 0.7227\n",
            "Epoch 357/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.3039 - accuracy: 0.8948 - val_loss: 1.1100 - val_accuracy: 0.6982\n",
            "Epoch 358/400\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.3125 - accuracy: 0.8893 - val_loss: 1.0881 - val_accuracy: 0.7170\n",
            "Epoch 359/400\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.2926 - accuracy: 0.8951 - val_loss: 1.1525 - val_accuracy: 0.6958\n",
            "Epoch 360/400\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.3054 - accuracy: 0.8907 - val_loss: 1.1409 - val_accuracy: 0.7031\n",
            "Epoch 361/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.2876 - accuracy: 0.9027 - val_loss: 1.1040 - val_accuracy: 0.7104\n",
            "Epoch 362/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.2926 - accuracy: 0.9016 - val_loss: 1.1159 - val_accuracy: 0.7096\n",
            "Epoch 363/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.3033 - accuracy: 0.8883 - val_loss: 1.1184 - val_accuracy: 0.6990\n",
            "Epoch 364/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.2889 - accuracy: 0.9018 - val_loss: 1.0936 - val_accuracy: 0.7137\n",
            "Epoch 365/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.2966 - accuracy: 0.8931 - val_loss: 1.1234 - val_accuracy: 0.7047\n",
            "Epoch 366/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.2846 - accuracy: 0.8972 - val_loss: 1.1243 - val_accuracy: 0.7113\n",
            "Epoch 367/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.2918 - accuracy: 0.8980 - val_loss: 1.1309 - val_accuracy: 0.7178\n",
            "Epoch 368/400\n",
            "184/184 [==============================] - 10s 54ms/step - loss: 0.2882 - accuracy: 0.8972 - val_loss: 1.1589 - val_accuracy: 0.7113\n",
            "Epoch 369/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.2917 - accuracy: 0.8953 - val_loss: 1.1420 - val_accuracy: 0.7104\n",
            "Epoch 370/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.2969 - accuracy: 0.8921 - val_loss: 1.1197 - val_accuracy: 0.7096\n",
            "Epoch 371/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.2888 - accuracy: 0.8961 - val_loss: 1.1425 - val_accuracy: 0.7104\n",
            "Epoch 372/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.2829 - accuracy: 0.9027 - val_loss: 1.1282 - val_accuracy: 0.7096\n",
            "Epoch 373/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.2993 - accuracy: 0.8945 - val_loss: 1.1322 - val_accuracy: 0.7113\n",
            "Epoch 374/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.2716 - accuracy: 0.9046 - val_loss: 1.1799 - val_accuracy: 0.6941\n",
            "Epoch 375/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.2901 - accuracy: 0.9010 - val_loss: 1.1560 - val_accuracy: 0.7121\n",
            "Epoch 376/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.2779 - accuracy: 0.9054 - val_loss: 1.1412 - val_accuracy: 0.7153\n",
            "Epoch 377/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.2868 - accuracy: 0.8940 - val_loss: 1.1444 - val_accuracy: 0.7202\n",
            "Epoch 378/400\n",
            "184/184 [==============================] - 11s 59ms/step - loss: 0.2833 - accuracy: 0.9005 - val_loss: 1.1849 - val_accuracy: 0.7047\n",
            "Epoch 379/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.2792 - accuracy: 0.8994 - val_loss: 1.1563 - val_accuracy: 0.7178\n",
            "Epoch 380/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.2727 - accuracy: 0.9078 - val_loss: 1.1673 - val_accuracy: 0.7194\n",
            "Epoch 381/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.2789 - accuracy: 0.9005 - val_loss: 1.1688 - val_accuracy: 0.7194\n",
            "Epoch 382/400\n",
            "184/184 [==============================] - 10s 55ms/step - loss: 0.2850 - accuracy: 0.9029 - val_loss: 1.1855 - val_accuracy: 0.6998\n",
            "Epoch 383/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.2654 - accuracy: 0.9059 - val_loss: 1.1382 - val_accuracy: 0.7113\n",
            "Epoch 384/400\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.2746 - accuracy: 0.9062 - val_loss: 1.1665 - val_accuracy: 0.7145\n",
            "Epoch 385/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.2771 - accuracy: 0.9013 - val_loss: 1.1634 - val_accuracy: 0.7047\n",
            "Epoch 386/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.2704 - accuracy: 0.9027 - val_loss: 1.1955 - val_accuracy: 0.7137\n",
            "Epoch 387/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.2829 - accuracy: 0.9040 - val_loss: 1.1788 - val_accuracy: 0.7047\n",
            "Epoch 388/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.2769 - accuracy: 0.9054 - val_loss: 1.1666 - val_accuracy: 0.7178\n",
            "Epoch 389/400\n",
            "184/184 [==============================] - 11s 59ms/step - loss: 0.2656 - accuracy: 0.9073 - val_loss: 1.1629 - val_accuracy: 0.7113\n",
            "Epoch 390/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.2626 - accuracy: 0.9062 - val_loss: 1.1971 - val_accuracy: 0.7047\n",
            "Epoch 391/400\n",
            "184/184 [==============================] - 10s 56ms/step - loss: 0.2648 - accuracy: 0.9027 - val_loss: 1.1532 - val_accuracy: 0.7194\n",
            "Epoch 392/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.2673 - accuracy: 0.9095 - val_loss: 1.1893 - val_accuracy: 0.6941\n",
            "Epoch 393/400\n",
            "184/184 [==============================] - 11s 57ms/step - loss: 0.2613 - accuracy: 0.9078 - val_loss: 1.1854 - val_accuracy: 0.7039\n",
            "Epoch 394/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.2743 - accuracy: 0.9027 - val_loss: 1.1671 - val_accuracy: 0.7031\n",
            "Epoch 395/400\n",
            "184/184 [==============================] - 11s 59ms/step - loss: 0.2576 - accuracy: 0.9097 - val_loss: 1.1492 - val_accuracy: 0.7186\n",
            "Epoch 396/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.2621 - accuracy: 0.9116 - val_loss: 1.1630 - val_accuracy: 0.7137\n",
            "Epoch 397/400\n",
            "184/184 [==============================] - 11s 58ms/step - loss: 0.2651 - accuracy: 0.9133 - val_loss: 1.1996 - val_accuracy: 0.7047\n",
            "Epoch 398/400\n",
            "184/184 [==============================] - 11s 59ms/step - loss: 0.2666 - accuracy: 0.9076 - val_loss: 1.1678 - val_accuracy: 0.7210\n",
            "Epoch 399/400\n",
            "184/184 [==============================] - 10s 57ms/step - loss: 0.2667 - accuracy: 0.9157 - val_loss: 1.1576 - val_accuracy: 0.7219\n",
            "Epoch 400/400\n",
            "184/184 [==============================] - 11s 59ms/step - loss: 0.2614 - accuracy: 0.9038 - val_loss: 1.1594 - val_accuracy: 0.7178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model7.evaluate(X_test, y_test)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8NCLafPJmwO",
        "outputId": "8a148baa-b4d0-4789-d8ee-dd719662320b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39/39 [==============================] - 1s 18ms/step - loss: 1.1594 - accuracy: 0.7178\n",
            "Accuracy: 71.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "plt.plot(cnn7.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(cnn7.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "XbTHam6mJyg0",
        "outputId": "437f917a-b214-482c-b8a1-f7f72e091608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "plt.plot(cnn7.history[\"accuracy\"], label=\"loss\")\n",
        "plt.plot(cnn7.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "dIotnCqhJ1x0",
        "outputId": "ce7878ec-63e6-434d-843f-585668a664b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduced Emotions \n"
      ],
      "metadata": {
        "id": "U80o3kqtZvuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data8 = pd.read_csv('dataset7.csv')\n",
        "data8.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "cKuaAc4bZz5_",
        "outputId": "ef74ec07-6f29-4e76-b288-2c642a2f4a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0           0          1          2          3         4  \\\n",
              "0           0 -524.339844  58.945076  11.774967  26.318909  0.261554   \n",
              "1           1 -269.140574  11.484386   8.767346   6.243472  2.747863   \n",
              "2           2 -366.166321  61.372746 -14.820083  21.295778 -8.899424   \n",
              "3           3 -231.392576  29.672213   1.565719   5.466136 -4.319672   \n",
              "4           4 -536.010803  69.903397 -16.303288  32.916740  2.925880   \n",
              "\n",
              "          5          6         7          8  ...       184       185  \\\n",
              "0  5.660612  -3.377984 -3.362769  -9.245324  ... -0.000091  0.007732   \n",
              "1  0.709594  -0.614465 -1.588504  -3.817834  ... -0.000729  0.002335   \n",
              "2 -7.860835  -2.845897 -0.053523 -10.914480  ... -0.030637 -0.010813   \n",
              "3 -7.645862  -0.795612  0.830001  -6.118091  ... -0.032956  0.001459   \n",
              "4  0.171463 -12.861864 -5.886380 -12.273261  ... -0.007125 -0.016768   \n",
              "\n",
              "         186        187        188        189        190        191  \\\n",
              "0  21.961529  15.875564  19.082055  14.696499  16.397359  16.391151   \n",
              "1  15.468811  13.326386  14.867802  12.761607  13.529643  13.522223   \n",
              "2  22.978009  17.598611  20.942201  18.762070  18.259227  17.844183   \n",
              "3  17.083159  15.874668  18.546013  16.412194  15.331840  14.713892   \n",
              "4  23.791126  19.190114  20.781159  18.825651  19.712703  20.324445   \n",
              "\n",
              "         192   labels  \n",
              "0  29.530816  disgust  \n",
              "1  13.355271  disgust  \n",
              "2  30.877108    angry  \n",
              "3  13.618339    angry  \n",
              "4  29.268788  neutral  \n",
              "\n",
              "[5 rows x 195 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5523fd4-6b82-43fb-8bdf-1a025e61a7fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-524.339844</td>\n",
              "      <td>58.945076</td>\n",
              "      <td>11.774967</td>\n",
              "      <td>26.318909</td>\n",
              "      <td>0.261554</td>\n",
              "      <td>5.660612</td>\n",
              "      <td>-3.377984</td>\n",
              "      <td>-3.362769</td>\n",
              "      <td>-9.245324</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000091</td>\n",
              "      <td>0.007732</td>\n",
              "      <td>21.961529</td>\n",
              "      <td>15.875564</td>\n",
              "      <td>19.082055</td>\n",
              "      <td>14.696499</td>\n",
              "      <td>16.397359</td>\n",
              "      <td>16.391151</td>\n",
              "      <td>29.530816</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-269.140574</td>\n",
              "      <td>11.484386</td>\n",
              "      <td>8.767346</td>\n",
              "      <td>6.243472</td>\n",
              "      <td>2.747863</td>\n",
              "      <td>0.709594</td>\n",
              "      <td>-0.614465</td>\n",
              "      <td>-1.588504</td>\n",
              "      <td>-3.817834</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000729</td>\n",
              "      <td>0.002335</td>\n",
              "      <td>15.468811</td>\n",
              "      <td>13.326386</td>\n",
              "      <td>14.867802</td>\n",
              "      <td>12.761607</td>\n",
              "      <td>13.529643</td>\n",
              "      <td>13.522223</td>\n",
              "      <td>13.355271</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-366.166321</td>\n",
              "      <td>61.372746</td>\n",
              "      <td>-14.820083</td>\n",
              "      <td>21.295778</td>\n",
              "      <td>-8.899424</td>\n",
              "      <td>-7.860835</td>\n",
              "      <td>-2.845897</td>\n",
              "      <td>-0.053523</td>\n",
              "      <td>-10.914480</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.030637</td>\n",
              "      <td>-0.010813</td>\n",
              "      <td>22.978009</td>\n",
              "      <td>17.598611</td>\n",
              "      <td>20.942201</td>\n",
              "      <td>18.762070</td>\n",
              "      <td>18.259227</td>\n",
              "      <td>17.844183</td>\n",
              "      <td>30.877108</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-231.392576</td>\n",
              "      <td>29.672213</td>\n",
              "      <td>1.565719</td>\n",
              "      <td>5.466136</td>\n",
              "      <td>-4.319672</td>\n",
              "      <td>-7.645862</td>\n",
              "      <td>-0.795612</td>\n",
              "      <td>0.830001</td>\n",
              "      <td>-6.118091</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.032956</td>\n",
              "      <td>0.001459</td>\n",
              "      <td>17.083159</td>\n",
              "      <td>15.874668</td>\n",
              "      <td>18.546013</td>\n",
              "      <td>16.412194</td>\n",
              "      <td>15.331840</td>\n",
              "      <td>14.713892</td>\n",
              "      <td>13.618339</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-536.010803</td>\n",
              "      <td>69.903397</td>\n",
              "      <td>-16.303288</td>\n",
              "      <td>32.916740</td>\n",
              "      <td>2.925880</td>\n",
              "      <td>0.171463</td>\n",
              "      <td>-12.861864</td>\n",
              "      <td>-5.886380</td>\n",
              "      <td>-12.273261</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007125</td>\n",
              "      <td>-0.016768</td>\n",
              "      <td>23.791126</td>\n",
              "      <td>19.190114</td>\n",
              "      <td>20.781159</td>\n",
              "      <td>18.825651</td>\n",
              "      <td>19.712703</td>\n",
              "      <td>20.324445</td>\n",
              "      <td>29.268788</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 195 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5523fd4-6b82-43fb-8bdf-1a025e61a7fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b5523fd4-6b82-43fb-8bdf-1a025e61a7fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b5523fd4-6b82-43fb-8bdf-1a025e61a7fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_filter =  ['angry', 'sad' , 'neutral' , 'happy']\n",
        "#376+376+376+188"
      ],
      "metadata": {
        "id": "uWvztBnCcCKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data8 = data8.loc[data8['labels'].isin(['angry', 'sad' , 'neutral' , 'happy'])]\n"
      ],
      "metadata": {
        "id": "u1eZNoE2bvmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X8 = data8.iloc[:,1:-1].values\n",
        "y8 = data8.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "wtBHokSSayRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y8 = encoder.fit_transform(y8)\n",
        "print(y8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6c1uADoiVXw",
        "outputId": "91d4be25-4cfe-46e7-9f72-1d0571ebca74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 2 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = split_scale(X8,y8)"
      ],
      "metadata": {
        "id": "mgwh2OqgidGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "X_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF8ZRU6FijHC",
        "outputId": "4da39a19-8c34-4d4e-f887-c3eade2bf617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1974, 193, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model8 = Sequential()\n",
        "\n",
        "model8.add(Conv1D(128, 3,padding='same',input_shape=(193,1)))        \n",
        "model8.add(Activation('relu'))\n",
        "model8.add(Dropout(0.1))\n",
        "model8.add(MaxPooling1D(pool_size=(2)))\n",
        "\n",
        "model8.add(Conv1D(128, 3,padding='same'))        \n",
        "model8.add(Activation('relu'))\n",
        "model8.add(MaxPooling1D(pool_size=(2)))\n",
        "model8.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model8.add(Conv1D(128, 3,padding='same'))                          \n",
        "model8.add(Activation('relu'))\n",
        "model8.add(MaxPooling1D(pool_size=(2)))\n",
        "model8.add(Dropout(0.1))\n",
        "\n",
        "model8.add(Flatten())\n",
        "model8.add(Dense(8))                                                 \n",
        "model8.add(Activation('softmax'))\n",
        "\n",
        "opt = optimizers.RMSprop(lr=0.00005, rho=0.9, epsilon=None, decay=0.0)\n",
        "model8.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDiEuFyViqJE",
        "outputId": "a2978aa7-bd74-4993-809e-ddc7fc979440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_3 (Conv1D)           (None, 193, 128)          512       \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 193, 128)          0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 193, 128)          0         \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 96, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 96, 128)           49280     \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 96, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 48, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 48, 128)           0         \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 48, 128)           49280     \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 48, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 24, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 24, 128)           0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 24584     \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 123,656\n",
            "Trainable params: 123,656\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model8.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "sQUULEoyi-pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn8 = model8.fit(X_train, y_train, batch_size=20, epochs=400, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqxFJ3VPjDdL",
        "outputId": "cab165c8-5ba9-4bc4-a909-26264f35d734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "99/99 [==============================] - 6s 50ms/step - loss: 1.7279 - accuracy: 0.3364 - val_loss: 1.2055 - val_accuracy: 0.4620\n",
            "Epoch 2/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 1.5019 - accuracy: 0.3779 - val_loss: 1.1257 - val_accuracy: 0.5228\n",
            "Epoch 3/400\n",
            "99/99 [==============================] - 5s 47ms/step - loss: 1.3438 - accuracy: 0.4235 - val_loss: 1.1401 - val_accuracy: 0.4590\n",
            "Epoch 4/400\n",
            "99/99 [==============================] - 6s 58ms/step - loss: 1.2558 - accuracy: 0.4564 - val_loss: 1.0988 - val_accuracy: 0.5334\n",
            "Epoch 5/400\n",
            "99/99 [==============================] - 10s 98ms/step - loss: 1.1936 - accuracy: 0.4757 - val_loss: 1.0292 - val_accuracy: 0.5365\n",
            "Epoch 6/400\n",
            "99/99 [==============================] - 10s 102ms/step - loss: 1.1533 - accuracy: 0.4980 - val_loss: 0.9910 - val_accuracy: 0.5805\n",
            "Epoch 7/400\n",
            "99/99 [==============================] - 8s 81ms/step - loss: 1.0932 - accuracy: 0.5162 - val_loss: 0.9571 - val_accuracy: 0.6216\n",
            "Epoch 8/400\n",
            "99/99 [==============================] - 8s 79ms/step - loss: 1.0464 - accuracy: 0.5380 - val_loss: 0.9365 - val_accuracy: 0.6292\n",
            "Epoch 9/400\n",
            "99/99 [==============================] - 10s 96ms/step - loss: 0.9936 - accuracy: 0.5750 - val_loss: 0.9103 - val_accuracy: 0.6733\n",
            "Epoch 10/400\n",
            "99/99 [==============================] - 9s 88ms/step - loss: 0.9693 - accuracy: 0.5790 - val_loss: 0.9059 - val_accuracy: 0.6839\n",
            "Epoch 11/400\n",
            "99/99 [==============================] - 8s 82ms/step - loss: 0.9385 - accuracy: 0.6018 - val_loss: 0.8868 - val_accuracy: 0.6824\n",
            "Epoch 12/400\n",
            "99/99 [==============================] - 8s 76ms/step - loss: 0.9103 - accuracy: 0.6226 - val_loss: 0.8448 - val_accuracy: 0.7097\n",
            "Epoch 13/400\n",
            "99/99 [==============================] - 8s 78ms/step - loss: 0.8859 - accuracy: 0.6277 - val_loss: 0.8217 - val_accuracy: 0.6930\n",
            "Epoch 14/400\n",
            "99/99 [==============================] - 9s 88ms/step - loss: 0.8568 - accuracy: 0.6429 - val_loss: 0.8066 - val_accuracy: 0.7021\n",
            "Epoch 15/400\n",
            "99/99 [==============================] - 9s 91ms/step - loss: 0.8414 - accuracy: 0.6535 - val_loss: 0.7961 - val_accuracy: 0.7173\n",
            "Epoch 16/400\n",
            "99/99 [==============================] - 9s 87ms/step - loss: 0.8141 - accuracy: 0.6611 - val_loss: 0.8212 - val_accuracy: 0.6733\n",
            "Epoch 17/400\n",
            "99/99 [==============================] - 8s 84ms/step - loss: 0.8009 - accuracy: 0.6743 - val_loss: 0.7610 - val_accuracy: 0.7143\n",
            "Epoch 18/400\n",
            "99/99 [==============================] - 8s 79ms/step - loss: 0.7827 - accuracy: 0.6849 - val_loss: 0.7899 - val_accuracy: 0.6945\n",
            "Epoch 19/400\n",
            "99/99 [==============================] - 8s 76ms/step - loss: 0.7604 - accuracy: 0.6940 - val_loss: 0.7371 - val_accuracy: 0.7188\n",
            "Epoch 20/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.7452 - accuracy: 0.7112 - val_loss: 0.7626 - val_accuracy: 0.6945\n",
            "Epoch 21/400\n",
            "99/99 [==============================] - 5s 47ms/step - loss: 0.7487 - accuracy: 0.6910 - val_loss: 0.7536 - val_accuracy: 0.7006\n",
            "Epoch 22/400\n",
            "99/99 [==============================] - 5s 47ms/step - loss: 0.7235 - accuracy: 0.7082 - val_loss: 0.7044 - val_accuracy: 0.7295\n",
            "Epoch 23/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.7222 - accuracy: 0.7107 - val_loss: 0.7232 - val_accuracy: 0.7036\n",
            "Epoch 24/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.7178 - accuracy: 0.7006 - val_loss: 0.6929 - val_accuracy: 0.7249\n",
            "Epoch 25/400\n",
            "99/99 [==============================] - 5s 47ms/step - loss: 0.7083 - accuracy: 0.7178 - val_loss: 0.7020 - val_accuracy: 0.7340\n",
            "Epoch 26/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.7048 - accuracy: 0.7097 - val_loss: 0.6979 - val_accuracy: 0.7280\n",
            "Epoch 27/400\n",
            "99/99 [==============================] - 5s 47ms/step - loss: 0.6823 - accuracy: 0.7275 - val_loss: 0.6995 - val_accuracy: 0.7249\n",
            "Epoch 28/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.6820 - accuracy: 0.7264 - val_loss: 0.6737 - val_accuracy: 0.7386\n",
            "Epoch 29/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.6731 - accuracy: 0.7239 - val_loss: 0.6594 - val_accuracy: 0.7462\n",
            "Epoch 30/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.6675 - accuracy: 0.7325 - val_loss: 0.6711 - val_accuracy: 0.7340\n",
            "Epoch 31/400\n",
            "99/99 [==============================] - 5s 47ms/step - loss: 0.6666 - accuracy: 0.7305 - val_loss: 0.6710 - val_accuracy: 0.7416\n",
            "Epoch 32/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.6573 - accuracy: 0.7305 - val_loss: 0.6647 - val_accuracy: 0.7264\n",
            "Epoch 33/400\n",
            "99/99 [==============================] - 5s 47ms/step - loss: 0.6463 - accuracy: 0.7335 - val_loss: 0.6522 - val_accuracy: 0.7340\n",
            "Epoch 34/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.6383 - accuracy: 0.7437 - val_loss: 0.6438 - val_accuracy: 0.7295\n",
            "Epoch 35/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.6295 - accuracy: 0.7381 - val_loss: 0.6515 - val_accuracy: 0.7325\n",
            "Epoch 36/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.6277 - accuracy: 0.7432 - val_loss: 0.6352 - val_accuracy: 0.7386\n",
            "Epoch 37/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.6205 - accuracy: 0.7467 - val_loss: 0.6787 - val_accuracy: 0.7204\n",
            "Epoch 38/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.6225 - accuracy: 0.7497 - val_loss: 0.6237 - val_accuracy: 0.7416\n",
            "Epoch 39/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.6200 - accuracy: 0.7371 - val_loss: 0.6971 - val_accuracy: 0.7143\n",
            "Epoch 40/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.6133 - accuracy: 0.7523 - val_loss: 0.6462 - val_accuracy: 0.7295\n",
            "Epoch 41/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.6010 - accuracy: 0.7523 - val_loss: 0.6406 - val_accuracy: 0.7447\n",
            "Epoch 42/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.5855 - accuracy: 0.7624 - val_loss: 0.6355 - val_accuracy: 0.7371\n",
            "Epoch 43/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.5934 - accuracy: 0.7634 - val_loss: 0.6882 - val_accuracy: 0.7249\n",
            "Epoch 44/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.5805 - accuracy: 0.7710 - val_loss: 0.6340 - val_accuracy: 0.7386\n",
            "Epoch 45/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.5753 - accuracy: 0.7695 - val_loss: 0.6003 - val_accuracy: 0.7462\n",
            "Epoch 46/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.5784 - accuracy: 0.7619 - val_loss: 0.6041 - val_accuracy: 0.7462\n",
            "Epoch 47/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.5767 - accuracy: 0.7695 - val_loss: 0.6419 - val_accuracy: 0.7310\n",
            "Epoch 48/400\n",
            "99/99 [==============================] - 5s 47ms/step - loss: 0.5654 - accuracy: 0.7644 - val_loss: 0.6199 - val_accuracy: 0.7447\n",
            "Epoch 49/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.5706 - accuracy: 0.7705 - val_loss: 0.6054 - val_accuracy: 0.7462\n",
            "Epoch 50/400\n",
            "99/99 [==============================] - 5s 47ms/step - loss: 0.5513 - accuracy: 0.7751 - val_loss: 0.5783 - val_accuracy: 0.7492\n",
            "Epoch 51/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.5542 - accuracy: 0.7720 - val_loss: 0.5945 - val_accuracy: 0.7553\n",
            "Epoch 52/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.5529 - accuracy: 0.7756 - val_loss: 0.5880 - val_accuracy: 0.7523\n",
            "Epoch 53/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.5458 - accuracy: 0.7837 - val_loss: 0.6002 - val_accuracy: 0.7553\n",
            "Epoch 54/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.5428 - accuracy: 0.7746 - val_loss: 0.5998 - val_accuracy: 0.7523\n",
            "Epoch 55/400\n",
            "99/99 [==============================] - 6s 61ms/step - loss: 0.5522 - accuracy: 0.7720 - val_loss: 0.5759 - val_accuracy: 0.7538\n",
            "Epoch 56/400\n",
            "99/99 [==============================] - 5s 47ms/step - loss: 0.5479 - accuracy: 0.7771 - val_loss: 0.6018 - val_accuracy: 0.7538\n",
            "Epoch 57/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.5409 - accuracy: 0.7781 - val_loss: 0.6121 - val_accuracy: 0.7295\n",
            "Epoch 58/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.5286 - accuracy: 0.7766 - val_loss: 0.5648 - val_accuracy: 0.7568\n",
            "Epoch 59/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.5276 - accuracy: 0.7751 - val_loss: 0.5967 - val_accuracy: 0.7523\n",
            "Epoch 60/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.5272 - accuracy: 0.7862 - val_loss: 0.5711 - val_accuracy: 0.7568\n",
            "Epoch 61/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.5166 - accuracy: 0.7964 - val_loss: 0.5763 - val_accuracy: 0.7568\n",
            "Epoch 62/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.5071 - accuracy: 0.7923 - val_loss: 0.5852 - val_accuracy: 0.7599\n",
            "Epoch 63/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.5094 - accuracy: 0.7837 - val_loss: 0.5465 - val_accuracy: 0.7644\n",
            "Epoch 64/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.5195 - accuracy: 0.7801 - val_loss: 0.5599 - val_accuracy: 0.7614\n",
            "Epoch 65/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.5041 - accuracy: 0.7893 - val_loss: 0.5422 - val_accuracy: 0.7736\n",
            "Epoch 66/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.5140 - accuracy: 0.7867 - val_loss: 0.5452 - val_accuracy: 0.7751\n",
            "Epoch 67/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.5031 - accuracy: 0.7989 - val_loss: 0.5887 - val_accuracy: 0.7538\n",
            "Epoch 68/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.5018 - accuracy: 0.7999 - val_loss: 0.5647 - val_accuracy: 0.7720\n",
            "Epoch 69/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.5010 - accuracy: 0.7882 - val_loss: 0.5525 - val_accuracy: 0.7629\n",
            "Epoch 70/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4939 - accuracy: 0.7908 - val_loss: 0.5445 - val_accuracy: 0.7751\n",
            "Epoch 71/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4797 - accuracy: 0.7994 - val_loss: 0.5505 - val_accuracy: 0.7751\n",
            "Epoch 72/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.4870 - accuracy: 0.8029 - val_loss: 0.5355 - val_accuracy: 0.7766\n",
            "Epoch 73/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4780 - accuracy: 0.8065 - val_loss: 0.5390 - val_accuracy: 0.7736\n",
            "Epoch 74/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4978 - accuracy: 0.8040 - val_loss: 0.5246 - val_accuracy: 0.7872\n",
            "Epoch 75/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4842 - accuracy: 0.7989 - val_loss: 0.5318 - val_accuracy: 0.7842\n",
            "Epoch 76/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4782 - accuracy: 0.8034 - val_loss: 0.5279 - val_accuracy: 0.7751\n",
            "Epoch 77/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4742 - accuracy: 0.8055 - val_loss: 0.5351 - val_accuracy: 0.7736\n",
            "Epoch 78/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.4621 - accuracy: 0.8141 - val_loss: 0.5280 - val_accuracy: 0.7872\n",
            "Epoch 79/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.4693 - accuracy: 0.8024 - val_loss: 0.5233 - val_accuracy: 0.7827\n",
            "Epoch 80/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.4686 - accuracy: 0.8029 - val_loss: 0.5134 - val_accuracy: 0.7872\n",
            "Epoch 81/400\n",
            "99/99 [==============================] - 6s 58ms/step - loss: 0.4647 - accuracy: 0.8080 - val_loss: 0.5116 - val_accuracy: 0.7827\n",
            "Epoch 82/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.4600 - accuracy: 0.8191 - val_loss: 0.5319 - val_accuracy: 0.7827\n",
            "Epoch 83/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.4572 - accuracy: 0.8126 - val_loss: 0.5124 - val_accuracy: 0.7888\n",
            "Epoch 84/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.4551 - accuracy: 0.8186 - val_loss: 0.5617 - val_accuracy: 0.7644\n",
            "Epoch 85/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.4533 - accuracy: 0.8176 - val_loss: 0.5050 - val_accuracy: 0.7948\n",
            "Epoch 86/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.4458 - accuracy: 0.8176 - val_loss: 0.5100 - val_accuracy: 0.7903\n",
            "Epoch 87/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4524 - accuracy: 0.8197 - val_loss: 0.5229 - val_accuracy: 0.7827\n",
            "Epoch 88/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.4429 - accuracy: 0.8232 - val_loss: 0.5346 - val_accuracy: 0.7675\n",
            "Epoch 89/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4423 - accuracy: 0.8217 - val_loss: 0.5101 - val_accuracy: 0.7872\n",
            "Epoch 90/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.4337 - accuracy: 0.8176 - val_loss: 0.5025 - val_accuracy: 0.7872\n",
            "Epoch 91/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.4407 - accuracy: 0.8136 - val_loss: 0.5178 - val_accuracy: 0.7827\n",
            "Epoch 92/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.4269 - accuracy: 0.8247 - val_loss: 0.5338 - val_accuracy: 0.7781\n",
            "Epoch 93/400\n",
            "99/99 [==============================] - 5s 47ms/step - loss: 0.4367 - accuracy: 0.8191 - val_loss: 0.5190 - val_accuracy: 0.7796\n",
            "Epoch 94/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.4351 - accuracy: 0.8166 - val_loss: 0.4929 - val_accuracy: 0.7948\n",
            "Epoch 95/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4384 - accuracy: 0.8181 - val_loss: 0.5015 - val_accuracy: 0.7842\n",
            "Epoch 96/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4273 - accuracy: 0.8212 - val_loss: 0.4865 - val_accuracy: 0.7933\n",
            "Epoch 97/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.4185 - accuracy: 0.8354 - val_loss: 0.4976 - val_accuracy: 0.7842\n",
            "Epoch 98/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.4296 - accuracy: 0.8349 - val_loss: 0.5203 - val_accuracy: 0.7781\n",
            "Epoch 99/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.4229 - accuracy: 0.8278 - val_loss: 0.5223 - val_accuracy: 0.7827\n",
            "Epoch 100/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4145 - accuracy: 0.8247 - val_loss: 0.4932 - val_accuracy: 0.7918\n",
            "Epoch 101/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.4122 - accuracy: 0.8262 - val_loss: 0.4885 - val_accuracy: 0.7903\n",
            "Epoch 102/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4057 - accuracy: 0.8389 - val_loss: 0.5113 - val_accuracy: 0.7736\n",
            "Epoch 103/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4139 - accuracy: 0.8303 - val_loss: 0.5051 - val_accuracy: 0.7918\n",
            "Epoch 104/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4090 - accuracy: 0.8308 - val_loss: 0.4905 - val_accuracy: 0.7903\n",
            "Epoch 105/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.4011 - accuracy: 0.8359 - val_loss: 0.5134 - val_accuracy: 0.7842\n",
            "Epoch 106/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3962 - accuracy: 0.8419 - val_loss: 0.5063 - val_accuracy: 0.7796\n",
            "Epoch 107/400\n",
            "99/99 [==============================] - 6s 60ms/step - loss: 0.4094 - accuracy: 0.8273 - val_loss: 0.4833 - val_accuracy: 0.7994\n",
            "Epoch 108/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.4032 - accuracy: 0.8308 - val_loss: 0.4877 - val_accuracy: 0.7979\n",
            "Epoch 109/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.4021 - accuracy: 0.8318 - val_loss: 0.4774 - val_accuracy: 0.7948\n",
            "Epoch 110/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3893 - accuracy: 0.8379 - val_loss: 0.4961 - val_accuracy: 0.7857\n",
            "Epoch 111/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3842 - accuracy: 0.8419 - val_loss: 0.4917 - val_accuracy: 0.7812\n",
            "Epoch 112/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3811 - accuracy: 0.8465 - val_loss: 0.5245 - val_accuracy: 0.7705\n",
            "Epoch 113/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3867 - accuracy: 0.8531 - val_loss: 0.4728 - val_accuracy: 0.7918\n",
            "Epoch 114/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3897 - accuracy: 0.8435 - val_loss: 0.4677 - val_accuracy: 0.8009\n",
            "Epoch 115/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3694 - accuracy: 0.8511 - val_loss: 0.4668 - val_accuracy: 0.8024\n",
            "Epoch 116/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3869 - accuracy: 0.8501 - val_loss: 0.4690 - val_accuracy: 0.8009\n",
            "Epoch 117/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.3782 - accuracy: 0.8435 - val_loss: 0.4738 - val_accuracy: 0.7964\n",
            "Epoch 118/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3913 - accuracy: 0.8414 - val_loss: 0.4762 - val_accuracy: 0.7964\n",
            "Epoch 119/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.3727 - accuracy: 0.8430 - val_loss: 0.4790 - val_accuracy: 0.7948\n",
            "Epoch 120/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.3796 - accuracy: 0.8419 - val_loss: 0.4842 - val_accuracy: 0.7918\n",
            "Epoch 121/400\n",
            "99/99 [==============================] - 6s 61ms/step - loss: 0.3690 - accuracy: 0.8516 - val_loss: 0.4862 - val_accuracy: 0.7872\n",
            "Epoch 122/400\n",
            "99/99 [==============================] - 6s 56ms/step - loss: 0.3767 - accuracy: 0.8485 - val_loss: 0.4686 - val_accuracy: 0.8055\n",
            "Epoch 123/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3607 - accuracy: 0.8551 - val_loss: 0.4831 - val_accuracy: 0.7888\n",
            "Epoch 124/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3697 - accuracy: 0.8435 - val_loss: 0.4779 - val_accuracy: 0.7964\n",
            "Epoch 125/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3845 - accuracy: 0.8445 - val_loss: 0.4790 - val_accuracy: 0.7964\n",
            "Epoch 126/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3538 - accuracy: 0.8607 - val_loss: 0.4922 - val_accuracy: 0.7872\n",
            "Epoch 127/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3692 - accuracy: 0.8485 - val_loss: 0.5149 - val_accuracy: 0.7736\n",
            "Epoch 128/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3694 - accuracy: 0.8506 - val_loss: 0.4625 - val_accuracy: 0.8024\n",
            "Epoch 129/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3686 - accuracy: 0.8455 - val_loss: 0.4578 - val_accuracy: 0.8055\n",
            "Epoch 130/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3558 - accuracy: 0.8658 - val_loss: 0.4614 - val_accuracy: 0.8131\n",
            "Epoch 131/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3564 - accuracy: 0.8597 - val_loss: 0.4649 - val_accuracy: 0.7994\n",
            "Epoch 132/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.3495 - accuracy: 0.8582 - val_loss: 0.4596 - val_accuracy: 0.7994\n",
            "Epoch 133/400\n",
            "99/99 [==============================] - 6s 62ms/step - loss: 0.3535 - accuracy: 0.8526 - val_loss: 0.4755 - val_accuracy: 0.7964\n",
            "Epoch 134/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3506 - accuracy: 0.8637 - val_loss: 0.4582 - val_accuracy: 0.8055\n",
            "Epoch 135/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3517 - accuracy: 0.8551 - val_loss: 0.4722 - val_accuracy: 0.7979\n",
            "Epoch 136/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3459 - accuracy: 0.8592 - val_loss: 0.4758 - val_accuracy: 0.7918\n",
            "Epoch 137/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.3470 - accuracy: 0.8642 - val_loss: 0.4605 - val_accuracy: 0.8055\n",
            "Epoch 138/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3301 - accuracy: 0.8744 - val_loss: 0.4542 - val_accuracy: 0.8009\n",
            "Epoch 139/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3368 - accuracy: 0.8612 - val_loss: 0.4451 - val_accuracy: 0.8116\n",
            "Epoch 140/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3385 - accuracy: 0.8602 - val_loss: 0.4454 - val_accuracy: 0.8131\n",
            "Epoch 141/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3358 - accuracy: 0.8566 - val_loss: 0.4758 - val_accuracy: 0.7933\n",
            "Epoch 142/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3483 - accuracy: 0.8612 - val_loss: 0.4700 - val_accuracy: 0.8040\n",
            "Epoch 143/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3398 - accuracy: 0.8663 - val_loss: 0.4557 - val_accuracy: 0.8100\n",
            "Epoch 144/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3378 - accuracy: 0.8658 - val_loss: 0.4456 - val_accuracy: 0.8131\n",
            "Epoch 145/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3344 - accuracy: 0.8718 - val_loss: 0.4455 - val_accuracy: 0.8161\n",
            "Epoch 146/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3202 - accuracy: 0.8678 - val_loss: 0.4542 - val_accuracy: 0.8100\n",
            "Epoch 147/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3259 - accuracy: 0.8734 - val_loss: 0.4639 - val_accuracy: 0.8055\n",
            "Epoch 148/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3257 - accuracy: 0.8718 - val_loss: 0.4723 - val_accuracy: 0.8009\n",
            "Epoch 149/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3269 - accuracy: 0.8658 - val_loss: 0.4774 - val_accuracy: 0.7948\n",
            "Epoch 150/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3359 - accuracy: 0.8637 - val_loss: 0.4487 - val_accuracy: 0.8040\n",
            "Epoch 151/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.3197 - accuracy: 0.8774 - val_loss: 0.4558 - val_accuracy: 0.8040\n",
            "Epoch 152/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3278 - accuracy: 0.8627 - val_loss: 0.4533 - val_accuracy: 0.8085\n",
            "Epoch 153/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3157 - accuracy: 0.8739 - val_loss: 0.4412 - val_accuracy: 0.8191\n",
            "Epoch 154/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3221 - accuracy: 0.8713 - val_loss: 0.4471 - val_accuracy: 0.8161\n",
            "Epoch 155/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3105 - accuracy: 0.8703 - val_loss: 0.4572 - val_accuracy: 0.8100\n",
            "Epoch 156/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3203 - accuracy: 0.8728 - val_loss: 0.4624 - val_accuracy: 0.8040\n",
            "Epoch 157/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3026 - accuracy: 0.8845 - val_loss: 0.4778 - val_accuracy: 0.8085\n",
            "Epoch 158/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.3128 - accuracy: 0.8754 - val_loss: 0.4762 - val_accuracy: 0.8070\n",
            "Epoch 159/400\n",
            "99/99 [==============================] - 6s 58ms/step - loss: 0.3146 - accuracy: 0.8754 - val_loss: 0.4813 - val_accuracy: 0.7979\n",
            "Epoch 160/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3114 - accuracy: 0.8845 - val_loss: 0.4425 - val_accuracy: 0.8176\n",
            "Epoch 161/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2989 - accuracy: 0.8870 - val_loss: 0.4653 - val_accuracy: 0.8116\n",
            "Epoch 162/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2968 - accuracy: 0.8911 - val_loss: 0.4401 - val_accuracy: 0.8161\n",
            "Epoch 163/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.3112 - accuracy: 0.8764 - val_loss: 0.4383 - val_accuracy: 0.8191\n",
            "Epoch 164/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3001 - accuracy: 0.8784 - val_loss: 0.4425 - val_accuracy: 0.8131\n",
            "Epoch 165/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.3033 - accuracy: 0.8825 - val_loss: 0.4927 - val_accuracy: 0.7933\n",
            "Epoch 166/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2972 - accuracy: 0.8810 - val_loss: 0.4690 - val_accuracy: 0.7933\n",
            "Epoch 167/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2994 - accuracy: 0.8744 - val_loss: 0.4410 - val_accuracy: 0.8267\n",
            "Epoch 168/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2905 - accuracy: 0.8891 - val_loss: 0.4509 - val_accuracy: 0.8131\n",
            "Epoch 169/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.3003 - accuracy: 0.8825 - val_loss: 0.4547 - val_accuracy: 0.8131\n",
            "Epoch 170/400\n",
            "99/99 [==============================] - 5s 48ms/step - loss: 0.2946 - accuracy: 0.8880 - val_loss: 0.4415 - val_accuracy: 0.8267\n",
            "Epoch 171/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2992 - accuracy: 0.8744 - val_loss: 0.4580 - val_accuracy: 0.8146\n",
            "Epoch 172/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2936 - accuracy: 0.8840 - val_loss: 0.4442 - val_accuracy: 0.8161\n",
            "Epoch 173/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2991 - accuracy: 0.8815 - val_loss: 0.4355 - val_accuracy: 0.8313\n",
            "Epoch 174/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.2878 - accuracy: 0.8901 - val_loss: 0.4318 - val_accuracy: 0.8207\n",
            "Epoch 175/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.2873 - accuracy: 0.8875 - val_loss: 0.4382 - val_accuracy: 0.8252\n",
            "Epoch 176/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2965 - accuracy: 0.8901 - val_loss: 0.4529 - val_accuracy: 0.8161\n",
            "Epoch 177/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2852 - accuracy: 0.8855 - val_loss: 0.4536 - val_accuracy: 0.8131\n",
            "Epoch 178/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2818 - accuracy: 0.8896 - val_loss: 0.4294 - val_accuracy: 0.8283\n",
            "Epoch 179/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2724 - accuracy: 0.8946 - val_loss: 0.4404 - val_accuracy: 0.8237\n",
            "Epoch 180/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2956 - accuracy: 0.8880 - val_loss: 0.4347 - val_accuracy: 0.8207\n",
            "Epoch 181/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2872 - accuracy: 0.8926 - val_loss: 0.4516 - val_accuracy: 0.8116\n",
            "Epoch 182/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.2756 - accuracy: 0.8911 - val_loss: 0.4521 - val_accuracy: 0.8161\n",
            "Epoch 183/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2734 - accuracy: 0.8941 - val_loss: 0.4294 - val_accuracy: 0.8343\n",
            "Epoch 184/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.2703 - accuracy: 0.8982 - val_loss: 0.4531 - val_accuracy: 0.8161\n",
            "Epoch 185/400\n",
            "99/99 [==============================] - 6s 59ms/step - loss: 0.2783 - accuracy: 0.8906 - val_loss: 0.4416 - val_accuracy: 0.8252\n",
            "Epoch 186/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2748 - accuracy: 0.8906 - val_loss: 0.4244 - val_accuracy: 0.8283\n",
            "Epoch 187/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2683 - accuracy: 0.8982 - val_loss: 0.4505 - val_accuracy: 0.8267\n",
            "Epoch 188/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2596 - accuracy: 0.8987 - val_loss: 0.4488 - val_accuracy: 0.8267\n",
            "Epoch 189/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2738 - accuracy: 0.8992 - val_loss: 0.4993 - val_accuracy: 0.8055\n",
            "Epoch 190/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2648 - accuracy: 0.8951 - val_loss: 0.4362 - val_accuracy: 0.8298\n",
            "Epoch 191/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2598 - accuracy: 0.8997 - val_loss: 0.4612 - val_accuracy: 0.8176\n",
            "Epoch 192/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2528 - accuracy: 0.9068 - val_loss: 0.4307 - val_accuracy: 0.8267\n",
            "Epoch 193/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2562 - accuracy: 0.9017 - val_loss: 0.4441 - val_accuracy: 0.8267\n",
            "Epoch 194/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2680 - accuracy: 0.8916 - val_loss: 0.4439 - val_accuracy: 0.8298\n",
            "Epoch 195/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2678 - accuracy: 0.8896 - val_loss: 0.4275 - val_accuracy: 0.8298\n",
            "Epoch 196/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2600 - accuracy: 0.8956 - val_loss: 0.4456 - val_accuracy: 0.8267\n",
            "Epoch 197/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2520 - accuracy: 0.8997 - val_loss: 0.4427 - val_accuracy: 0.8252\n",
            "Epoch 198/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2667 - accuracy: 0.8946 - val_loss: 0.4416 - val_accuracy: 0.8237\n",
            "Epoch 199/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2576 - accuracy: 0.9012 - val_loss: 0.4181 - val_accuracy: 0.8389\n",
            "Epoch 200/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2549 - accuracy: 0.8992 - val_loss: 0.4448 - val_accuracy: 0.8191\n",
            "Epoch 201/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2514 - accuracy: 0.9037 - val_loss: 0.4635 - val_accuracy: 0.8161\n",
            "Epoch 202/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2580 - accuracy: 0.9012 - val_loss: 0.4244 - val_accuracy: 0.8359\n",
            "Epoch 203/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.2491 - accuracy: 0.9022 - val_loss: 0.4322 - val_accuracy: 0.8343\n",
            "Epoch 204/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2558 - accuracy: 0.8982 - val_loss: 0.4392 - val_accuracy: 0.8283\n",
            "Epoch 205/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2443 - accuracy: 0.9078 - val_loss: 0.4271 - val_accuracy: 0.8328\n",
            "Epoch 206/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2385 - accuracy: 0.9144 - val_loss: 0.4339 - val_accuracy: 0.8298\n",
            "Epoch 207/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2414 - accuracy: 0.9103 - val_loss: 0.4344 - val_accuracy: 0.8237\n",
            "Epoch 208/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2566 - accuracy: 0.8982 - val_loss: 0.4553 - val_accuracy: 0.8267\n",
            "Epoch 209/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.2453 - accuracy: 0.9083 - val_loss: 0.4297 - val_accuracy: 0.8389\n",
            "Epoch 210/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.2404 - accuracy: 0.9073 - val_loss: 0.4422 - val_accuracy: 0.8161\n",
            "Epoch 211/400\n",
            "99/99 [==============================] - 6s 59ms/step - loss: 0.2443 - accuracy: 0.9098 - val_loss: 0.4208 - val_accuracy: 0.8389\n",
            "Epoch 212/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2492 - accuracy: 0.9073 - val_loss: 0.4230 - val_accuracy: 0.8435\n",
            "Epoch 213/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2448 - accuracy: 0.8992 - val_loss: 0.4219 - val_accuracy: 0.8404\n",
            "Epoch 214/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2379 - accuracy: 0.9129 - val_loss: 0.4400 - val_accuracy: 0.8222\n",
            "Epoch 215/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.2337 - accuracy: 0.9154 - val_loss: 0.4321 - val_accuracy: 0.8298\n",
            "Epoch 216/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.2273 - accuracy: 0.9164 - val_loss: 0.4255 - val_accuracy: 0.8343\n",
            "Epoch 217/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.2305 - accuracy: 0.9124 - val_loss: 0.4299 - val_accuracy: 0.8343\n",
            "Epoch 218/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.2258 - accuracy: 0.9169 - val_loss: 0.4286 - val_accuracy: 0.8328\n",
            "Epoch 219/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.2395 - accuracy: 0.9134 - val_loss: 0.4383 - val_accuracy: 0.8343\n",
            "Epoch 220/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.2312 - accuracy: 0.9103 - val_loss: 0.4229 - val_accuracy: 0.8374\n",
            "Epoch 221/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.2366 - accuracy: 0.9129 - val_loss: 0.4323 - val_accuracy: 0.8343\n",
            "Epoch 222/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.2349 - accuracy: 0.9179 - val_loss: 0.4224 - val_accuracy: 0.8419\n",
            "Epoch 223/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2311 - accuracy: 0.9093 - val_loss: 0.4377 - val_accuracy: 0.8343\n",
            "Epoch 224/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2197 - accuracy: 0.9205 - val_loss: 0.4205 - val_accuracy: 0.8435\n",
            "Epoch 225/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2314 - accuracy: 0.9108 - val_loss: 0.4440 - val_accuracy: 0.8389\n",
            "Epoch 226/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.2305 - accuracy: 0.9144 - val_loss: 0.4161 - val_accuracy: 0.8450\n",
            "Epoch 227/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.2202 - accuracy: 0.9124 - val_loss: 0.4582 - val_accuracy: 0.8283\n",
            "Epoch 228/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2290 - accuracy: 0.9048 - val_loss: 0.4302 - val_accuracy: 0.8374\n",
            "Epoch 229/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2242 - accuracy: 0.9159 - val_loss: 0.4305 - val_accuracy: 0.8343\n",
            "Epoch 230/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2236 - accuracy: 0.9164 - val_loss: 0.4325 - val_accuracy: 0.8283\n",
            "Epoch 231/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.2187 - accuracy: 0.9154 - val_loss: 0.4155 - val_accuracy: 0.8435\n",
            "Epoch 232/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.2344 - accuracy: 0.9053 - val_loss: 0.4359 - val_accuracy: 0.8359\n",
            "Epoch 233/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.2255 - accuracy: 0.9088 - val_loss: 0.4416 - val_accuracy: 0.8404\n",
            "Epoch 234/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.2105 - accuracy: 0.9195 - val_loss: 0.4168 - val_accuracy: 0.8495\n",
            "Epoch 235/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.2191 - accuracy: 0.9113 - val_loss: 0.4333 - val_accuracy: 0.8389\n",
            "Epoch 236/400\n",
            "99/99 [==============================] - 6s 62ms/step - loss: 0.2106 - accuracy: 0.9169 - val_loss: 0.4345 - val_accuracy: 0.8328\n",
            "Epoch 237/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2187 - accuracy: 0.9134 - val_loss: 0.4326 - val_accuracy: 0.8359\n",
            "Epoch 238/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.2122 - accuracy: 0.9179 - val_loss: 0.4210 - val_accuracy: 0.8450\n",
            "Epoch 239/400\n",
            "99/99 [==============================] - 6s 58ms/step - loss: 0.2049 - accuracy: 0.9260 - val_loss: 0.4361 - val_accuracy: 0.8374\n",
            "Epoch 240/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.2083 - accuracy: 0.9205 - val_loss: 0.4464 - val_accuracy: 0.8328\n",
            "Epoch 241/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.2173 - accuracy: 0.9174 - val_loss: 0.4282 - val_accuracy: 0.8450\n",
            "Epoch 242/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2163 - accuracy: 0.9240 - val_loss: 0.4525 - val_accuracy: 0.8313\n",
            "Epoch 243/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2195 - accuracy: 0.9215 - val_loss: 0.4197 - val_accuracy: 0.8435\n",
            "Epoch 244/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2152 - accuracy: 0.9124 - val_loss: 0.4214 - val_accuracy: 0.8389\n",
            "Epoch 245/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2089 - accuracy: 0.9245 - val_loss: 0.4201 - val_accuracy: 0.8450\n",
            "Epoch 246/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2134 - accuracy: 0.9195 - val_loss: 0.4151 - val_accuracy: 0.8419\n",
            "Epoch 247/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2089 - accuracy: 0.9154 - val_loss: 0.4229 - val_accuracy: 0.8465\n",
            "Epoch 248/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.2071 - accuracy: 0.9230 - val_loss: 0.4345 - val_accuracy: 0.8465\n",
            "Epoch 249/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.1973 - accuracy: 0.9210 - val_loss: 0.4173 - val_accuracy: 0.8526\n",
            "Epoch 250/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.2056 - accuracy: 0.9271 - val_loss: 0.4162 - val_accuracy: 0.8556\n",
            "Epoch 251/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.1955 - accuracy: 0.9352 - val_loss: 0.4198 - val_accuracy: 0.8465\n",
            "Epoch 252/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.2017 - accuracy: 0.9265 - val_loss: 0.4191 - val_accuracy: 0.8571\n",
            "Epoch 253/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.1914 - accuracy: 0.9306 - val_loss: 0.4181 - val_accuracy: 0.8511\n",
            "Epoch 254/400\n",
            "99/99 [==============================] - 5s 49ms/step - loss: 0.1952 - accuracy: 0.9250 - val_loss: 0.4387 - val_accuracy: 0.8404\n",
            "Epoch 255/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.2052 - accuracy: 0.9255 - val_loss: 0.4309 - val_accuracy: 0.8389\n",
            "Epoch 256/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.1928 - accuracy: 0.9230 - val_loss: 0.4356 - val_accuracy: 0.8450\n",
            "Epoch 257/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.1936 - accuracy: 0.9296 - val_loss: 0.4348 - val_accuracy: 0.8419\n",
            "Epoch 258/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.1979 - accuracy: 0.9250 - val_loss: 0.4287 - val_accuracy: 0.8480\n",
            "Epoch 259/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.1906 - accuracy: 0.9281 - val_loss: 0.4307 - val_accuracy: 0.8404\n",
            "Epoch 260/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.1893 - accuracy: 0.9255 - val_loss: 0.4266 - val_accuracy: 0.8465\n",
            "Epoch 261/400\n",
            "99/99 [==============================] - 6s 63ms/step - loss: 0.1837 - accuracy: 0.9301 - val_loss: 0.4338 - val_accuracy: 0.8495\n",
            "Epoch 262/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1870 - accuracy: 0.9276 - val_loss: 0.4432 - val_accuracy: 0.8450\n",
            "Epoch 263/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1922 - accuracy: 0.9286 - val_loss: 0.4625 - val_accuracy: 0.8267\n",
            "Epoch 264/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.1896 - accuracy: 0.9230 - val_loss: 0.4370 - val_accuracy: 0.8359\n",
            "Epoch 265/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1938 - accuracy: 0.9255 - val_loss: 0.4193 - val_accuracy: 0.8495\n",
            "Epoch 266/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.1886 - accuracy: 0.9230 - val_loss: 0.4210 - val_accuracy: 0.8541\n",
            "Epoch 267/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.1910 - accuracy: 0.9271 - val_loss: 0.4315 - val_accuracy: 0.8404\n",
            "Epoch 268/400\n",
            "99/99 [==============================] - 5s 50ms/step - loss: 0.2002 - accuracy: 0.9210 - val_loss: 0.4149 - val_accuracy: 0.8526\n",
            "Epoch 269/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1929 - accuracy: 0.9281 - val_loss: 0.4295 - val_accuracy: 0.8541\n",
            "Epoch 270/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.1835 - accuracy: 0.9367 - val_loss: 0.4229 - val_accuracy: 0.8465\n",
            "Epoch 271/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.1849 - accuracy: 0.9255 - val_loss: 0.4185 - val_accuracy: 0.8495\n",
            "Epoch 272/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.1880 - accuracy: 0.9311 - val_loss: 0.4174 - val_accuracy: 0.8511\n",
            "Epoch 273/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.1841 - accuracy: 0.9367 - val_loss: 0.4455 - val_accuracy: 0.8465\n",
            "Epoch 274/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1836 - accuracy: 0.9271 - val_loss: 0.4269 - val_accuracy: 0.8480\n",
            "Epoch 275/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1866 - accuracy: 0.9250 - val_loss: 0.4248 - val_accuracy: 0.8450\n",
            "Epoch 276/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.1839 - accuracy: 0.9316 - val_loss: 0.4240 - val_accuracy: 0.8571\n",
            "Epoch 277/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1806 - accuracy: 0.9271 - val_loss: 0.4550 - val_accuracy: 0.8389\n",
            "Epoch 278/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.1833 - accuracy: 0.9316 - val_loss: 0.4304 - val_accuracy: 0.8587\n",
            "Epoch 279/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.1772 - accuracy: 0.9382 - val_loss: 0.4262 - val_accuracy: 0.8632\n",
            "Epoch 280/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1789 - accuracy: 0.9326 - val_loss: 0.4216 - val_accuracy: 0.8526\n",
            "Epoch 281/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.1825 - accuracy: 0.9281 - val_loss: 0.4304 - val_accuracy: 0.8617\n",
            "Epoch 282/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1699 - accuracy: 0.9362 - val_loss: 0.4482 - val_accuracy: 0.8465\n",
            "Epoch 283/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1808 - accuracy: 0.9331 - val_loss: 0.4427 - val_accuracy: 0.8450\n",
            "Epoch 284/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1761 - accuracy: 0.9382 - val_loss: 0.4324 - val_accuracy: 0.8495\n",
            "Epoch 285/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1717 - accuracy: 0.9341 - val_loss: 0.4243 - val_accuracy: 0.8587\n",
            "Epoch 286/400\n",
            "99/99 [==============================] - 6s 65ms/step - loss: 0.1704 - accuracy: 0.9387 - val_loss: 0.4290 - val_accuracy: 0.8511\n",
            "Epoch 287/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1732 - accuracy: 0.9392 - val_loss: 0.4327 - val_accuracy: 0.8526\n",
            "Epoch 288/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1689 - accuracy: 0.9372 - val_loss: 0.4528 - val_accuracy: 0.8389\n",
            "Epoch 289/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.1759 - accuracy: 0.9347 - val_loss: 0.4242 - val_accuracy: 0.8526\n",
            "Epoch 290/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1664 - accuracy: 0.9362 - val_loss: 0.4300 - val_accuracy: 0.8511\n",
            "Epoch 291/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1671 - accuracy: 0.9377 - val_loss: 0.4381 - val_accuracy: 0.8465\n",
            "Epoch 292/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1713 - accuracy: 0.9352 - val_loss: 0.4310 - val_accuracy: 0.8541\n",
            "Epoch 293/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1605 - accuracy: 0.9397 - val_loss: 0.4301 - val_accuracy: 0.8571\n",
            "Epoch 294/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1674 - accuracy: 0.9352 - val_loss: 0.4561 - val_accuracy: 0.8465\n",
            "Epoch 295/400\n",
            "99/99 [==============================] - 5s 51ms/step - loss: 0.1676 - accuracy: 0.9392 - val_loss: 0.4395 - val_accuracy: 0.8526\n",
            "Epoch 296/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1564 - accuracy: 0.9458 - val_loss: 0.4224 - val_accuracy: 0.8602\n",
            "Epoch 297/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1642 - accuracy: 0.9362 - val_loss: 0.4281 - val_accuracy: 0.8571\n",
            "Epoch 298/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1613 - accuracy: 0.9387 - val_loss: 0.4523 - val_accuracy: 0.8435\n",
            "Epoch 299/400\n",
            "99/99 [==============================] - 6s 56ms/step - loss: 0.1716 - accuracy: 0.9336 - val_loss: 0.4332 - val_accuracy: 0.8511\n",
            "Epoch 300/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1636 - accuracy: 0.9372 - val_loss: 0.4195 - val_accuracy: 0.8587\n",
            "Epoch 301/400\n",
            "99/99 [==============================] - 6s 56ms/step - loss: 0.1574 - accuracy: 0.9377 - val_loss: 0.4262 - val_accuracy: 0.8571\n",
            "Epoch 302/400\n",
            "99/99 [==============================] - 6s 56ms/step - loss: 0.1639 - accuracy: 0.9377 - val_loss: 0.4301 - val_accuracy: 0.8587\n",
            "Epoch 303/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1599 - accuracy: 0.9428 - val_loss: 0.4292 - val_accuracy: 0.8556\n",
            "Epoch 304/400\n",
            "99/99 [==============================] - 6s 57ms/step - loss: 0.1473 - accuracy: 0.9483 - val_loss: 0.4618 - val_accuracy: 0.8495\n",
            "Epoch 305/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1599 - accuracy: 0.9407 - val_loss: 0.4368 - val_accuracy: 0.8511\n",
            "Epoch 306/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1631 - accuracy: 0.9347 - val_loss: 0.4205 - val_accuracy: 0.8571\n",
            "Epoch 307/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1629 - accuracy: 0.9382 - val_loss: 0.4419 - val_accuracy: 0.8495\n",
            "Epoch 308/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1554 - accuracy: 0.9372 - val_loss: 0.4382 - val_accuracy: 0.8526\n",
            "Epoch 309/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1528 - accuracy: 0.9428 - val_loss: 0.4438 - val_accuracy: 0.8435\n",
            "Epoch 310/400\n",
            "99/99 [==============================] - 6s 65ms/step - loss: 0.1512 - accuracy: 0.9458 - val_loss: 0.4359 - val_accuracy: 0.8556\n",
            "Epoch 311/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1515 - accuracy: 0.9433 - val_loss: 0.4231 - val_accuracy: 0.8465\n",
            "Epoch 312/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1562 - accuracy: 0.9422 - val_loss: 0.4456 - val_accuracy: 0.8495\n",
            "Epoch 313/400\n",
            "99/99 [==============================] - 6s 56ms/step - loss: 0.1526 - accuracy: 0.9417 - val_loss: 0.4339 - val_accuracy: 0.8541\n",
            "Epoch 314/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1536 - accuracy: 0.9422 - val_loss: 0.4437 - val_accuracy: 0.8541\n",
            "Epoch 315/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1539 - accuracy: 0.9438 - val_loss: 0.4341 - val_accuracy: 0.8602\n",
            "Epoch 316/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1608 - accuracy: 0.9428 - val_loss: 0.4397 - val_accuracy: 0.8495\n",
            "Epoch 317/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1542 - accuracy: 0.9433 - val_loss: 0.4397 - val_accuracy: 0.8541\n",
            "Epoch 318/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1518 - accuracy: 0.9473 - val_loss: 0.4655 - val_accuracy: 0.8526\n",
            "Epoch 319/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1685 - accuracy: 0.9448 - val_loss: 0.4256 - val_accuracy: 0.8571\n",
            "Epoch 320/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1543 - accuracy: 0.9463 - val_loss: 0.4306 - val_accuracy: 0.8587\n",
            "Epoch 321/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1490 - accuracy: 0.9448 - val_loss: 0.4219 - val_accuracy: 0.8663\n",
            "Epoch 322/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1498 - accuracy: 0.9458 - val_loss: 0.4369 - val_accuracy: 0.8556\n",
            "Epoch 323/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1493 - accuracy: 0.9422 - val_loss: 0.4265 - val_accuracy: 0.8526\n",
            "Epoch 324/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1531 - accuracy: 0.9443 - val_loss: 0.4231 - val_accuracy: 0.8526\n",
            "Epoch 325/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1533 - accuracy: 0.9483 - val_loss: 0.4382 - val_accuracy: 0.8526\n",
            "Epoch 326/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1454 - accuracy: 0.9428 - val_loss: 0.4446 - val_accuracy: 0.8495\n",
            "Epoch 327/400\n",
            "99/99 [==============================] - 6s 56ms/step - loss: 0.1633 - accuracy: 0.9392 - val_loss: 0.4247 - val_accuracy: 0.8602\n",
            "Epoch 328/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1504 - accuracy: 0.9438 - val_loss: 0.4337 - val_accuracy: 0.8541\n",
            "Epoch 329/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1523 - accuracy: 0.9417 - val_loss: 0.4372 - val_accuracy: 0.8556\n",
            "Epoch 330/400\n",
            "99/99 [==============================] - 6s 56ms/step - loss: 0.1493 - accuracy: 0.9473 - val_loss: 0.4368 - val_accuracy: 0.8541\n",
            "Epoch 331/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1400 - accuracy: 0.9493 - val_loss: 0.4511 - val_accuracy: 0.8480\n",
            "Epoch 332/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1397 - accuracy: 0.9468 - val_loss: 0.4469 - val_accuracy: 0.8587\n",
            "Epoch 333/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1468 - accuracy: 0.9478 - val_loss: 0.4469 - val_accuracy: 0.8541\n",
            "Epoch 334/400\n",
            "99/99 [==============================] - 6s 65ms/step - loss: 0.1435 - accuracy: 0.9483 - val_loss: 0.4589 - val_accuracy: 0.8571\n",
            "Epoch 335/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1336 - accuracy: 0.9514 - val_loss: 0.4455 - val_accuracy: 0.8571\n",
            "Epoch 336/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1382 - accuracy: 0.9504 - val_loss: 0.4541 - val_accuracy: 0.8526\n",
            "Epoch 337/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1308 - accuracy: 0.9544 - val_loss: 0.4496 - val_accuracy: 0.8526\n",
            "Epoch 338/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1356 - accuracy: 0.9509 - val_loss: 0.4692 - val_accuracy: 0.8480\n",
            "Epoch 339/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1442 - accuracy: 0.9493 - val_loss: 0.4746 - val_accuracy: 0.8541\n",
            "Epoch 340/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1392 - accuracy: 0.9519 - val_loss: 0.4526 - val_accuracy: 0.8541\n",
            "Epoch 341/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1314 - accuracy: 0.9580 - val_loss: 0.4652 - val_accuracy: 0.8541\n",
            "Epoch 342/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1315 - accuracy: 0.9524 - val_loss: 0.4593 - val_accuracy: 0.8587\n",
            "Epoch 343/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1331 - accuracy: 0.9488 - val_loss: 0.4489 - val_accuracy: 0.8602\n",
            "Epoch 344/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1332 - accuracy: 0.9493 - val_loss: 0.4641 - val_accuracy: 0.8511\n",
            "Epoch 345/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1309 - accuracy: 0.9478 - val_loss: 0.4682 - val_accuracy: 0.8556\n",
            "Epoch 346/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1245 - accuracy: 0.9529 - val_loss: 0.4520 - val_accuracy: 0.8632\n",
            "Epoch 347/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1352 - accuracy: 0.9468 - val_loss: 0.4426 - val_accuracy: 0.8617\n",
            "Epoch 348/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1338 - accuracy: 0.9478 - val_loss: 0.4590 - val_accuracy: 0.8571\n",
            "Epoch 349/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1216 - accuracy: 0.9585 - val_loss: 0.4656 - val_accuracy: 0.8541\n",
            "Epoch 350/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1333 - accuracy: 0.9524 - val_loss: 0.4556 - val_accuracy: 0.8602\n",
            "Epoch 351/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1239 - accuracy: 0.9559 - val_loss: 0.4793 - val_accuracy: 0.8587\n",
            "Epoch 352/400\n",
            "99/99 [==============================] - 5s 56ms/step - loss: 0.1332 - accuracy: 0.9509 - val_loss: 0.4824 - val_accuracy: 0.8602\n",
            "Epoch 353/400\n",
            "99/99 [==============================] - 6s 58ms/step - loss: 0.1277 - accuracy: 0.9554 - val_loss: 0.4519 - val_accuracy: 0.8647\n",
            "Epoch 354/400\n",
            "99/99 [==============================] - 6s 57ms/step - loss: 0.1351 - accuracy: 0.9534 - val_loss: 0.4647 - val_accuracy: 0.8587\n",
            "Epoch 355/400\n",
            "99/99 [==============================] - 6s 58ms/step - loss: 0.1211 - accuracy: 0.9544 - val_loss: 0.4877 - val_accuracy: 0.8556\n",
            "Epoch 356/400\n",
            "99/99 [==============================] - 6s 56ms/step - loss: 0.1336 - accuracy: 0.9498 - val_loss: 0.4558 - val_accuracy: 0.8647\n",
            "Epoch 357/400\n",
            "99/99 [==============================] - 7s 66ms/step - loss: 0.1368 - accuracy: 0.9564 - val_loss: 0.4596 - val_accuracy: 0.8541\n",
            "Epoch 358/400\n",
            "99/99 [==============================] - 6s 57ms/step - loss: 0.1293 - accuracy: 0.9519 - val_loss: 0.4565 - val_accuracy: 0.8571\n",
            "Epoch 359/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1282 - accuracy: 0.9519 - val_loss: 0.4715 - val_accuracy: 0.8587\n",
            "Epoch 360/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1216 - accuracy: 0.9529 - val_loss: 0.4468 - val_accuracy: 0.8556\n",
            "Epoch 361/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1190 - accuracy: 0.9574 - val_loss: 0.4993 - val_accuracy: 0.8374\n",
            "Epoch 362/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1252 - accuracy: 0.9549 - val_loss: 0.4536 - val_accuracy: 0.8632\n",
            "Epoch 363/400\n",
            "99/99 [==============================] - 6s 56ms/step - loss: 0.1254 - accuracy: 0.9544 - val_loss: 0.4968 - val_accuracy: 0.8450\n",
            "Epoch 364/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1181 - accuracy: 0.9595 - val_loss: 0.4705 - val_accuracy: 0.8556\n",
            "Epoch 365/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1229 - accuracy: 0.9539 - val_loss: 0.4605 - val_accuracy: 0.8571\n",
            "Epoch 366/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1217 - accuracy: 0.9595 - val_loss: 0.4774 - val_accuracy: 0.8571\n",
            "Epoch 367/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1203 - accuracy: 0.9549 - val_loss: 0.4597 - val_accuracy: 0.8556\n",
            "Epoch 368/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1142 - accuracy: 0.9630 - val_loss: 0.4637 - val_accuracy: 0.8526\n",
            "Epoch 369/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1204 - accuracy: 0.9544 - val_loss: 0.4718 - val_accuracy: 0.8495\n",
            "Epoch 370/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1123 - accuracy: 0.9564 - val_loss: 0.4572 - val_accuracy: 0.8571\n",
            "Epoch 371/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1125 - accuracy: 0.9620 - val_loss: 0.4786 - val_accuracy: 0.8495\n",
            "Epoch 372/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1202 - accuracy: 0.9524 - val_loss: 0.4565 - val_accuracy: 0.8511\n",
            "Epoch 373/400\n",
            "99/99 [==============================] - 5s 52ms/step - loss: 0.1141 - accuracy: 0.9590 - val_loss: 0.4630 - val_accuracy: 0.8526\n",
            "Epoch 374/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1220 - accuracy: 0.9554 - val_loss: 0.4892 - val_accuracy: 0.8495\n",
            "Epoch 375/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1169 - accuracy: 0.9544 - val_loss: 0.4844 - val_accuracy: 0.8465\n",
            "Epoch 376/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1097 - accuracy: 0.9600 - val_loss: 0.4703 - val_accuracy: 0.8587\n",
            "Epoch 377/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1118 - accuracy: 0.9645 - val_loss: 0.4672 - val_accuracy: 0.8602\n",
            "Epoch 378/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1137 - accuracy: 0.9554 - val_loss: 0.4731 - val_accuracy: 0.8587\n",
            "Epoch 379/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1209 - accuracy: 0.9559 - val_loss: 0.4790 - val_accuracy: 0.8587\n",
            "Epoch 380/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1196 - accuracy: 0.9549 - val_loss: 0.5097 - val_accuracy: 0.8435\n",
            "Epoch 381/400\n",
            "99/99 [==============================] - 7s 67ms/step - loss: 0.1256 - accuracy: 0.9605 - val_loss: 0.5022 - val_accuracy: 0.8571\n",
            "Epoch 382/400\n",
            "99/99 [==============================] - 6s 58ms/step - loss: 0.1110 - accuracy: 0.9569 - val_loss: 0.4850 - val_accuracy: 0.8541\n",
            "Epoch 383/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1144 - accuracy: 0.9569 - val_loss: 0.4874 - val_accuracy: 0.8602\n",
            "Epoch 384/400\n",
            "99/99 [==============================] - 6s 56ms/step - loss: 0.1175 - accuracy: 0.9569 - val_loss: 0.4800 - val_accuracy: 0.8602\n",
            "Epoch 385/400\n",
            "99/99 [==============================] - 6s 58ms/step - loss: 0.1218 - accuracy: 0.9610 - val_loss: 0.4745 - val_accuracy: 0.8602\n",
            "Epoch 386/400\n",
            "99/99 [==============================] - 6s 56ms/step - loss: 0.1058 - accuracy: 0.9600 - val_loss: 0.4907 - val_accuracy: 0.8571\n",
            "Epoch 387/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1117 - accuracy: 0.9590 - val_loss: 0.4924 - val_accuracy: 0.8465\n",
            "Epoch 388/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1092 - accuracy: 0.9625 - val_loss: 0.4746 - val_accuracy: 0.8602\n",
            "Epoch 389/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1082 - accuracy: 0.9671 - val_loss: 0.4697 - val_accuracy: 0.8587\n",
            "Epoch 390/400\n",
            "99/99 [==============================] - 6s 55ms/step - loss: 0.1069 - accuracy: 0.9620 - val_loss: 0.5047 - val_accuracy: 0.8465\n",
            "Epoch 391/400\n",
            "99/99 [==============================] - 6s 56ms/step - loss: 0.1112 - accuracy: 0.9595 - val_loss: 0.4886 - val_accuracy: 0.8556\n",
            "Epoch 392/400\n",
            "99/99 [==============================] - 6s 57ms/step - loss: 0.1074 - accuracy: 0.9650 - val_loss: 0.4926 - val_accuracy: 0.8556\n",
            "Epoch 393/400\n",
            "99/99 [==============================] - 6s 56ms/step - loss: 0.0996 - accuracy: 0.9645 - val_loss: 0.4789 - val_accuracy: 0.8587\n",
            "Epoch 394/400\n",
            "99/99 [==============================] - 6s 56ms/step - loss: 0.1149 - accuracy: 0.9615 - val_loss: 0.4659 - val_accuracy: 0.8647\n",
            "Epoch 395/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1067 - accuracy: 0.9635 - val_loss: 0.4838 - val_accuracy: 0.8571\n",
            "Epoch 396/400\n",
            "99/99 [==============================] - 5s 55ms/step - loss: 0.1004 - accuracy: 0.9630 - val_loss: 0.4791 - val_accuracy: 0.8647\n",
            "Epoch 397/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1083 - accuracy: 0.9640 - val_loss: 0.4648 - val_accuracy: 0.8587\n",
            "Epoch 398/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1076 - accuracy: 0.9595 - val_loss: 0.4988 - val_accuracy: 0.8556\n",
            "Epoch 399/400\n",
            "99/99 [==============================] - 5s 53ms/step - loss: 0.1128 - accuracy: 0.9574 - val_loss: 0.4884 - val_accuracy: 0.8556\n",
            "Epoch 400/400\n",
            "99/99 [==============================] - 5s 54ms/step - loss: 0.1029 - accuracy: 0.9625 - val_loss: 0.4768 - val_accuracy: 0.8647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model8.evaluate(X_test, y_test)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL_TzPwJjIX2",
        "outputId": "a35463dd-434c-4b8a-9ab1-6b61d883f413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 16ms/step - loss: 0.4768 - accuracy: 0.8647\n",
            "Accuracy: 86.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "plt.plot(cnn8.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(cnn8.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "gz9O7li8jM-D",
        "outputId": "768f59fc-3c94-4a4f-ef3b-c6efafab8413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "plt.plot(cnn8.history[\"accuracy\"], label=\"loss\")\n",
        "plt.plot(cnn8.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "N-E2incOjNOX",
        "outputId": "16df6765-f29a-4629-955f-7d4702c5c48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=300,max_features='sqrt',random_state=25)\n",
        "rfc.fit(X_train,y_train)\n",
        "\n",
        "rfc_predict = rfc.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_true=y_test,y_pred=rfc_predict))\n",
        "print(classification_report(y_test,rfc_predict)) \n",
        "# creating a confusion matrix \n",
        "print(confusion_matrix(y_test, rfc_predict) )\n",
        "print(rfc.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OyX-NBoH6HO",
        "outputId": "3d650439-a6b6-49e2-e1fe-92417279f970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8085106382978723\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       182\n",
            "           1       0.83      0.80      0.82       180\n",
            "           2       0.93      0.60      0.73       106\n",
            "           3       0.72      0.85      0.78       190\n",
            "\n",
            "    accuracy                           0.81       658\n",
            "   macro avg       0.83      0.79      0.80       658\n",
            "weighted avg       0.82      0.81      0.81       658\n",
            "\n",
            "[[162   8   1  11]\n",
            " [ 22 144   1  13]\n",
            " [  0   3  64  39]\n",
            " [  7  18   3 162]]\n",
            "[0.00198463 0.00253454 0.0027987  0.00266961 0.00354369 0.00304515\n",
            " 0.00383547 0.00251506 0.00248751 0.00343159 0.00367477 0.00308894\n",
            " 0.00369948 0.00391445 0.00631562 0.00515751 0.0051556  0.00391675\n",
            " 0.00457693 0.00398536 0.00296739 0.00253825 0.00340313 0.00349976\n",
            " 0.00327477 0.00352812 0.00353112 0.00372829 0.00346392 0.0070302\n",
            " 0.02337563 0.01008071 0.00753604 0.00537652 0.00465939 0.00580729\n",
            " 0.00545681 0.0053129  0.00442951 0.00478723 0.00310571 0.00187783\n",
            " 0.00411707 0.00369472 0.00377656 0.00514424 0.00474869 0.00678435\n",
            " 0.0098688  0.00963497 0.00638382 0.00476927 0.0045553  0.00445593\n",
            " 0.0063535  0.00593569 0.00702635 0.01465345 0.00524332 0.00360799\n",
            " 0.00294177 0.00490867 0.00431634 0.00535956 0.00722376 0.00539462\n",
            " 0.00499557 0.00620822 0.0086711  0.00598034 0.00484921 0.00589253\n",
            " 0.0052215  0.01419698 0.01795757 0.00860781 0.00639346 0.00543151\n",
            " 0.00626692 0.00500978 0.00382432 0.00469272 0.00553528 0.00513424\n",
            " 0.00659771 0.00567366 0.00561834 0.00377379 0.00675351 0.00575613\n",
            " 0.00365385 0.00415033 0.00320199 0.00409161 0.00429603 0.00385914\n",
            " 0.00375463 0.0039517  0.00342089 0.00594297 0.00707823 0.00383875\n",
            " 0.00308418 0.00488595 0.00426859 0.00616406 0.00564398 0.00565741\n",
            " 0.00487817 0.00263093 0.00455624 0.00981991 0.00847011 0.0125108\n",
            " 0.01038598 0.01158323 0.00979522 0.00757183 0.00949394 0.0127871\n",
            " 0.00644323 0.00685718 0.00774682 0.01529473 0.01503387 0.00528523\n",
            " 0.00514393 0.0078164  0.00600878 0.00550263 0.0052326  0.00509815\n",
            " 0.00496127 0.00436018 0.00462138 0.00384418 0.00270963 0.00260176\n",
            " 0.00180197 0.00263602 0.00246033 0.00200245 0.00257577 0.00258472\n",
            " 0.00250033 0.00266559 0.00200963 0.00157701 0.00163584 0.00214825\n",
            " 0.00184647 0.00210516 0.00202078 0.00180831 0.00246499 0.00195629\n",
            " 0.00181612 0.0021896  0.00190114 0.00272231 0.00297559 0.0028776\n",
            " 0.00281939 0.00231771 0.00177326 0.00198073 0.00183223 0.00176117\n",
            " 0.00266812 0.0023825  0.0025936  0.00239812 0.00218916 0.00260512\n",
            " 0.00299307 0.00478525 0.00601311 0.0044039  0.00331004 0.00262975\n",
            " 0.01248163 0.01762234 0.01785792 0.01538482 0.01209536 0.01134846\n",
            " 0.0025688  0.00284104 0.0026883  0.00205767 0.00227625 0.00217973\n",
            " 0.0028267 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(400,),random_state=50,batch_size=200,\n",
        "                    max_iter=1000,epsilon=1e-08,learning_rate='adaptive')\n",
        "    \n",
        "mlp.fit(X_train,y_train)\n",
        "mlp_pred = mlp.predict(X_test)\n",
        "mlp.score(X_test,y_test)\n",
        "print(accuracy_score(y_true=y_test,y_pred=mlp_pred))\n",
        "print(classification_report(y_test,mlp_pred)) \n",
        "print(confusion_matrix(y_test, mlp_pred) )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-97TeOF0IB8w",
        "outputId": "8d1ca713-c753-49b6-8ef3-b06ddf108667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8632218844984803\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92       182\n",
            "           1       0.93      0.88      0.90       180\n",
            "           2       0.79      0.74      0.76       106\n",
            "           3       0.79      0.87      0.83       190\n",
            "\n",
            "    accuracy                           0.86       658\n",
            "   macro avg       0.86      0.85      0.85       658\n",
            "weighted avg       0.87      0.86      0.86       658\n",
            "\n",
            "[[167   2   5   8]\n",
            " [ 10 158   2  10]\n",
            " [  0   3  78  25]\n",
            " [  4   7  14 165]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC \n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "\n",
        "\n",
        "pca = PCA(n_components=50)\n",
        "X8 = pca.fit_transform(X8)\n",
        "\n",
        "X_train, X_test, y_train, y_test = split_scale(X8,y8)\n",
        "\n",
        "\n",
        "svm_model_linear = SVC(kernel = 'linear', C = 1,decision_function_shape='ovo').fit(X_train, y_train) \n",
        "svm_predictions = svm_model_linear.predict(X_test) \n",
        "\n",
        "\n",
        "print(accuracy_score(y_true=y_test,y_pred=svm_predictions))\n",
        "print(classification_report(y_test,svm_predictions)) \n",
        "# creating a confusion matrix \n",
        "print(confusion_matrix(y_test, svm_predictions) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PeTxxPbJjT6",
        "outputId": "408e8914-4e8c-4d4b-c71a-441329ffea9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.723404255319149\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.73      0.74       182\n",
            "           1       0.69      0.74      0.71       180\n",
            "           2       0.81      0.63      0.71       106\n",
            "           3       0.70      0.75      0.72       190\n",
            "\n",
            "    accuracy                           0.72       658\n",
            "   macro avg       0.74      0.71      0.72       658\n",
            "weighted avg       0.73      0.72      0.72       658\n",
            "\n",
            "[[133  28   3  18]\n",
            " [ 27 134   3  16]\n",
            " [  3   8  67  28]\n",
            " [ 13  25  10 142]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing using Real Data"
      ],
      "metadata": {
        "id": "rXJmgh4ss_sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('test_berlin.csv')\n",
        "test_data.head()"
      ],
      "metadata": {
        "id": "XJCtKih5tEwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_filter =  ['angry', 'sad' , 'neutral' , 'happy']\n",
        "#376+376+376+188"
      ],
      "metadata": {
        "id": "F4I9OctlfnWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test_data.loc[test_data['labels'].isin(['angry', 'sad' , 'neutral' , 'happy'])]\n"
      ],
      "metadata": {
        "id": "f5PdcIECf6dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_erli = test_data.iloc[:,1:-1].values\n",
        "y_erli = test_data.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "7z_-85JigDJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y_erli = encoder.fit_transform(y_erli)\n",
        "print(y_erli)"
      ],
      "metadata": {
        "id": "Vd5OYyu5gLWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62e45bde-3583-43b8-a414-91d14fdc97bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 0 0 0 3 0 0 3 2 0 3 3 1 2 0 1 0 0 2 3 3 2 0 0 0 3 1 3 0 1 1 0 3 3 0\n",
            " 0 0 3 1 0 1 1 1 2 0 3 0 1 3 1 2 3 1 3 0 0 2 3 0 2 3 2 2 3 0 1 2 0 2 0 1 1\n",
            " 0 2 0 3 1 2 0 3 0 0 1 0 3 3 1 2 3 0 3 3 0 0 0 0 3 0 3 3 3 3 0 0 0 0 1 3 0\n",
            " 3 3 3 2 0 3 2 0 3 0 0 2 2 3 3 2 0 2 0 3 3 3 0 1 0 0 2 0 0 3 3 1 3 1 0 3 2\n",
            " 1 0 0 2 0 1 1 3 1 1 2 3 0 3 0 2 3 0 3 3 0 3 2 3 2 1 1 3 3 1 2 3 0 2 0 1 0\n",
            " 2 3 0 0 3 3 0 3 2 3 3 0 2 3 3 0 1 0 3 0 0 3 2 1 2 3 2 0 2 0 3 3 3 3 2 0 3\n",
            " 1 2 3 1 2 3 2 1 1 3 3 0 3 1 2 3 1 2 1 2 3 0 3 3 2 2 3 0 1 3 1 3 1 0 0 2 3\n",
            " 1 3 2 2 3 1 0 0 2 1 2 2 3 3 2 0 0 3 0 0 3 3 2 0 0 1 1 0 3 0 3 3 3 1 0 0 1\n",
            " 3 3 3 3 3 0 0 2 3 0 2 3 0 0 3 0 0 2 0 1 3 3 3 3 1 1 3 2 3 3 3 3 1 0 0 1 0\n",
            " 3 0 3 2 1 2 3 3 2 2 1 3 3 1 2 3 2 0 1 2 2 3 1 3 2 3 0 0 2 0 1 2 2 3 3 0 0\n",
            " 0 0 3 0 0 3 3 1 1 3 3 3 0 0 2 0 1 1 2 2 0 3 3 2 1 3 0 3 3 0 3 2 0 3 1 3 0\n",
            " 1 0 3 2 0 2 3 0 2 3 3 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Random Forest Classifier\n",
        "\n",
        "rfc_predict = rfc.predict(X)\n",
        "\n",
        "print(accuracy_score(y_true=y,y_pred=rfc_predict))\n",
        "print(classification_report(y,rfc_predict)) \n",
        "# creating a confusion matrix \n",
        "print(confusion_matrix(y, rfc_predict) )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIOnSGb6gcs0",
        "outputId": "3eeba5fe-a678-4ce5-a6af-2ca37edc2e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3119047619047619\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      1.00      0.50       127\n",
            "           1       0.09      0.06      0.07        71\n",
            "           2       0.00      0.00      0.00        79\n",
            "           3       0.00      0.00      0.00       143\n",
            "\n",
            "    accuracy                           0.31       420\n",
            "   macro avg       0.11      0.26      0.14       420\n",
            "weighted avg       0.12      0.31      0.16       420\n",
            "\n",
            "[[127   0   0   0]\n",
            " [ 67   4   0   0]\n",
            " [ 67  12   0   0]\n",
            " [116  27   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    \n",
        "\n",
        "mlp_pred = mlp.predict(X)\n",
        "mlp.score(X,y)\n",
        "print(accuracy_score(y_true=y,y_pred=mlp_pred))\n",
        "print(classification_report(y,mlp_pred)) \n",
        "print(confusion_matrix(y, mlp_pred) )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8vDpSHAgN9A",
        "outputId": "f16e3323-6485-4d6e-98b5-890d19cf22df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5452380952380952\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.82      0.70       127\n",
            "           1       0.41      0.28      0.33        71\n",
            "           2       0.37      0.44      0.40        79\n",
            "           3       0.67      0.49      0.56       143\n",
            "\n",
            "    accuracy                           0.55       420\n",
            "   macro avg       0.51      0.51      0.50       420\n",
            "weighted avg       0.55      0.55      0.54       420\n",
            "\n",
            "[[104  22   1   0]\n",
            " [ 49  20   1   1]\n",
            " [  6   4  35  34]\n",
            " [ 13   3  57  70]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pca.fit_transform(X)\n",
        "svm_predictions = svm_model_linear.predict(X) \n",
        "\n",
        "\n",
        "print(accuracy_score(y_true=y,y_pred=svm_predictions))\n",
        "print(classification_report(y,svm_predictions)) \n",
        "# creating a confusion matrix \n",
        "print(confusion_matrix(y, svm_predictions) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RfHicBSht14",
        "outputId": "e8f180e8-00e6-4f88-dc92-13b4d183d88a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1880952380952381\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.21      0.20       127\n",
            "           1       0.10      0.08      0.09        71\n",
            "           2       0.15      0.29      0.20        79\n",
            "           3       0.39      0.16      0.23       143\n",
            "\n",
            "    accuracy                           0.19       420\n",
            "   macro avg       0.21      0.19      0.18       420\n",
            "weighted avg       0.23      0.19      0.19       420\n",
            "\n",
            "[[27 29 62  9]\n",
            " [15  6 36 14]\n",
            " [34  9 23 13]\n",
            " [72 14 34 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = np.expand_dims(X, axis=2)\n",
        "\n",
        "\n",
        "loss, acc = model8.evaluate(X, y)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL8TdoIjiQ8W",
        "outputId": "9cae5bfd-8567-4ac3-8c43-4c1e4e682ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 16ms/step - loss: 27.7303 - accuracy: 0.4310\n",
            "Accuracy: 43.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K FOlds Cross Validation"
      ],
      "metadata": {
        "id": "OmhyTSNPbzvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "data8 = pd.read_csv('dataset7.csv')\n",
        "data8.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "1nffqaWOb2AB",
        "outputId": "30dadb03-9ac5-4787-dee0-fddb57ddf3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0           0          1          2          3         4  \\\n",
              "0           0 -524.339844  58.945076  11.774967  26.318909  0.261554   \n",
              "1           1 -269.140574  11.484386   8.767346   6.243472  2.747863   \n",
              "2           2 -366.166321  61.372746 -14.820083  21.295778 -8.899424   \n",
              "3           3 -231.392576  29.672213   1.565719   5.466136 -4.319672   \n",
              "4           4 -536.010803  69.903397 -16.303288  32.916740  2.925880   \n",
              "\n",
              "          5          6         7          8  ...       184       185  \\\n",
              "0  5.660612  -3.377984 -3.362769  -9.245324  ... -0.000091  0.007732   \n",
              "1  0.709594  -0.614465 -1.588504  -3.817834  ... -0.000729  0.002335   \n",
              "2 -7.860835  -2.845897 -0.053523 -10.914480  ... -0.030637 -0.010813   \n",
              "3 -7.645862  -0.795612  0.830001  -6.118091  ... -0.032956  0.001459   \n",
              "4  0.171463 -12.861864 -5.886380 -12.273261  ... -0.007125 -0.016768   \n",
              "\n",
              "         186        187        188        189        190        191  \\\n",
              "0  21.961529  15.875564  19.082055  14.696499  16.397359  16.391151   \n",
              "1  15.468811  13.326386  14.867802  12.761607  13.529643  13.522223   \n",
              "2  22.978009  17.598611  20.942201  18.762070  18.259227  17.844183   \n",
              "3  17.083159  15.874668  18.546013  16.412194  15.331840  14.713892   \n",
              "4  23.791126  19.190114  20.781159  18.825651  19.712703  20.324445   \n",
              "\n",
              "         192   labels  \n",
              "0  29.530816  disgust  \n",
              "1  13.355271  disgust  \n",
              "2  30.877108    angry  \n",
              "3  13.618339    angry  \n",
              "4  29.268788  neutral  \n",
              "\n",
              "[5 rows x 195 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b98c45a1-f969-473e-8b21-f3b6f0953013\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-524.339844</td>\n",
              "      <td>58.945076</td>\n",
              "      <td>11.774967</td>\n",
              "      <td>26.318909</td>\n",
              "      <td>0.261554</td>\n",
              "      <td>5.660612</td>\n",
              "      <td>-3.377984</td>\n",
              "      <td>-3.362769</td>\n",
              "      <td>-9.245324</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000091</td>\n",
              "      <td>0.007732</td>\n",
              "      <td>21.961529</td>\n",
              "      <td>15.875564</td>\n",
              "      <td>19.082055</td>\n",
              "      <td>14.696499</td>\n",
              "      <td>16.397359</td>\n",
              "      <td>16.391151</td>\n",
              "      <td>29.530816</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-269.140574</td>\n",
              "      <td>11.484386</td>\n",
              "      <td>8.767346</td>\n",
              "      <td>6.243472</td>\n",
              "      <td>2.747863</td>\n",
              "      <td>0.709594</td>\n",
              "      <td>-0.614465</td>\n",
              "      <td>-1.588504</td>\n",
              "      <td>-3.817834</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000729</td>\n",
              "      <td>0.002335</td>\n",
              "      <td>15.468811</td>\n",
              "      <td>13.326386</td>\n",
              "      <td>14.867802</td>\n",
              "      <td>12.761607</td>\n",
              "      <td>13.529643</td>\n",
              "      <td>13.522223</td>\n",
              "      <td>13.355271</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-366.166321</td>\n",
              "      <td>61.372746</td>\n",
              "      <td>-14.820083</td>\n",
              "      <td>21.295778</td>\n",
              "      <td>-8.899424</td>\n",
              "      <td>-7.860835</td>\n",
              "      <td>-2.845897</td>\n",
              "      <td>-0.053523</td>\n",
              "      <td>-10.914480</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.030637</td>\n",
              "      <td>-0.010813</td>\n",
              "      <td>22.978009</td>\n",
              "      <td>17.598611</td>\n",
              "      <td>20.942201</td>\n",
              "      <td>18.762070</td>\n",
              "      <td>18.259227</td>\n",
              "      <td>17.844183</td>\n",
              "      <td>30.877108</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-231.392576</td>\n",
              "      <td>29.672213</td>\n",
              "      <td>1.565719</td>\n",
              "      <td>5.466136</td>\n",
              "      <td>-4.319672</td>\n",
              "      <td>-7.645862</td>\n",
              "      <td>-0.795612</td>\n",
              "      <td>0.830001</td>\n",
              "      <td>-6.118091</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.032956</td>\n",
              "      <td>0.001459</td>\n",
              "      <td>17.083159</td>\n",
              "      <td>15.874668</td>\n",
              "      <td>18.546013</td>\n",
              "      <td>16.412194</td>\n",
              "      <td>15.331840</td>\n",
              "      <td>14.713892</td>\n",
              "      <td>13.618339</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-536.010803</td>\n",
              "      <td>69.903397</td>\n",
              "      <td>-16.303288</td>\n",
              "      <td>32.916740</td>\n",
              "      <td>2.925880</td>\n",
              "      <td>0.171463</td>\n",
              "      <td>-12.861864</td>\n",
              "      <td>-5.886380</td>\n",
              "      <td>-12.273261</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007125</td>\n",
              "      <td>-0.016768</td>\n",
              "      <td>23.791126</td>\n",
              "      <td>19.190114</td>\n",
              "      <td>20.781159</td>\n",
              "      <td>18.825651</td>\n",
              "      <td>19.712703</td>\n",
              "      <td>20.324445</td>\n",
              "      <td>29.268788</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 195 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b98c45a1-f969-473e-8b21-f3b6f0953013')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b98c45a1-f969-473e-8b21-f3b6f0953013 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b98c45a1-f969-473e-8b21-f3b6f0953013');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data8 = data8.loc[data8['labels'].isin(['angry', 'sad' , 'neutral' , 'happy'])]\n"
      ],
      "metadata": {
        "id": "1FFe5h0Te9iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data8.iloc[:,1:-1].values\n",
        "y = data8.iloc[:,-1].values\n",
        "print(y)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA2xT3i8fCkv",
        "outputId": "5550a410-3cde-4200-d4a5-b29ab6e97d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['angry' 'angry' 'neutral' ... 'angry' 'angry' 'angry']\n",
            "[0 0 2 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model8 = Sequential()\n",
        "\n",
        "  model8.add(Conv1D(128, 3,padding='same',input_shape=(193,1)))        \n",
        "  model8.add(Activation('relu'))\n",
        "  model8.add(Dropout(0.1))\n",
        "  model8.add(MaxPooling1D(pool_size=(2)))\n",
        "\n",
        "  model8.add(Conv1D(128, 3,padding='same'))        \n",
        "  model8.add(Activation('relu'))\n",
        "  model8.add(MaxPooling1D(pool_size=(2)))\n",
        "  model8.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "  model8.add(Conv1D(128, 3,padding='same'))                          \n",
        "  model8.add(Activation('relu'))\n",
        "  model8.add(MaxPooling1D(pool_size=(2)))\n",
        "  model8.add(Dropout(0.1))\n",
        "\n",
        "  model8.add(Flatten())\n",
        "  model8.add(Dense(4))                                                 \n",
        "  model8.add(Activation('softmax'))\n",
        "\n",
        "  opt = optimizers.RMSprop(lr=0.00005, rho=0.9, epsilon=None, decay=0.0)\n",
        "  model8.summary()\n",
        "  model8.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "  return model8"
      ],
      "metadata": {
        "id": "ZHS7rLcuf1ZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "n_split=3\n",
        "\n",
        "for train_index,test_index in KFold(n_split).split(X):\n",
        "  x_train,x_test=X[train_index],X[test_index]\n",
        "  x_train = np.expand_dims(x_train, axis=2)\n",
        "  x_test = np.expand_dims(x_test, axis=2)\n",
        "\n",
        "  y_train,y_test=y[train_index],y[test_index]\n",
        "  \n",
        "  model=create_model()\n",
        "  model.fit(x_train, y_train,epochs=400)\n",
        "  \n",
        "  print('Model evaluation ',model.evaluate(x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZNnSI-OgGZ6",
        "outputId": "ef406bdc-f01e-43a8-aa66-c90ce9b210af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 193, 128)          512       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 193, 128)          0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 193, 128)          0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 96, 128)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 96, 128)           49280     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 96, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 48, 128)          0         \n",
            " 1D)                                                             \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 48, 128)           0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 48, 128)           49280     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 48, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 24, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 24, 128)           0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 12292     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 111,364\n",
            "Trainable params: 111,364\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/400\n",
            "55/55 [==============================] - 11s 115ms/step - loss: 1.6521 - accuracy: 0.3107\n",
            "Epoch 2/400\n",
            "55/55 [==============================] - 7s 130ms/step - loss: 1.4018 - accuracy: 0.3905\n",
            "Epoch 3/400\n",
            "55/55 [==============================] - 7s 123ms/step - loss: 1.3276 - accuracy: 0.4133\n",
            "Epoch 4/400\n",
            "55/55 [==============================] - 7s 132ms/step - loss: 1.2671 - accuracy: 0.4379\n",
            "Epoch 5/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 1.2144 - accuracy: 0.4532\n",
            "Epoch 6/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 1.1520 - accuracy: 0.4903\n",
            "Epoch 7/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 1.1238 - accuracy: 0.4966\n",
            "Epoch 8/400\n",
            "55/55 [==============================] - 4s 65ms/step - loss: 1.0898 - accuracy: 0.5251\n",
            "Epoch 9/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 1.0709 - accuracy: 0.5325\n",
            "Epoch 10/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 1.0405 - accuracy: 0.5473\n",
            "Epoch 11/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.9983 - accuracy: 0.5701\n",
            "Epoch 12/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.9725 - accuracy: 0.5815\n",
            "Epoch 13/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.9627 - accuracy: 0.5941\n",
            "Epoch 14/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.9501 - accuracy: 0.5849\n",
            "Epoch 15/400\n",
            "55/55 [==============================] - 8s 155ms/step - loss: 0.9354 - accuracy: 0.6015\n",
            "Epoch 16/400\n",
            "55/55 [==============================] - 8s 151ms/step - loss: 0.9167 - accuracy: 0.6249\n",
            "Epoch 17/400\n",
            "55/55 [==============================] - 7s 124ms/step - loss: 0.8868 - accuracy: 0.6283\n",
            "Epoch 18/400\n",
            "55/55 [==============================] - 6s 111ms/step - loss: 0.8815 - accuracy: 0.6340\n",
            "Epoch 19/400\n",
            "55/55 [==============================] - 8s 153ms/step - loss: 0.8525 - accuracy: 0.6619\n",
            "Epoch 20/400\n",
            "55/55 [==============================] - 7s 130ms/step - loss: 0.8452 - accuracy: 0.6551\n",
            "Epoch 21/400\n",
            "55/55 [==============================] - 6s 108ms/step - loss: 0.8358 - accuracy: 0.6710\n",
            "Epoch 22/400\n",
            "55/55 [==============================] - 6s 105ms/step - loss: 0.8218 - accuracy: 0.6631\n",
            "Epoch 23/400\n",
            "55/55 [==============================] - 7s 120ms/step - loss: 0.7943 - accuracy: 0.6802\n",
            "Epoch 24/400\n",
            "55/55 [==============================] - 6s 117ms/step - loss: 0.8018 - accuracy: 0.6773\n",
            "Epoch 25/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.7816 - accuracy: 0.6847\n",
            "Epoch 26/400\n",
            "55/55 [==============================] - 4s 65ms/step - loss: 0.7760 - accuracy: 0.6807\n",
            "Epoch 27/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.7605 - accuracy: 0.6836\n",
            "Epoch 28/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.7578 - accuracy: 0.6990\n",
            "Epoch 29/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.7488 - accuracy: 0.6973\n",
            "Epoch 30/400\n",
            "55/55 [==============================] - 3s 63ms/step - loss: 0.7388 - accuracy: 0.6921\n",
            "Epoch 31/400\n",
            "55/55 [==============================] - 3s 63ms/step - loss: 0.7290 - accuracy: 0.6995\n",
            "Epoch 32/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.7324 - accuracy: 0.7138\n",
            "Epoch 33/400\n",
            "55/55 [==============================] - 4s 64ms/step - loss: 0.7079 - accuracy: 0.7087\n",
            "Epoch 34/400\n",
            "55/55 [==============================] - 4s 65ms/step - loss: 0.7134 - accuracy: 0.7206\n",
            "Epoch 35/400\n",
            "55/55 [==============================] - 3s 64ms/step - loss: 0.6921 - accuracy: 0.7206\n",
            "Epoch 36/400\n",
            "55/55 [==============================] - 3s 63ms/step - loss: 0.7002 - accuracy: 0.7075\n",
            "Epoch 37/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.6817 - accuracy: 0.7269\n",
            "Epoch 38/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.6764 - accuracy: 0.7332\n",
            "Epoch 39/400\n",
            "55/55 [==============================] - 3s 64ms/step - loss: 0.6847 - accuracy: 0.7303\n",
            "Epoch 40/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.6869 - accuracy: 0.7241\n",
            "Epoch 41/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.6673 - accuracy: 0.7269\n",
            "Epoch 42/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.6661 - accuracy: 0.7252\n",
            "Epoch 43/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.6582 - accuracy: 0.7252\n",
            "Epoch 44/400\n",
            "55/55 [==============================] - 4s 64ms/step - loss: 0.6542 - accuracy: 0.7349\n",
            "Epoch 45/400\n",
            "55/55 [==============================] - 4s 65ms/step - loss: 0.6478 - accuracy: 0.7417\n",
            "Epoch 46/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.6427 - accuracy: 0.7434\n",
            "Epoch 47/400\n",
            "55/55 [==============================] - 4s 65ms/step - loss: 0.6450 - accuracy: 0.7372\n",
            "Epoch 48/400\n",
            "55/55 [==============================] - 4s 64ms/step - loss: 0.6303 - accuracy: 0.7486\n",
            "Epoch 49/400\n",
            "55/55 [==============================] - 4s 64ms/step - loss: 0.6418 - accuracy: 0.7406\n",
            "Epoch 50/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.6250 - accuracy: 0.7486\n",
            "Epoch 51/400\n",
            "55/55 [==============================] - 6s 103ms/step - loss: 0.6294 - accuracy: 0.7503\n",
            "Epoch 52/400\n",
            "55/55 [==============================] - 6s 105ms/step - loss: 0.6210 - accuracy: 0.7548\n",
            "Epoch 53/400\n",
            "55/55 [==============================] - 4s 65ms/step - loss: 0.6151 - accuracy: 0.7469\n",
            "Epoch 54/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.6117 - accuracy: 0.7526\n",
            "Epoch 55/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.5962 - accuracy: 0.7623\n",
            "Epoch 56/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.5989 - accuracy: 0.7623\n",
            "Epoch 57/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.5984 - accuracy: 0.7605\n",
            "Epoch 58/400\n",
            "55/55 [==============================] - 4s 65ms/step - loss: 0.5960 - accuracy: 0.7594\n",
            "Epoch 59/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.6048 - accuracy: 0.7537\n",
            "Epoch 60/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.5907 - accuracy: 0.7634\n",
            "Epoch 61/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.5871 - accuracy: 0.7617\n",
            "Epoch 62/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.5814 - accuracy: 0.7680\n",
            "Epoch 63/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.5849 - accuracy: 0.7588\n",
            "Epoch 64/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.5827 - accuracy: 0.7645\n",
            "Epoch 65/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.5707 - accuracy: 0.7674\n",
            "Epoch 66/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.5670 - accuracy: 0.7754\n",
            "Epoch 67/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.5722 - accuracy: 0.7645\n",
            "Epoch 68/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.5767 - accuracy: 0.7617\n",
            "Epoch 69/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.5539 - accuracy: 0.7748\n",
            "Epoch 70/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.5703 - accuracy: 0.7628\n",
            "Epoch 71/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.5687 - accuracy: 0.7662\n",
            "Epoch 72/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.5504 - accuracy: 0.7765\n",
            "Epoch 73/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.5427 - accuracy: 0.7851\n",
            "Epoch 74/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.5414 - accuracy: 0.7725\n",
            "Epoch 75/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.5419 - accuracy: 0.7839\n",
            "Epoch 76/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.5399 - accuracy: 0.7805\n",
            "Epoch 77/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.5406 - accuracy: 0.7839\n",
            "Epoch 78/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.5329 - accuracy: 0.7805\n",
            "Epoch 79/400\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.5270 - accuracy: 0.7834\n",
            "Epoch 80/400\n",
            "55/55 [==============================] - 5s 89ms/step - loss: 0.5302 - accuracy: 0.7862\n",
            "Epoch 81/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.5226 - accuracy: 0.7845\n",
            "Epoch 82/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.5202 - accuracy: 0.7908\n",
            "Epoch 83/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.5154 - accuracy: 0.7959\n",
            "Epoch 84/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.5099 - accuracy: 0.7993\n",
            "Epoch 85/400\n",
            "55/55 [==============================] - 5s 83ms/step - loss: 0.5169 - accuracy: 0.7885\n",
            "Epoch 86/400\n",
            "55/55 [==============================] - 5s 91ms/step - loss: 0.5108 - accuracy: 0.7959\n",
            "Epoch 87/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.5171 - accuracy: 0.7879\n",
            "Epoch 88/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.5201 - accuracy: 0.7919\n",
            "Epoch 89/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.5022 - accuracy: 0.7942\n",
            "Epoch 90/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.4944 - accuracy: 0.8039\n",
            "Epoch 91/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.5021 - accuracy: 0.7970\n",
            "Epoch 92/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.4998 - accuracy: 0.7993\n",
            "Epoch 93/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.4812 - accuracy: 0.8113\n",
            "Epoch 94/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.4867 - accuracy: 0.7993\n",
            "Epoch 95/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.4939 - accuracy: 0.7959\n",
            "Epoch 96/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4962 - accuracy: 0.8044\n",
            "Epoch 97/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.4838 - accuracy: 0.8044\n",
            "Epoch 98/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.4817 - accuracy: 0.8124\n",
            "Epoch 99/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.4732 - accuracy: 0.8090\n",
            "Epoch 100/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.4693 - accuracy: 0.8124\n",
            "Epoch 101/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.4706 - accuracy: 0.8096\n",
            "Epoch 102/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.4637 - accuracy: 0.8238\n",
            "Epoch 103/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.4683 - accuracy: 0.8005\n",
            "Epoch 104/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.4572 - accuracy: 0.8216\n",
            "Epoch 105/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.4715 - accuracy: 0.8084\n",
            "Epoch 106/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.4648 - accuracy: 0.8170\n",
            "Epoch 107/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4600 - accuracy: 0.8090\n",
            "Epoch 108/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.4659 - accuracy: 0.8073\n",
            "Epoch 109/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.4553 - accuracy: 0.8176\n",
            "Epoch 110/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.4539 - accuracy: 0.8210\n",
            "Epoch 111/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.4547 - accuracy: 0.8164\n",
            "Epoch 112/400\n",
            "55/55 [==============================] - 4s 64ms/step - loss: 0.4560 - accuracy: 0.8101\n",
            "Epoch 113/400\n",
            "55/55 [==============================] - 4s 64ms/step - loss: 0.4451 - accuracy: 0.8244\n",
            "Epoch 114/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.4437 - accuracy: 0.8295\n",
            "Epoch 115/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.4459 - accuracy: 0.8181\n",
            "Epoch 116/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.4395 - accuracy: 0.8187\n",
            "Epoch 117/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4466 - accuracy: 0.8210\n",
            "Epoch 118/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4476 - accuracy: 0.8164\n",
            "Epoch 119/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4324 - accuracy: 0.8312\n",
            "Epoch 120/400\n",
            "55/55 [==============================] - 6s 102ms/step - loss: 0.4350 - accuracy: 0.8318\n",
            "Epoch 121/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.4285 - accuracy: 0.8255\n",
            "Epoch 122/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.4348 - accuracy: 0.8324\n",
            "Epoch 123/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.4335 - accuracy: 0.8267\n",
            "Epoch 124/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.4296 - accuracy: 0.8273\n",
            "Epoch 125/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.4413 - accuracy: 0.8210\n",
            "Epoch 126/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.4311 - accuracy: 0.8312\n",
            "Epoch 127/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.4232 - accuracy: 0.8238\n",
            "Epoch 128/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.4222 - accuracy: 0.8278\n",
            "Epoch 129/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.4094 - accuracy: 0.8369\n",
            "Epoch 130/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.4283 - accuracy: 0.8267\n",
            "Epoch 131/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4119 - accuracy: 0.8381\n",
            "Epoch 132/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.4108 - accuracy: 0.8364\n",
            "Epoch 133/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.4079 - accuracy: 0.8409\n",
            "Epoch 134/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4025 - accuracy: 0.8404\n",
            "Epoch 135/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4032 - accuracy: 0.8307\n",
            "Epoch 136/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.4044 - accuracy: 0.8341\n",
            "Epoch 137/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3938 - accuracy: 0.8438\n",
            "Epoch 138/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.4120 - accuracy: 0.8364\n",
            "Epoch 139/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4032 - accuracy: 0.8375\n",
            "Epoch 140/400\n",
            "55/55 [==============================] - 4s 65ms/step - loss: 0.3996 - accuracy: 0.8449\n",
            "Epoch 141/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4049 - accuracy: 0.8426\n",
            "Epoch 142/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.4049 - accuracy: 0.8421\n",
            "Epoch 143/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.4118 - accuracy: 0.8312\n",
            "Epoch 144/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4013 - accuracy: 0.8301\n",
            "Epoch 145/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.3976 - accuracy: 0.8404\n",
            "Epoch 146/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.4015 - accuracy: 0.8478\n",
            "Epoch 147/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3934 - accuracy: 0.8455\n",
            "Epoch 148/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3984 - accuracy: 0.8438\n",
            "Epoch 149/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3788 - accuracy: 0.8483\n",
            "Epoch 150/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3891 - accuracy: 0.8506\n",
            "Epoch 151/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.3991 - accuracy: 0.8392\n",
            "Epoch 152/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3829 - accuracy: 0.8426\n",
            "Epoch 153/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3823 - accuracy: 0.8523\n",
            "Epoch 154/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3769 - accuracy: 0.8489\n",
            "Epoch 155/400\n",
            "55/55 [==============================] - 5s 97ms/step - loss: 0.3728 - accuracy: 0.8501\n",
            "Epoch 156/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.3860 - accuracy: 0.8546\n",
            "Epoch 157/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3715 - accuracy: 0.8552\n",
            "Epoch 158/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.3650 - accuracy: 0.8523\n",
            "Epoch 159/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.3867 - accuracy: 0.8540\n",
            "Epoch 160/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.3612 - accuracy: 0.8552\n",
            "Epoch 161/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.3669 - accuracy: 0.8597\n",
            "Epoch 162/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3681 - accuracy: 0.8558\n",
            "Epoch 163/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.3608 - accuracy: 0.8569\n",
            "Epoch 164/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.3663 - accuracy: 0.8535\n",
            "Epoch 165/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.3599 - accuracy: 0.8637\n",
            "Epoch 166/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.3659 - accuracy: 0.8586\n",
            "Epoch 167/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3578 - accuracy: 0.8552\n",
            "Epoch 168/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3500 - accuracy: 0.8712\n",
            "Epoch 169/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3491 - accuracy: 0.8597\n",
            "Epoch 170/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3416 - accuracy: 0.8700\n",
            "Epoch 171/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3684 - accuracy: 0.8461\n",
            "Epoch 172/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.3534 - accuracy: 0.8597\n",
            "Epoch 173/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3469 - accuracy: 0.8626\n",
            "Epoch 174/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.3521 - accuracy: 0.8632\n",
            "Epoch 175/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.3530 - accuracy: 0.8586\n",
            "Epoch 176/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.3445 - accuracy: 0.8706\n",
            "Epoch 177/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.3399 - accuracy: 0.8706\n",
            "Epoch 178/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3520 - accuracy: 0.8603\n",
            "Epoch 179/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.3520 - accuracy: 0.8563\n",
            "Epoch 180/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3476 - accuracy: 0.8700\n",
            "Epoch 181/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.3361 - accuracy: 0.8717\n",
            "Epoch 182/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3447 - accuracy: 0.8643\n",
            "Epoch 183/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.3392 - accuracy: 0.8694\n",
            "Epoch 184/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.3418 - accuracy: 0.8620\n",
            "Epoch 185/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.3315 - accuracy: 0.8774\n",
            "Epoch 186/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.3356 - accuracy: 0.8683\n",
            "Epoch 187/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.3223 - accuracy: 0.8786\n",
            "Epoch 188/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.3273 - accuracy: 0.8694\n",
            "Epoch 189/400\n",
            "55/55 [==============================] - 6s 102ms/step - loss: 0.3249 - accuracy: 0.8723\n",
            "Epoch 190/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3360 - accuracy: 0.8712\n",
            "Epoch 191/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3391 - accuracy: 0.8609\n",
            "Epoch 192/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.3285 - accuracy: 0.8672\n",
            "Epoch 193/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.3334 - accuracy: 0.8729\n",
            "Epoch 194/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.3248 - accuracy: 0.8717\n",
            "Epoch 195/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.3190 - accuracy: 0.8706\n",
            "Epoch 196/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.3138 - accuracy: 0.8808\n",
            "Epoch 197/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.3249 - accuracy: 0.8740\n",
            "Epoch 198/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.3086 - accuracy: 0.8797\n",
            "Epoch 199/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3172 - accuracy: 0.8717\n",
            "Epoch 200/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.3118 - accuracy: 0.8774\n",
            "Epoch 201/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.3211 - accuracy: 0.8746\n",
            "Epoch 202/400\n",
            "55/55 [==============================] - 4s 65ms/step - loss: 0.3163 - accuracy: 0.8746\n",
            "Epoch 203/400\n",
            "55/55 [==============================] - 4s 65ms/step - loss: 0.3106 - accuracy: 0.8820\n",
            "Epoch 204/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.3047 - accuracy: 0.8780\n",
            "Epoch 205/400\n",
            "55/55 [==============================] - 4s 65ms/step - loss: 0.3092 - accuracy: 0.8797\n",
            "Epoch 206/400\n",
            "55/55 [==============================] - 4s 65ms/step - loss: 0.3172 - accuracy: 0.8746\n",
            "Epoch 207/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.3214 - accuracy: 0.8700\n",
            "Epoch 208/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.3062 - accuracy: 0.8791\n",
            "Epoch 209/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.3064 - accuracy: 0.8860\n",
            "Epoch 210/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.3096 - accuracy: 0.8808\n",
            "Epoch 211/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3106 - accuracy: 0.8831\n",
            "Epoch 212/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3096 - accuracy: 0.8769\n",
            "Epoch 213/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.3043 - accuracy: 0.8814\n",
            "Epoch 214/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.3069 - accuracy: 0.8848\n",
            "Epoch 215/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2993 - accuracy: 0.8865\n",
            "Epoch 216/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.2948 - accuracy: 0.8797\n",
            "Epoch 217/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2964 - accuracy: 0.8883\n",
            "Epoch 218/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.3052 - accuracy: 0.8848\n",
            "Epoch 219/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.2958 - accuracy: 0.8865\n",
            "Epoch 220/400\n",
            "55/55 [==============================] - 4s 65ms/step - loss: 0.2952 - accuracy: 0.8940\n",
            "Epoch 221/400\n",
            "55/55 [==============================] - 4s 65ms/step - loss: 0.2894 - accuracy: 0.8917\n",
            "Epoch 222/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.3038 - accuracy: 0.8786\n",
            "Epoch 223/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.2880 - accuracy: 0.8871\n",
            "Epoch 224/400\n",
            "55/55 [==============================] - 6s 101ms/step - loss: 0.2824 - accuracy: 0.8951\n",
            "Epoch 225/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.2795 - accuracy: 0.9014\n",
            "Epoch 226/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2878 - accuracy: 0.8900\n",
            "Epoch 227/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.2833 - accuracy: 0.8905\n",
            "Epoch 228/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2702 - accuracy: 0.8974\n",
            "Epoch 229/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2992 - accuracy: 0.8837\n",
            "Epoch 230/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2852 - accuracy: 0.8928\n",
            "Epoch 231/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.2739 - accuracy: 0.8945\n",
            "Epoch 232/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.2763 - accuracy: 0.8945\n",
            "Epoch 233/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.2780 - accuracy: 0.8894\n",
            "Epoch 234/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2872 - accuracy: 0.8911\n",
            "Epoch 235/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2768 - accuracy: 0.8928\n",
            "Epoch 236/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2779 - accuracy: 0.8917\n",
            "Epoch 237/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.2902 - accuracy: 0.8883\n",
            "Epoch 238/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2785 - accuracy: 0.8951\n",
            "Epoch 239/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.2723 - accuracy: 0.9008\n",
            "Epoch 240/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.2647 - accuracy: 0.8985\n",
            "Epoch 241/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2658 - accuracy: 0.9082\n",
            "Epoch 242/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2710 - accuracy: 0.9071\n",
            "Epoch 243/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.2651 - accuracy: 0.8962\n",
            "Epoch 244/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2810 - accuracy: 0.8934\n",
            "Epoch 245/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.2691 - accuracy: 0.8979\n",
            "Epoch 246/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2711 - accuracy: 0.8951\n",
            "Epoch 247/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.2635 - accuracy: 0.8991\n",
            "Epoch 248/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.2652 - accuracy: 0.8991\n",
            "Epoch 249/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2642 - accuracy: 0.9048\n",
            "Epoch 250/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.2565 - accuracy: 0.8957\n",
            "Epoch 251/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2685 - accuracy: 0.8945\n",
            "Epoch 252/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.2733 - accuracy: 0.8951\n",
            "Epoch 253/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.2605 - accuracy: 0.9008\n",
            "Epoch 254/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.2655 - accuracy: 0.8991\n",
            "Epoch 255/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.2630 - accuracy: 0.8974\n",
            "Epoch 256/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.2568 - accuracy: 0.9048\n",
            "Epoch 257/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2703 - accuracy: 0.8934\n",
            "Epoch 258/400\n",
            "55/55 [==============================] - 5s 100ms/step - loss: 0.2550 - accuracy: 0.9042\n",
            "Epoch 259/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2529 - accuracy: 0.9088\n",
            "Epoch 260/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.2475 - accuracy: 0.9059\n",
            "Epoch 261/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.2606 - accuracy: 0.9059\n",
            "Epoch 262/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.2463 - accuracy: 0.9111\n",
            "Epoch 263/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2499 - accuracy: 0.9065\n",
            "Epoch 264/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2512 - accuracy: 0.9059\n",
            "Epoch 265/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2487 - accuracy: 0.9054\n",
            "Epoch 266/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2511 - accuracy: 0.9065\n",
            "Epoch 267/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.2503 - accuracy: 0.9065\n",
            "Epoch 268/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2464 - accuracy: 0.9025\n",
            "Epoch 269/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.2459 - accuracy: 0.9116\n",
            "Epoch 270/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.2542 - accuracy: 0.9019\n",
            "Epoch 271/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2474 - accuracy: 0.9059\n",
            "Epoch 272/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.2407 - accuracy: 0.9168\n",
            "Epoch 273/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2467 - accuracy: 0.9059\n",
            "Epoch 274/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.2408 - accuracy: 0.9059\n",
            "Epoch 275/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2338 - accuracy: 0.9190\n",
            "Epoch 276/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.2427 - accuracy: 0.9082\n",
            "Epoch 277/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2409 - accuracy: 0.9162\n",
            "Epoch 278/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2399 - accuracy: 0.9168\n",
            "Epoch 279/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.2457 - accuracy: 0.9065\n",
            "Epoch 280/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2336 - accuracy: 0.9111\n",
            "Epoch 281/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.2360 - accuracy: 0.9151\n",
            "Epoch 282/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.2470 - accuracy: 0.9036\n",
            "Epoch 283/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2386 - accuracy: 0.9054\n",
            "Epoch 284/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2308 - accuracy: 0.9208\n",
            "Epoch 285/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.2359 - accuracy: 0.9139\n",
            "Epoch 286/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2313 - accuracy: 0.9094\n",
            "Epoch 287/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.2290 - accuracy: 0.9196\n",
            "Epoch 288/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2256 - accuracy: 0.9076\n",
            "Epoch 289/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.2321 - accuracy: 0.9082\n",
            "Epoch 290/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2267 - accuracy: 0.9145\n",
            "Epoch 291/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2321 - accuracy: 0.9173\n",
            "Epoch 292/400\n",
            "55/55 [==============================] - 5s 99ms/step - loss: 0.2260 - accuracy: 0.9156\n",
            "Epoch 293/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.2203 - accuracy: 0.9133\n",
            "Epoch 294/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.2203 - accuracy: 0.9168\n",
            "Epoch 295/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.2315 - accuracy: 0.9116\n",
            "Epoch 296/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.2228 - accuracy: 0.9151\n",
            "Epoch 297/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.2275 - accuracy: 0.9225\n",
            "Epoch 298/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.2249 - accuracy: 0.9168\n",
            "Epoch 299/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.2270 - accuracy: 0.9128\n",
            "Epoch 300/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.2129 - accuracy: 0.9208\n",
            "Epoch 301/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.2213 - accuracy: 0.9225\n",
            "Epoch 302/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2202 - accuracy: 0.9185\n",
            "Epoch 303/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.2228 - accuracy: 0.9208\n",
            "Epoch 304/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2136 - accuracy: 0.9190\n",
            "Epoch 305/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.2066 - accuracy: 0.9230\n",
            "Epoch 306/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.2104 - accuracy: 0.9202\n",
            "Epoch 307/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2155 - accuracy: 0.9225\n",
            "Epoch 308/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2300 - accuracy: 0.9116\n",
            "Epoch 309/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.2237 - accuracy: 0.9202\n",
            "Epoch 310/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2191 - accuracy: 0.9213\n",
            "Epoch 311/400\n",
            "55/55 [==============================] - 4s 66ms/step - loss: 0.2121 - accuracy: 0.9185\n",
            "Epoch 312/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2092 - accuracy: 0.9213\n",
            "Epoch 313/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.2179 - accuracy: 0.9196\n",
            "Epoch 314/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2098 - accuracy: 0.9253\n",
            "Epoch 315/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.2098 - accuracy: 0.9242\n",
            "Epoch 316/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2115 - accuracy: 0.9202\n",
            "Epoch 317/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2058 - accuracy: 0.9253\n",
            "Epoch 318/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.2027 - accuracy: 0.9259\n",
            "Epoch 319/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.2110 - accuracy: 0.9219\n",
            "Epoch 320/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.2078 - accuracy: 0.9213\n",
            "Epoch 321/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2025 - accuracy: 0.9282\n",
            "Epoch 322/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2058 - accuracy: 0.9225\n",
            "Epoch 323/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2097 - accuracy: 0.9259\n",
            "Epoch 324/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.1998 - accuracy: 0.9293\n",
            "Epoch 325/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.2061 - accuracy: 0.9265\n",
            "Epoch 326/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.1943 - accuracy: 0.9253\n",
            "Epoch 327/400\n",
            "55/55 [==============================] - 6s 104ms/step - loss: 0.2029 - accuracy: 0.9293\n",
            "Epoch 328/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.2006 - accuracy: 0.9282\n",
            "Epoch 329/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2017 - accuracy: 0.9225\n",
            "Epoch 330/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.2029 - accuracy: 0.9282\n",
            "Epoch 331/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1916 - accuracy: 0.9276\n",
            "Epoch 332/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.1934 - accuracy: 0.9310\n",
            "Epoch 333/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.1982 - accuracy: 0.9265\n",
            "Epoch 334/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.1962 - accuracy: 0.9299\n",
            "Epoch 335/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.1865 - accuracy: 0.9350\n",
            "Epoch 336/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.1944 - accuracy: 0.9304\n",
            "Epoch 337/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.1939 - accuracy: 0.9202\n",
            "Epoch 338/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.1884 - accuracy: 0.9327\n",
            "Epoch 339/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1955 - accuracy: 0.9327\n",
            "Epoch 340/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.1957 - accuracy: 0.9270\n",
            "Epoch 341/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1884 - accuracy: 0.9344\n",
            "Epoch 342/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.1875 - accuracy: 0.9287\n",
            "Epoch 343/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.1884 - accuracy: 0.9322\n",
            "Epoch 344/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.1896 - accuracy: 0.9333\n",
            "Epoch 345/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.1868 - accuracy: 0.9310\n",
            "Epoch 346/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1855 - accuracy: 0.9350\n",
            "Epoch 347/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.1851 - accuracy: 0.9316\n",
            "Epoch 348/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.1811 - accuracy: 0.9333\n",
            "Epoch 349/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1677 - accuracy: 0.9430\n",
            "Epoch 350/400\n",
            "55/55 [==============================] - 4s 68ms/step - loss: 0.1841 - accuracy: 0.9287\n",
            "Epoch 351/400\n",
            "55/55 [==============================] - 4s 67ms/step - loss: 0.1827 - accuracy: 0.9293\n",
            "Epoch 352/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.1824 - accuracy: 0.9304\n",
            "Epoch 353/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.1844 - accuracy: 0.9310\n",
            "Epoch 354/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.1804 - accuracy: 0.9373\n",
            "Epoch 355/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1813 - accuracy: 0.9356\n",
            "Epoch 356/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.1854 - accuracy: 0.9339\n",
            "Epoch 357/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.1772 - accuracy: 0.9304\n",
            "Epoch 358/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1856 - accuracy: 0.9396\n",
            "Epoch 359/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.1686 - accuracy: 0.9441\n",
            "Epoch 360/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.1686 - accuracy: 0.9418\n",
            "Epoch 361/400\n",
            "55/55 [==============================] - 6s 105ms/step - loss: 0.1716 - accuracy: 0.9367\n",
            "Epoch 362/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.1782 - accuracy: 0.9401\n",
            "Epoch 363/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.1670 - accuracy: 0.9361\n",
            "Epoch 364/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.1841 - accuracy: 0.9299\n",
            "Epoch 365/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.1852 - accuracy: 0.9310\n",
            "Epoch 366/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1684 - accuracy: 0.9401\n",
            "Epoch 367/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1689 - accuracy: 0.9413\n",
            "Epoch 368/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1753 - accuracy: 0.9379\n",
            "Epoch 369/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.1744 - accuracy: 0.9413\n",
            "Epoch 370/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1724 - accuracy: 0.9361\n",
            "Epoch 371/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.1670 - accuracy: 0.9413\n",
            "Epoch 372/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.1732 - accuracy: 0.9407\n",
            "Epoch 373/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.1756 - accuracy: 0.9310\n",
            "Epoch 374/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.1777 - accuracy: 0.9396\n",
            "Epoch 375/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.1670 - accuracy: 0.9390\n",
            "Epoch 376/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1744 - accuracy: 0.9379\n",
            "Epoch 377/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.1708 - accuracy: 0.9424\n",
            "Epoch 378/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.1782 - accuracy: 0.9344\n",
            "Epoch 379/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.1779 - accuracy: 0.9361\n",
            "Epoch 380/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.1720 - accuracy: 0.9373\n",
            "Epoch 381/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.1655 - accuracy: 0.9361\n",
            "Epoch 382/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.1607 - accuracy: 0.9447\n",
            "Epoch 383/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.1528 - accuracy: 0.9521\n",
            "Epoch 384/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.1664 - accuracy: 0.9384\n",
            "Epoch 385/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1574 - accuracy: 0.9464\n",
            "Epoch 386/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.1688 - accuracy: 0.9350\n",
            "Epoch 387/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.1700 - accuracy: 0.9413\n",
            "Epoch 388/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.1592 - accuracy: 0.9453\n",
            "Epoch 389/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.1576 - accuracy: 0.9418\n",
            "Epoch 390/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.1699 - accuracy: 0.9424\n",
            "Epoch 391/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1579 - accuracy: 0.9447\n",
            "Epoch 392/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.1683 - accuracy: 0.9379\n",
            "Epoch 393/400\n",
            "55/55 [==============================] - 5s 82ms/step - loss: 0.1574 - accuracy: 0.9458\n",
            "Epoch 394/400\n",
            "55/55 [==============================] - 5s 95ms/step - loss: 0.1608 - accuracy: 0.9407\n",
            "Epoch 395/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1561 - accuracy: 0.9481\n",
            "Epoch 396/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.1496 - accuracy: 0.9470\n",
            "Epoch 397/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.1595 - accuracy: 0.9436\n",
            "Epoch 398/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.1542 - accuracy: 0.9487\n",
            "Epoch 399/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.1685 - accuracy: 0.9390\n",
            "Epoch 400/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.1524 - accuracy: 0.9458\n",
            "28/28 [==============================] - 1s 17ms/step - loss: 1.2806 - accuracy: 0.7882\n",
            "Model evaluation  [1.2805653810501099, 0.7881549000740051]\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_3 (Conv1D)           (None, 193, 128)          512       \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 193, 128)          0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 193, 128)          0         \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 96, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 96, 128)           49280     \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 96, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 48, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 48, 128)           0         \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 48, 128)           49280     \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 48, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 24, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 24, 128)           0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 12292     \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 111,364\n",
            "Trainable params: 111,364\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/400\n",
            "55/55 [==============================] - 5s 72ms/step - loss: 1.7638 - accuracy: 0.3140\n",
            "Epoch 2/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 1.4449 - accuracy: 0.4063\n",
            "Epoch 3/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 1.3926 - accuracy: 0.3943\n",
            "Epoch 4/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 1.2812 - accuracy: 0.4342\n",
            "Epoch 5/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 1.2454 - accuracy: 0.4439\n",
            "Epoch 6/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 1.1601 - accuracy: 0.4917\n",
            "Epoch 7/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 1.1451 - accuracy: 0.4803\n",
            "Epoch 8/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 1.1193 - accuracy: 0.4986\n",
            "Epoch 9/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 1.0617 - accuracy: 0.5322\n",
            "Epoch 10/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 1.0192 - accuracy: 0.5533\n",
            "Epoch 11/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 1.0196 - accuracy: 0.5464\n",
            "Epoch 12/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.9777 - accuracy: 0.5613\n",
            "Epoch 13/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.9646 - accuracy: 0.5778\n",
            "Epoch 14/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.9357 - accuracy: 0.6006\n",
            "Epoch 15/400\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.9081 - accuracy: 0.6085\n",
            "Epoch 16/400\n",
            "55/55 [==============================] - 5s 95ms/step - loss: 0.8930 - accuracy: 0.6171\n",
            "Epoch 17/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.9040 - accuracy: 0.6251\n",
            "Epoch 18/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.8572 - accuracy: 0.6313\n",
            "Epoch 19/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.8583 - accuracy: 0.6359\n",
            "Epoch 20/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.8410 - accuracy: 0.6450\n",
            "Epoch 21/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.8228 - accuracy: 0.6615\n",
            "Epoch 22/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.8166 - accuracy: 0.6479\n",
            "Epoch 23/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.8045 - accuracy: 0.6655\n",
            "Epoch 24/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.7892 - accuracy: 0.6741\n",
            "Epoch 25/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.7932 - accuracy: 0.6781\n",
            "Epoch 26/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.7713 - accuracy: 0.6815\n",
            "Epoch 27/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.7393 - accuracy: 0.6900\n",
            "Epoch 28/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.7527 - accuracy: 0.6849\n",
            "Epoch 29/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.7478 - accuracy: 0.6821\n",
            "Epoch 30/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.7383 - accuracy: 0.6929\n",
            "Epoch 31/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.7190 - accuracy: 0.6929\n",
            "Epoch 32/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.7095 - accuracy: 0.7031\n",
            "Epoch 33/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.7102 - accuracy: 0.7105\n",
            "Epoch 34/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.7118 - accuracy: 0.7105\n",
            "Epoch 35/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.7006 - accuracy: 0.7219\n",
            "Epoch 36/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.6883 - accuracy: 0.7265\n",
            "Epoch 37/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.6863 - accuracy: 0.7254\n",
            "Epoch 38/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.6694 - accuracy: 0.7271\n",
            "Epoch 39/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.6781 - accuracy: 0.7157\n",
            "Epoch 40/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.6703 - accuracy: 0.7254\n",
            "Epoch 41/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.6788 - accuracy: 0.7202\n",
            "Epoch 42/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.6587 - accuracy: 0.7299\n",
            "Epoch 43/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.6504 - accuracy: 0.7362\n",
            "Epoch 44/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.6425 - accuracy: 0.7436\n",
            "Epoch 45/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.6525 - accuracy: 0.7316\n",
            "Epoch 46/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.6338 - accuracy: 0.7368\n",
            "Epoch 47/400\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 0.6243 - accuracy: 0.7407\n",
            "Epoch 48/400\n",
            "55/55 [==============================] - 5s 96ms/step - loss: 0.6181 - accuracy: 0.7567\n",
            "Epoch 49/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.6187 - accuracy: 0.7425\n",
            "Epoch 50/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.6244 - accuracy: 0.7464\n",
            "Epoch 51/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.6217 - accuracy: 0.7402\n",
            "Epoch 52/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.6210 - accuracy: 0.7396\n",
            "Epoch 53/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.5981 - accuracy: 0.7516\n",
            "Epoch 54/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.6147 - accuracy: 0.7493\n",
            "Epoch 55/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.5945 - accuracy: 0.7527\n",
            "Epoch 56/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.5976 - accuracy: 0.7533\n",
            "Epoch 57/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.5974 - accuracy: 0.7584\n",
            "Epoch 58/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.5684 - accuracy: 0.7658\n",
            "Epoch 59/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.5680 - accuracy: 0.7647\n",
            "Epoch 60/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.5857 - accuracy: 0.7561\n",
            "Epoch 61/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.5763 - accuracy: 0.7601\n",
            "Epoch 62/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.5756 - accuracy: 0.7738\n",
            "Epoch 63/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.5688 - accuracy: 0.7607\n",
            "Epoch 64/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.5600 - accuracy: 0.7692\n",
            "Epoch 65/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.5409 - accuracy: 0.7778\n",
            "Epoch 66/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.5609 - accuracy: 0.7664\n",
            "Epoch 67/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.5538 - accuracy: 0.7641\n",
            "Epoch 68/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.5556 - accuracy: 0.7635\n",
            "Epoch 69/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.5415 - accuracy: 0.7732\n",
            "Epoch 70/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.5512 - accuracy: 0.7823\n",
            "Epoch 71/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.5474 - accuracy: 0.7709\n",
            "Epoch 72/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.5382 - accuracy: 0.7835\n",
            "Epoch 73/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.5321 - accuracy: 0.7744\n",
            "Epoch 74/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.5300 - accuracy: 0.7829\n",
            "Epoch 75/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.5269 - accuracy: 0.7846\n",
            "Epoch 76/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.5269 - accuracy: 0.7835\n",
            "Epoch 77/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.5289 - accuracy: 0.7840\n",
            "Epoch 78/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.5092 - accuracy: 0.7875\n",
            "Epoch 79/400\n",
            "55/55 [==============================] - 6s 106ms/step - loss: 0.5229 - accuracy: 0.7886\n",
            "Epoch 80/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.5071 - accuracy: 0.7909\n",
            "Epoch 81/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.5104 - accuracy: 0.7846\n",
            "Epoch 82/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.5090 - accuracy: 0.7943\n",
            "Epoch 83/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.5153 - accuracy: 0.7897\n",
            "Epoch 84/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4999 - accuracy: 0.7977\n",
            "Epoch 85/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.4839 - accuracy: 0.8097\n",
            "Epoch 86/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4969 - accuracy: 0.8080\n",
            "Epoch 87/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.4964 - accuracy: 0.7983\n",
            "Epoch 88/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.5051 - accuracy: 0.7863\n",
            "Epoch 89/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4886 - accuracy: 0.8023\n",
            "Epoch 90/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.4869 - accuracy: 0.7977\n",
            "Epoch 91/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4860 - accuracy: 0.8006\n",
            "Epoch 92/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4790 - accuracy: 0.8085\n",
            "Epoch 93/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.4867 - accuracy: 0.8040\n",
            "Epoch 94/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4811 - accuracy: 0.8034\n",
            "Epoch 95/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.4820 - accuracy: 0.7966\n",
            "Epoch 96/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.4743 - accuracy: 0.8028\n",
            "Epoch 97/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.4634 - accuracy: 0.8074\n",
            "Epoch 98/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.4688 - accuracy: 0.8051\n",
            "Epoch 99/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.4781 - accuracy: 0.8023\n",
            "Epoch 100/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.4736 - accuracy: 0.8011\n",
            "Epoch 101/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4517 - accuracy: 0.8217\n",
            "Epoch 102/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.4689 - accuracy: 0.8051\n",
            "Epoch 103/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.4671 - accuracy: 0.8046\n",
            "Epoch 104/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.4685 - accuracy: 0.8103\n",
            "Epoch 105/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.4498 - accuracy: 0.8148\n",
            "Epoch 106/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.4415 - accuracy: 0.8199\n",
            "Epoch 107/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.4450 - accuracy: 0.8256\n",
            "Epoch 108/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.4520 - accuracy: 0.8063\n",
            "Epoch 109/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4359 - accuracy: 0.8160\n",
            "Epoch 110/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.4407 - accuracy: 0.8165\n",
            "Epoch 111/400\n",
            "55/55 [==============================] - 6s 104ms/step - loss: 0.4408 - accuracy: 0.8262\n",
            "Epoch 112/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.4348 - accuracy: 0.8199\n",
            "Epoch 113/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.4370 - accuracy: 0.8262\n",
            "Epoch 114/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.4377 - accuracy: 0.8165\n",
            "Epoch 115/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.4397 - accuracy: 0.8188\n",
            "Epoch 116/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.4238 - accuracy: 0.8291\n",
            "Epoch 117/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.4344 - accuracy: 0.8188\n",
            "Epoch 118/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.4240 - accuracy: 0.8274\n",
            "Epoch 119/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.4204 - accuracy: 0.8239\n",
            "Epoch 120/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.4134 - accuracy: 0.8387\n",
            "Epoch 121/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.4234 - accuracy: 0.8359\n",
            "Epoch 122/400\n",
            "55/55 [==============================] - 4s 69ms/step - loss: 0.4175 - accuracy: 0.8285\n",
            "Epoch 123/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.4015 - accuracy: 0.8416\n",
            "Epoch 124/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.4129 - accuracy: 0.8262\n",
            "Epoch 125/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4175 - accuracy: 0.8348\n",
            "Epoch 126/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.4254 - accuracy: 0.8308\n",
            "Epoch 127/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.4151 - accuracy: 0.8285\n",
            "Epoch 128/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3990 - accuracy: 0.8405\n",
            "Epoch 129/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4125 - accuracy: 0.8336\n",
            "Epoch 130/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4043 - accuracy: 0.8342\n",
            "Epoch 131/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4133 - accuracy: 0.8330\n",
            "Epoch 132/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.4006 - accuracy: 0.8422\n",
            "Epoch 133/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.3878 - accuracy: 0.8433\n",
            "Epoch 134/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3858 - accuracy: 0.8427\n",
            "Epoch 135/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.3962 - accuracy: 0.8330\n",
            "Epoch 136/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4032 - accuracy: 0.8365\n",
            "Epoch 137/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.4015 - accuracy: 0.8313\n",
            "Epoch 138/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3893 - accuracy: 0.8387\n",
            "Epoch 139/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.3920 - accuracy: 0.8444\n",
            "Epoch 140/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.3932 - accuracy: 0.8325\n",
            "Epoch 141/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3863 - accuracy: 0.8427\n",
            "Epoch 142/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3875 - accuracy: 0.8382\n",
            "Epoch 143/400\n",
            "55/55 [==============================] - 6s 107ms/step - loss: 0.3875 - accuracy: 0.8416\n",
            "Epoch 144/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.3681 - accuracy: 0.8484\n",
            "Epoch 145/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3756 - accuracy: 0.8484\n",
            "Epoch 146/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.3725 - accuracy: 0.8530\n",
            "Epoch 147/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3767 - accuracy: 0.8473\n",
            "Epoch 148/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3731 - accuracy: 0.8479\n",
            "Epoch 149/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.3713 - accuracy: 0.8507\n",
            "Epoch 150/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.3836 - accuracy: 0.8422\n",
            "Epoch 151/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.3755 - accuracy: 0.8439\n",
            "Epoch 152/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.3707 - accuracy: 0.8473\n",
            "Epoch 153/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3745 - accuracy: 0.8524\n",
            "Epoch 154/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.3603 - accuracy: 0.8530\n",
            "Epoch 155/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3595 - accuracy: 0.8513\n",
            "Epoch 156/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3734 - accuracy: 0.8513\n",
            "Epoch 157/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.3720 - accuracy: 0.8496\n",
            "Epoch 158/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3535 - accuracy: 0.8638\n",
            "Epoch 159/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.3540 - accuracy: 0.8530\n",
            "Epoch 160/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.3608 - accuracy: 0.8519\n",
            "Epoch 161/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3646 - accuracy: 0.8581\n",
            "Epoch 162/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.3592 - accuracy: 0.8547\n",
            "Epoch 163/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.3660 - accuracy: 0.8587\n",
            "Epoch 164/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.3713 - accuracy: 0.8536\n",
            "Epoch 165/400\n",
            "55/55 [==============================] - 4s 71ms/step - loss: 0.3423 - accuracy: 0.8615\n",
            "Epoch 166/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3514 - accuracy: 0.8627\n",
            "Epoch 167/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3433 - accuracy: 0.8610\n",
            "Epoch 168/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.3494 - accuracy: 0.8655\n",
            "Epoch 169/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.3325 - accuracy: 0.8712\n",
            "Epoch 170/400\n",
            "55/55 [==============================] - 4s 70ms/step - loss: 0.3466 - accuracy: 0.8570\n",
            "Epoch 171/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3405 - accuracy: 0.8650\n",
            "Epoch 172/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.3358 - accuracy: 0.8644\n",
            "Epoch 173/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3504 - accuracy: 0.8689\n",
            "Epoch 174/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.3373 - accuracy: 0.8689\n",
            "Epoch 175/400\n",
            "55/55 [==============================] - 5s 94ms/step - loss: 0.3327 - accuracy: 0.8672\n",
            "Epoch 176/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.3408 - accuracy: 0.8650\n",
            "Epoch 177/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.3310 - accuracy: 0.8661\n",
            "Epoch 178/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.3313 - accuracy: 0.8615\n",
            "Epoch 179/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3320 - accuracy: 0.8746\n",
            "Epoch 180/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3308 - accuracy: 0.8610\n",
            "Epoch 181/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3336 - accuracy: 0.8632\n",
            "Epoch 182/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3280 - accuracy: 0.8644\n",
            "Epoch 183/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3215 - accuracy: 0.8695\n",
            "Epoch 184/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.3208 - accuracy: 0.8769\n",
            "Epoch 185/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3280 - accuracy: 0.8638\n",
            "Epoch 186/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.3251 - accuracy: 0.8729\n",
            "Epoch 187/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.3122 - accuracy: 0.8752\n",
            "Epoch 188/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3171 - accuracy: 0.8752\n",
            "Epoch 189/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3138 - accuracy: 0.8684\n",
            "Epoch 190/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.3148 - accuracy: 0.8752\n",
            "Epoch 191/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3189 - accuracy: 0.8695\n",
            "Epoch 192/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.3185 - accuracy: 0.8769\n",
            "Epoch 193/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3093 - accuracy: 0.8735\n",
            "Epoch 194/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3080 - accuracy: 0.8752\n",
            "Epoch 195/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.3171 - accuracy: 0.8752\n",
            "Epoch 196/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3027 - accuracy: 0.8815\n",
            "Epoch 197/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3016 - accuracy: 0.8815\n",
            "Epoch 198/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3141 - accuracy: 0.8764\n",
            "Epoch 199/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3132 - accuracy: 0.8758\n",
            "Epoch 200/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3081 - accuracy: 0.8792\n",
            "Epoch 201/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3036 - accuracy: 0.8798\n",
            "Epoch 202/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.3081 - accuracy: 0.8786\n",
            "Epoch 203/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.3063 - accuracy: 0.8758\n",
            "Epoch 204/400\n",
            "55/55 [==============================] - 6s 109ms/step - loss: 0.3048 - accuracy: 0.8786\n",
            "Epoch 205/400\n",
            "55/55 [==============================] - 8s 146ms/step - loss: 0.2962 - accuracy: 0.8803\n",
            "Epoch 206/400\n",
            "55/55 [==============================] - 8s 138ms/step - loss: 0.2895 - accuracy: 0.8832\n",
            "Epoch 207/400\n",
            "55/55 [==============================] - 10s 175ms/step - loss: 0.3066 - accuracy: 0.8752\n",
            "Epoch 208/400\n",
            "55/55 [==============================] - 8s 141ms/step - loss: 0.3101 - accuracy: 0.8832\n",
            "Epoch 209/400\n",
            "55/55 [==============================] - 7s 135ms/step - loss: 0.2985 - accuracy: 0.8843\n",
            "Epoch 210/400\n",
            "55/55 [==============================] - 6s 114ms/step - loss: 0.2995 - accuracy: 0.8798\n",
            "Epoch 211/400\n",
            "55/55 [==============================] - 6s 114ms/step - loss: 0.3007 - accuracy: 0.8781\n",
            "Epoch 212/400\n",
            "55/55 [==============================] - 6s 117ms/step - loss: 0.2986 - accuracy: 0.8826\n",
            "Epoch 213/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2812 - accuracy: 0.8895\n",
            "Epoch 214/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2839 - accuracy: 0.8821\n",
            "Epoch 215/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2894 - accuracy: 0.8803\n",
            "Epoch 216/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2958 - accuracy: 0.8866\n",
            "Epoch 217/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2887 - accuracy: 0.8912\n",
            "Epoch 218/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.2880 - accuracy: 0.8843\n",
            "Epoch 219/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2892 - accuracy: 0.8843\n",
            "Epoch 220/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2782 - accuracy: 0.8912\n",
            "Epoch 221/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.2907 - accuracy: 0.8860\n",
            "Epoch 222/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2889 - accuracy: 0.8883\n",
            "Epoch 223/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2813 - accuracy: 0.8940\n",
            "Epoch 224/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2860 - accuracy: 0.8872\n",
            "Epoch 225/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2881 - accuracy: 0.8872\n",
            "Epoch 226/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2732 - accuracy: 0.8895\n",
            "Epoch 227/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2705 - accuracy: 0.9020\n",
            "Epoch 228/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2832 - accuracy: 0.8866\n",
            "Epoch 229/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2730 - accuracy: 0.8917\n",
            "Epoch 230/400\n",
            "55/55 [==============================] - 5s 92ms/step - loss: 0.2794 - accuracy: 0.8895\n",
            "Epoch 231/400\n",
            "55/55 [==============================] - 5s 90ms/step - loss: 0.2710 - accuracy: 0.8957\n",
            "Epoch 232/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2788 - accuracy: 0.8866\n",
            "Epoch 233/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2731 - accuracy: 0.8917\n",
            "Epoch 234/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2710 - accuracy: 0.8957\n",
            "Epoch 235/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2609 - accuracy: 0.8986\n",
            "Epoch 236/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2601 - accuracy: 0.8877\n",
            "Epoch 237/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2667 - accuracy: 0.8934\n",
            "Epoch 238/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.2626 - accuracy: 0.8957\n",
            "Epoch 239/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2602 - accuracy: 0.8991\n",
            "Epoch 240/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2572 - accuracy: 0.8969\n",
            "Epoch 241/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2653 - accuracy: 0.8969\n",
            "Epoch 242/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2721 - accuracy: 0.9003\n",
            "Epoch 243/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.2594 - accuracy: 0.8980\n",
            "Epoch 244/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2509 - accuracy: 0.9083\n",
            "Epoch 245/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2536 - accuracy: 0.9026\n",
            "Epoch 246/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.2605 - accuracy: 0.9026\n",
            "Epoch 247/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2621 - accuracy: 0.8980\n",
            "Epoch 248/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2542 - accuracy: 0.8991\n",
            "Epoch 249/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2464 - accuracy: 0.9031\n",
            "Epoch 250/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2524 - accuracy: 0.9037\n",
            "Epoch 251/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2550 - accuracy: 0.9009\n",
            "Epoch 252/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2536 - accuracy: 0.8974\n",
            "Epoch 253/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2494 - accuracy: 0.9020\n",
            "Epoch 254/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2450 - accuracy: 0.9100\n",
            "Epoch 255/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2437 - accuracy: 0.9031\n",
            "Epoch 256/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2529 - accuracy: 0.9009\n",
            "Epoch 257/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2461 - accuracy: 0.9026\n",
            "Epoch 258/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2542 - accuracy: 0.9037\n",
            "Epoch 259/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2511 - accuracy: 0.8940\n",
            "Epoch 260/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2421 - accuracy: 0.9071\n",
            "Epoch 261/400\n",
            "55/55 [==============================] - 5s 90ms/step - loss: 0.2467 - accuracy: 0.9026\n",
            "Epoch 262/400\n",
            "55/55 [==============================] - 5s 97ms/step - loss: 0.2365 - accuracy: 0.9043\n",
            "Epoch 263/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2361 - accuracy: 0.9083\n",
            "Epoch 264/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2356 - accuracy: 0.9123\n",
            "Epoch 265/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2407 - accuracy: 0.9066\n",
            "Epoch 266/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2237 - accuracy: 0.9162\n",
            "Epoch 267/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.2385 - accuracy: 0.9003\n",
            "Epoch 268/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.2434 - accuracy: 0.9066\n",
            "Epoch 269/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2438 - accuracy: 0.9003\n",
            "Epoch 270/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2345 - accuracy: 0.9128\n",
            "Epoch 271/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2406 - accuracy: 0.9083\n",
            "Epoch 272/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2264 - accuracy: 0.9145\n",
            "Epoch 273/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2443 - accuracy: 0.9071\n",
            "Epoch 274/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2282 - accuracy: 0.9083\n",
            "Epoch 275/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2302 - accuracy: 0.9066\n",
            "Epoch 276/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.2208 - accuracy: 0.9197\n",
            "Epoch 277/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2274 - accuracy: 0.9123\n",
            "Epoch 278/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2279 - accuracy: 0.9094\n",
            "Epoch 279/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2270 - accuracy: 0.9088\n",
            "Epoch 280/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2259 - accuracy: 0.9145\n",
            "Epoch 281/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2196 - accuracy: 0.9168\n",
            "Epoch 282/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2367 - accuracy: 0.9100\n",
            "Epoch 283/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.2209 - accuracy: 0.9168\n",
            "Epoch 284/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2263 - accuracy: 0.9185\n",
            "Epoch 285/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2177 - accuracy: 0.9140\n",
            "Epoch 286/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2285 - accuracy: 0.9168\n",
            "Epoch 287/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2259 - accuracy: 0.9105\n",
            "Epoch 288/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2159 - accuracy: 0.9123\n",
            "Epoch 289/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2223 - accuracy: 0.9185\n",
            "Epoch 290/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2083 - accuracy: 0.9236\n",
            "Epoch 291/400\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 0.2191 - accuracy: 0.9174\n",
            "Epoch 292/400\n",
            "55/55 [==============================] - 6s 103ms/step - loss: 0.2149 - accuracy: 0.9145\n",
            "Epoch 293/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2202 - accuracy: 0.9140\n",
            "Epoch 294/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2117 - accuracy: 0.9236\n",
            "Epoch 295/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2118 - accuracy: 0.9162\n",
            "Epoch 296/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2125 - accuracy: 0.9191\n",
            "Epoch 297/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2194 - accuracy: 0.9162\n",
            "Epoch 298/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2205 - accuracy: 0.9168\n",
            "Epoch 299/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2111 - accuracy: 0.9157\n",
            "Epoch 300/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.2199 - accuracy: 0.9157\n",
            "Epoch 301/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2020 - accuracy: 0.9259\n",
            "Epoch 302/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2107 - accuracy: 0.9254\n",
            "Epoch 303/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.2079 - accuracy: 0.9174\n",
            "Epoch 304/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2092 - accuracy: 0.9197\n",
            "Epoch 305/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2086 - accuracy: 0.9197\n",
            "Epoch 306/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2072 - accuracy: 0.9162\n",
            "Epoch 307/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1961 - accuracy: 0.9236\n",
            "Epoch 308/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2029 - accuracy: 0.9254\n",
            "Epoch 309/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.2102 - accuracy: 0.9128\n",
            "Epoch 310/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.2071 - accuracy: 0.9225\n",
            "Epoch 311/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2148 - accuracy: 0.9208\n",
            "Epoch 312/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2001 - accuracy: 0.9254\n",
            "Epoch 313/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2059 - accuracy: 0.9208\n",
            "Epoch 314/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1895 - accuracy: 0.9316\n",
            "Epoch 315/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.2013 - accuracy: 0.9248\n",
            "Epoch 316/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.1996 - accuracy: 0.9225\n",
            "Epoch 317/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.2027 - accuracy: 0.9282\n",
            "Epoch 318/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1932 - accuracy: 0.9322\n",
            "Epoch 319/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1950 - accuracy: 0.9282\n",
            "Epoch 320/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2044 - accuracy: 0.9197\n",
            "Epoch 321/400\n",
            "55/55 [==============================] - 5s 94ms/step - loss: 0.1980 - accuracy: 0.9225\n",
            "Epoch 322/400\n",
            "55/55 [==============================] - 5s 94ms/step - loss: 0.2009 - accuracy: 0.9236\n",
            "Epoch 323/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2051 - accuracy: 0.9225\n",
            "Epoch 324/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1918 - accuracy: 0.9231\n",
            "Epoch 325/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2024 - accuracy: 0.9254\n",
            "Epoch 326/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1885 - accuracy: 0.9265\n",
            "Epoch 327/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1865 - accuracy: 0.9265\n",
            "Epoch 328/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.1982 - accuracy: 0.9248\n",
            "Epoch 329/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.2018 - accuracy: 0.9236\n",
            "Epoch 330/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1861 - accuracy: 0.9265\n",
            "Epoch 331/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1935 - accuracy: 0.9271\n",
            "Epoch 332/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1897 - accuracy: 0.9339\n",
            "Epoch 333/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1861 - accuracy: 0.9311\n",
            "Epoch 334/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1890 - accuracy: 0.9299\n",
            "Epoch 335/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.1853 - accuracy: 0.9339\n",
            "Epoch 336/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1878 - accuracy: 0.9316\n",
            "Epoch 337/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1890 - accuracy: 0.9271\n",
            "Epoch 338/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1792 - accuracy: 0.9339\n",
            "Epoch 339/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1797 - accuracy: 0.9350\n",
            "Epoch 340/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1884 - accuracy: 0.9265\n",
            "Epoch 341/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1868 - accuracy: 0.9259\n",
            "Epoch 342/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1766 - accuracy: 0.9322\n",
            "Epoch 343/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1829 - accuracy: 0.9328\n",
            "Epoch 344/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1767 - accuracy: 0.9316\n",
            "Epoch 345/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1828 - accuracy: 0.9316\n",
            "Epoch 346/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1845 - accuracy: 0.9311\n",
            "Epoch 347/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1779 - accuracy: 0.9328\n",
            "Epoch 348/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1692 - accuracy: 0.9362\n",
            "Epoch 349/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1911 - accuracy: 0.9231\n",
            "Epoch 350/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1805 - accuracy: 0.9362\n",
            "Epoch 351/400\n",
            "55/55 [==============================] - 5s 83ms/step - loss: 0.1741 - accuracy: 0.9425\n",
            "Epoch 352/400\n",
            "55/55 [==============================] - 6s 102ms/step - loss: 0.1734 - accuracy: 0.9368\n",
            "Epoch 353/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1867 - accuracy: 0.9311\n",
            "Epoch 354/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1788 - accuracy: 0.9299\n",
            "Epoch 355/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1751 - accuracy: 0.9328\n",
            "Epoch 356/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1656 - accuracy: 0.9436\n",
            "Epoch 357/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1819 - accuracy: 0.9350\n",
            "Epoch 358/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1785 - accuracy: 0.9350\n",
            "Epoch 359/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1683 - accuracy: 0.9396\n",
            "Epoch 360/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1730 - accuracy: 0.9368\n",
            "Epoch 361/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1735 - accuracy: 0.9311\n",
            "Epoch 362/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1761 - accuracy: 0.9350\n",
            "Epoch 363/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1748 - accuracy: 0.9390\n",
            "Epoch 364/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.1670 - accuracy: 0.9396\n",
            "Epoch 365/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1732 - accuracy: 0.9345\n",
            "Epoch 366/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1626 - accuracy: 0.9413\n",
            "Epoch 367/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1637 - accuracy: 0.9430\n",
            "Epoch 368/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1738 - accuracy: 0.9373\n",
            "Epoch 369/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1713 - accuracy: 0.9345\n",
            "Epoch 370/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1670 - accuracy: 0.9362\n",
            "Epoch 371/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1569 - accuracy: 0.9407\n",
            "Epoch 372/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1678 - accuracy: 0.9373\n",
            "Epoch 373/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1570 - accuracy: 0.9430\n",
            "Epoch 374/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1673 - accuracy: 0.9407\n",
            "Epoch 375/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1631 - accuracy: 0.9419\n",
            "Epoch 376/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1622 - accuracy: 0.9419\n",
            "Epoch 377/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1621 - accuracy: 0.9442\n",
            "Epoch 378/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1632 - accuracy: 0.9373\n",
            "Epoch 379/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1633 - accuracy: 0.9407\n",
            "Epoch 380/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1526 - accuracy: 0.9464\n",
            "Epoch 381/400\n",
            "55/55 [==============================] - 6s 106ms/step - loss: 0.1532 - accuracy: 0.9442\n",
            "Epoch 382/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1643 - accuracy: 0.9356\n",
            "Epoch 383/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1694 - accuracy: 0.9447\n",
            "Epoch 384/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1566 - accuracy: 0.9413\n",
            "Epoch 385/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1567 - accuracy: 0.9390\n",
            "Epoch 386/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1548 - accuracy: 0.9459\n",
            "Epoch 387/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1498 - accuracy: 0.9453\n",
            "Epoch 388/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.1630 - accuracy: 0.9413\n",
            "Epoch 389/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1648 - accuracy: 0.9396\n",
            "Epoch 390/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1517 - accuracy: 0.9430\n",
            "Epoch 391/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1566 - accuracy: 0.9430\n",
            "Epoch 392/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1544 - accuracy: 0.9459\n",
            "Epoch 393/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1450 - accuracy: 0.9453\n",
            "Epoch 394/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1503 - accuracy: 0.9447\n",
            "Epoch 395/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1523 - accuracy: 0.9442\n",
            "Epoch 396/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1490 - accuracy: 0.9470\n",
            "Epoch 397/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1466 - accuracy: 0.9487\n",
            "Epoch 398/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1510 - accuracy: 0.9453\n",
            "Epoch 399/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.1467 - accuracy: 0.9419\n",
            "Epoch 400/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1590 - accuracy: 0.9413\n",
            "28/28 [==============================] - 1s 19ms/step - loss: 0.6872 - accuracy: 0.7845\n",
            "Model evaluation  [0.6871576309204102, 0.7844926118850708]\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_6 (Conv1D)           (None, 193, 128)          512       \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 193, 128)          0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 193, 128)          0         \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPooling  (None, 96, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 96, 128)           49280     \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 96, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_7 (MaxPooling  (None, 48, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 48, 128)           0         \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, 48, 128)           49280     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 48, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_8 (MaxPooling  (None, 24, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 24, 128)           0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 12292     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 111,364\n",
            "Trainable params: 111,364\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/400\n",
            "55/55 [==============================] - 6s 78ms/step - loss: 1.7723 - accuracy: 0.3123\n",
            "Epoch 2/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 1.5903 - accuracy: 0.3590\n",
            "Epoch 3/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 1.4235 - accuracy: 0.3886\n",
            "Epoch 4/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 1.3144 - accuracy: 0.4262\n",
            "Epoch 5/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 1.2720 - accuracy: 0.4439\n",
            "Epoch 6/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 1.2116 - accuracy: 0.4621\n",
            "Epoch 7/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 1.1420 - accuracy: 0.4986\n",
            "Epoch 8/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 1.1012 - accuracy: 0.5271\n",
            "Epoch 9/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 1.0828 - accuracy: 0.5271\n",
            "Epoch 10/400\n",
            "55/55 [==============================] - 5s 94ms/step - loss: 1.0435 - accuracy: 0.5459\n",
            "Epoch 11/400\n",
            "55/55 [==============================] - 5s 94ms/step - loss: 1.0112 - accuracy: 0.5726\n",
            "Epoch 12/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.9720 - accuracy: 0.5926\n",
            "Epoch 13/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.9594 - accuracy: 0.5858\n",
            "Epoch 14/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.9293 - accuracy: 0.6108\n",
            "Epoch 15/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.9327 - accuracy: 0.6068\n",
            "Epoch 16/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.8892 - accuracy: 0.6308\n",
            "Epoch 17/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.8619 - accuracy: 0.6490\n",
            "Epoch 18/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.8783 - accuracy: 0.6194\n",
            "Epoch 19/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.8284 - accuracy: 0.6667\n",
            "Epoch 20/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.8420 - accuracy: 0.6439\n",
            "Epoch 21/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.8313 - accuracy: 0.6632\n",
            "Epoch 22/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.8073 - accuracy: 0.6632\n",
            "Epoch 23/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.7999 - accuracy: 0.6809\n",
            "Epoch 24/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.7737 - accuracy: 0.6843\n",
            "Epoch 25/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.7650 - accuracy: 0.6912\n",
            "Epoch 26/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.7571 - accuracy: 0.6929\n",
            "Epoch 27/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.7623 - accuracy: 0.6895\n",
            "Epoch 28/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.7418 - accuracy: 0.7083\n",
            "Epoch 29/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.7359 - accuracy: 0.7060\n",
            "Epoch 30/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.7304 - accuracy: 0.7117\n",
            "Epoch 31/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.7313 - accuracy: 0.7111\n",
            "Epoch 32/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.6935 - accuracy: 0.7248\n",
            "Epoch 33/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.6836 - accuracy: 0.7219\n",
            "Epoch 34/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.6810 - accuracy: 0.7265\n",
            "Epoch 35/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.6668 - accuracy: 0.7311\n",
            "Epoch 36/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.6717 - accuracy: 0.7311\n",
            "Epoch 37/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.6671 - accuracy: 0.7299\n",
            "Epoch 38/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.6762 - accuracy: 0.7128\n",
            "Epoch 39/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.6635 - accuracy: 0.7345\n",
            "Epoch 40/400\n",
            "55/55 [==============================] - 6s 109ms/step - loss: 0.6435 - accuracy: 0.7305\n",
            "Epoch 41/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.6476 - accuracy: 0.7362\n",
            "Epoch 42/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.6396 - accuracy: 0.7459\n",
            "Epoch 43/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.6346 - accuracy: 0.7481\n",
            "Epoch 44/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.6395 - accuracy: 0.7425\n",
            "Epoch 45/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.6136 - accuracy: 0.7476\n",
            "Epoch 46/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.6162 - accuracy: 0.7510\n",
            "Epoch 47/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.6059 - accuracy: 0.7510\n",
            "Epoch 48/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.6182 - accuracy: 0.7476\n",
            "Epoch 49/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.6060 - accuracy: 0.7504\n",
            "Epoch 50/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.6007 - accuracy: 0.7510\n",
            "Epoch 51/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.5945 - accuracy: 0.7516\n",
            "Epoch 52/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.5913 - accuracy: 0.7533\n",
            "Epoch 53/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.5937 - accuracy: 0.7595\n",
            "Epoch 54/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.5990 - accuracy: 0.7550\n",
            "Epoch 55/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.5781 - accuracy: 0.7573\n",
            "Epoch 56/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.5735 - accuracy: 0.7704\n",
            "Epoch 57/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.5733 - accuracy: 0.7675\n",
            "Epoch 58/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.5729 - accuracy: 0.7681\n",
            "Epoch 59/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.5687 - accuracy: 0.7624\n",
            "Epoch 60/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.5673 - accuracy: 0.7675\n",
            "Epoch 61/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.5566 - accuracy: 0.7801\n",
            "Epoch 62/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.5534 - accuracy: 0.7761\n",
            "Epoch 63/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.5562 - accuracy: 0.7630\n",
            "Epoch 64/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.5504 - accuracy: 0.7709\n",
            "Epoch 65/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.5513 - accuracy: 0.7744\n",
            "Epoch 66/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.5517 - accuracy: 0.7704\n",
            "Epoch 67/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.5545 - accuracy: 0.7658\n",
            "Epoch 68/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.5449 - accuracy: 0.7835\n",
            "Epoch 69/400\n",
            "55/55 [==============================] - 5s 97ms/step - loss: 0.5490 - accuracy: 0.7795\n",
            "Epoch 70/400\n",
            "55/55 [==============================] - 5s 89ms/step - loss: 0.5263 - accuracy: 0.7989\n",
            "Epoch 71/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.5463 - accuracy: 0.7709\n",
            "Epoch 72/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.5388 - accuracy: 0.7852\n",
            "Epoch 73/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.5232 - accuracy: 0.7892\n",
            "Epoch 74/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.5247 - accuracy: 0.7863\n",
            "Epoch 75/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.5271 - accuracy: 0.7766\n",
            "Epoch 76/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.5169 - accuracy: 0.7892\n",
            "Epoch 77/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.5126 - accuracy: 0.7926\n",
            "Epoch 78/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.5102 - accuracy: 0.7897\n",
            "Epoch 79/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.5126 - accuracy: 0.7852\n",
            "Epoch 80/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.5134 - accuracy: 0.7852\n",
            "Epoch 81/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.5064 - accuracy: 0.7903\n",
            "Epoch 82/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.5051 - accuracy: 0.7972\n",
            "Epoch 83/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.5055 - accuracy: 0.7903\n",
            "Epoch 84/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.5081 - accuracy: 0.7846\n",
            "Epoch 85/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.4997 - accuracy: 0.7926\n",
            "Epoch 86/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.5046 - accuracy: 0.8028\n",
            "Epoch 87/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4899 - accuracy: 0.7983\n",
            "Epoch 88/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4871 - accuracy: 0.7989\n",
            "Epoch 89/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.4858 - accuracy: 0.7977\n",
            "Epoch 90/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.4765 - accuracy: 0.8051\n",
            "Epoch 91/400\n",
            "55/55 [==============================] - 4s 72ms/step - loss: 0.4819 - accuracy: 0.7966\n",
            "Epoch 92/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.4801 - accuracy: 0.7983\n",
            "Epoch 93/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.4792 - accuracy: 0.8000\n",
            "Epoch 94/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.4692 - accuracy: 0.8108\n",
            "Epoch 95/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.4682 - accuracy: 0.8085\n",
            "Epoch 96/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4825 - accuracy: 0.8006\n",
            "Epoch 97/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.4655 - accuracy: 0.8034\n",
            "Epoch 98/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.4777 - accuracy: 0.7960\n",
            "Epoch 99/400\n",
            "55/55 [==============================] - 6s 110ms/step - loss: 0.4651 - accuracy: 0.8171\n",
            "Epoch 100/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.4748 - accuracy: 0.8051\n",
            "Epoch 101/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.4570 - accuracy: 0.8154\n",
            "Epoch 102/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.4608 - accuracy: 0.8091\n",
            "Epoch 103/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.4693 - accuracy: 0.8097\n",
            "Epoch 104/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.4530 - accuracy: 0.8165\n",
            "Epoch 105/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.4538 - accuracy: 0.8120\n",
            "Epoch 106/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.4586 - accuracy: 0.8154\n",
            "Epoch 107/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4506 - accuracy: 0.8182\n",
            "Epoch 108/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.4462 - accuracy: 0.8142\n",
            "Epoch 109/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.4468 - accuracy: 0.8108\n",
            "Epoch 110/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4445 - accuracy: 0.8211\n",
            "Epoch 111/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.4340 - accuracy: 0.8165\n",
            "Epoch 112/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4404 - accuracy: 0.8222\n",
            "Epoch 113/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.4474 - accuracy: 0.8211\n",
            "Epoch 114/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.4347 - accuracy: 0.8217\n",
            "Epoch 115/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.4323 - accuracy: 0.8160\n",
            "Epoch 116/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.4335 - accuracy: 0.8239\n",
            "Epoch 117/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.4432 - accuracy: 0.8199\n",
            "Epoch 118/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.4189 - accuracy: 0.8285\n",
            "Epoch 119/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.4222 - accuracy: 0.8234\n",
            "Epoch 120/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.4272 - accuracy: 0.8194\n",
            "Epoch 121/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.4119 - accuracy: 0.8348\n",
            "Epoch 122/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.4101 - accuracy: 0.8359\n",
            "Epoch 123/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.4158 - accuracy: 0.8268\n",
            "Epoch 124/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.4169 - accuracy: 0.8279\n",
            "Epoch 125/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.4259 - accuracy: 0.8268\n",
            "Epoch 126/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.4275 - accuracy: 0.8239\n",
            "Epoch 127/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.4169 - accuracy: 0.8302\n",
            "Epoch 128/400\n",
            "55/55 [==============================] - 6s 102ms/step - loss: 0.4228 - accuracy: 0.8262\n",
            "Epoch 129/400\n",
            "55/55 [==============================] - 5s 83ms/step - loss: 0.3989 - accuracy: 0.8313\n",
            "Epoch 130/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.4157 - accuracy: 0.8313\n",
            "Epoch 131/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.4016 - accuracy: 0.8353\n",
            "Epoch 132/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4160 - accuracy: 0.8279\n",
            "Epoch 133/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.3965 - accuracy: 0.8456\n",
            "Epoch 134/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3949 - accuracy: 0.8359\n",
            "Epoch 135/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.3905 - accuracy: 0.8353\n",
            "Epoch 136/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.4079 - accuracy: 0.8308\n",
            "Epoch 137/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3941 - accuracy: 0.8439\n",
            "Epoch 138/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3984 - accuracy: 0.8387\n",
            "Epoch 139/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3967 - accuracy: 0.8410\n",
            "Epoch 140/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.3985 - accuracy: 0.8348\n",
            "Epoch 141/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3870 - accuracy: 0.8376\n",
            "Epoch 142/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3967 - accuracy: 0.8336\n",
            "Epoch 143/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3810 - accuracy: 0.8433\n",
            "Epoch 144/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3849 - accuracy: 0.8365\n",
            "Epoch 145/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3890 - accuracy: 0.8416\n",
            "Epoch 146/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3788 - accuracy: 0.8490\n",
            "Epoch 147/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3825 - accuracy: 0.8422\n",
            "Epoch 148/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3816 - accuracy: 0.8416\n",
            "Epoch 149/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3784 - accuracy: 0.8473\n",
            "Epoch 150/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3737 - accuracy: 0.8496\n",
            "Epoch 151/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3645 - accuracy: 0.8507\n",
            "Epoch 152/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3819 - accuracy: 0.8439\n",
            "Epoch 153/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.3734 - accuracy: 0.8496\n",
            "Epoch 154/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3629 - accuracy: 0.8496\n",
            "Epoch 155/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3694 - accuracy: 0.8524\n",
            "Epoch 156/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3679 - accuracy: 0.8496\n",
            "Epoch 157/400\n",
            "55/55 [==============================] - 5s 90ms/step - loss: 0.3795 - accuracy: 0.8393\n",
            "Epoch 158/400\n",
            "55/55 [==============================] - 5s 99ms/step - loss: 0.3672 - accuracy: 0.8519\n",
            "Epoch 159/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3612 - accuracy: 0.8450\n",
            "Epoch 160/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3580 - accuracy: 0.8564\n",
            "Epoch 161/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.3586 - accuracy: 0.8490\n",
            "Epoch 162/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.3569 - accuracy: 0.8473\n",
            "Epoch 163/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3687 - accuracy: 0.8575\n",
            "Epoch 164/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3641 - accuracy: 0.8530\n",
            "Epoch 165/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3587 - accuracy: 0.8513\n",
            "Epoch 166/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.3605 - accuracy: 0.8564\n",
            "Epoch 167/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3533 - accuracy: 0.8530\n",
            "Epoch 168/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3467 - accuracy: 0.8536\n",
            "Epoch 169/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3493 - accuracy: 0.8598\n",
            "Epoch 170/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3487 - accuracy: 0.8524\n",
            "Epoch 171/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3517 - accuracy: 0.8524\n",
            "Epoch 172/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3475 - accuracy: 0.8524\n",
            "Epoch 173/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3607 - accuracy: 0.8496\n",
            "Epoch 174/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3395 - accuracy: 0.8724\n",
            "Epoch 175/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3484 - accuracy: 0.8604\n",
            "Epoch 176/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3438 - accuracy: 0.8581\n",
            "Epoch 177/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3330 - accuracy: 0.8621\n",
            "Epoch 178/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3327 - accuracy: 0.8644\n",
            "Epoch 179/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3509 - accuracy: 0.8519\n",
            "Epoch 180/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3293 - accuracy: 0.8707\n",
            "Epoch 181/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3368 - accuracy: 0.8672\n",
            "Epoch 182/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3279 - accuracy: 0.8678\n",
            "Epoch 183/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3318 - accuracy: 0.8627\n",
            "Epoch 184/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3271 - accuracy: 0.8724\n",
            "Epoch 185/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3292 - accuracy: 0.8627\n",
            "Epoch 186/400\n",
            "55/55 [==============================] - 5s 91ms/step - loss: 0.3427 - accuracy: 0.8678\n",
            "Epoch 187/400\n",
            "55/55 [==============================] - 5s 96ms/step - loss: 0.3282 - accuracy: 0.8610\n",
            "Epoch 188/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3203 - accuracy: 0.8684\n",
            "Epoch 189/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3336 - accuracy: 0.8621\n",
            "Epoch 190/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3191 - accuracy: 0.8678\n",
            "Epoch 191/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3244 - accuracy: 0.8678\n",
            "Epoch 192/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3113 - accuracy: 0.8860\n",
            "Epoch 193/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3165 - accuracy: 0.8661\n",
            "Epoch 194/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3127 - accuracy: 0.8735\n",
            "Epoch 195/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2995 - accuracy: 0.8900\n",
            "Epoch 196/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.3116 - accuracy: 0.8718\n",
            "Epoch 197/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3219 - accuracy: 0.8769\n",
            "Epoch 198/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3025 - accuracy: 0.8866\n",
            "Epoch 199/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3093 - accuracy: 0.8764\n",
            "Epoch 200/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3176 - accuracy: 0.8707\n",
            "Epoch 201/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3070 - accuracy: 0.8724\n",
            "Epoch 202/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2967 - accuracy: 0.8809\n",
            "Epoch 203/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3099 - accuracy: 0.8786\n",
            "Epoch 204/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3020 - accuracy: 0.8860\n",
            "Epoch 205/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3024 - accuracy: 0.8741\n",
            "Epoch 206/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3112 - accuracy: 0.8758\n",
            "Epoch 207/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3086 - accuracy: 0.8701\n",
            "Epoch 208/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3015 - accuracy: 0.8815\n",
            "Epoch 209/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.3088 - accuracy: 0.8746\n",
            "Epoch 210/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.3114 - accuracy: 0.8689\n",
            "Epoch 211/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2906 - accuracy: 0.8826\n",
            "Epoch 212/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2925 - accuracy: 0.8826\n",
            "Epoch 213/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2863 - accuracy: 0.8866\n",
            "Epoch 214/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2920 - accuracy: 0.8877\n",
            "Epoch 215/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.3014 - accuracy: 0.8786\n",
            "Epoch 216/400\n",
            "55/55 [==============================] - 6s 110ms/step - loss: 0.2902 - accuracy: 0.8838\n",
            "Epoch 217/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.2916 - accuracy: 0.8838\n",
            "Epoch 218/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2953 - accuracy: 0.8758\n",
            "Epoch 219/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2792 - accuracy: 0.8900\n",
            "Epoch 220/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.2948 - accuracy: 0.8889\n",
            "Epoch 221/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2898 - accuracy: 0.8826\n",
            "Epoch 222/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2857 - accuracy: 0.8877\n",
            "Epoch 223/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2831 - accuracy: 0.8957\n",
            "Epoch 224/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2814 - accuracy: 0.8906\n",
            "Epoch 225/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2856 - accuracy: 0.8929\n",
            "Epoch 226/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2877 - accuracy: 0.8912\n",
            "Epoch 227/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2665 - accuracy: 0.8969\n",
            "Epoch 228/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2809 - accuracy: 0.8877\n",
            "Epoch 229/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2930 - accuracy: 0.8838\n",
            "Epoch 230/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2750 - accuracy: 0.8860\n",
            "Epoch 231/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2768 - accuracy: 0.8917\n",
            "Epoch 232/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2754 - accuracy: 0.8974\n",
            "Epoch 233/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.2602 - accuracy: 0.8997\n",
            "Epoch 234/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2806 - accuracy: 0.8877\n",
            "Epoch 235/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2682 - accuracy: 0.8895\n",
            "Epoch 236/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2689 - accuracy: 0.8906\n",
            "Epoch 237/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.2691 - accuracy: 0.9014\n",
            "Epoch 238/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2742 - accuracy: 0.8798\n",
            "Epoch 239/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2737 - accuracy: 0.8860\n",
            "Epoch 240/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2705 - accuracy: 0.8906\n",
            "Epoch 241/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2740 - accuracy: 0.8917\n",
            "Epoch 242/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2714 - accuracy: 0.8974\n",
            "Epoch 243/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2737 - accuracy: 0.8969\n",
            "Epoch 244/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2628 - accuracy: 0.9020\n",
            "Epoch 245/400\n",
            "55/55 [==============================] - 6s 110ms/step - loss: 0.2636 - accuracy: 0.8895\n",
            "Epoch 246/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2673 - accuracy: 0.8917\n",
            "Epoch 247/400\n",
            "55/55 [==============================] - 4s 73ms/step - loss: 0.2535 - accuracy: 0.8980\n",
            "Epoch 248/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.2597 - accuracy: 0.8997\n",
            "Epoch 249/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.2556 - accuracy: 0.8957\n",
            "Epoch 250/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.2584 - accuracy: 0.9060\n",
            "Epoch 251/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2631 - accuracy: 0.8969\n",
            "Epoch 252/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2568 - accuracy: 0.9031\n",
            "Epoch 253/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2544 - accuracy: 0.9003\n",
            "Epoch 254/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2538 - accuracy: 0.9060\n",
            "Epoch 255/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2611 - accuracy: 0.8940\n",
            "Epoch 256/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2548 - accuracy: 0.9026\n",
            "Epoch 257/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.2489 - accuracy: 0.9026\n",
            "Epoch 258/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2581 - accuracy: 0.9071\n",
            "Epoch 259/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2596 - accuracy: 0.8997\n",
            "Epoch 260/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.2558 - accuracy: 0.8963\n",
            "Epoch 261/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2386 - accuracy: 0.9048\n",
            "Epoch 262/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2524 - accuracy: 0.8991\n",
            "Epoch 263/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2422 - accuracy: 0.9100\n",
            "Epoch 264/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2512 - accuracy: 0.9020\n",
            "Epoch 265/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2527 - accuracy: 0.9009\n",
            "Epoch 266/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2493 - accuracy: 0.9066\n",
            "Epoch 267/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2278 - accuracy: 0.9168\n",
            "Epoch 268/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2481 - accuracy: 0.9009\n",
            "Epoch 269/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.2474 - accuracy: 0.9043\n",
            "Epoch 270/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2322 - accuracy: 0.9128\n",
            "Epoch 271/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.2409 - accuracy: 0.9071\n",
            "Epoch 272/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.2315 - accuracy: 0.9100\n",
            "Epoch 273/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.2412 - accuracy: 0.9100\n",
            "Epoch 274/400\n",
            "55/55 [==============================] - 6s 104ms/step - loss: 0.2319 - accuracy: 0.9105\n",
            "Epoch 275/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2260 - accuracy: 0.9071\n",
            "Epoch 276/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.2332 - accuracy: 0.9151\n",
            "Epoch 277/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2298 - accuracy: 0.9140\n",
            "Epoch 278/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2371 - accuracy: 0.9026\n",
            "Epoch 279/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.2325 - accuracy: 0.9060\n",
            "Epoch 280/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.2414 - accuracy: 0.9014\n",
            "Epoch 281/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2461 - accuracy: 0.9066\n",
            "Epoch 282/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2371 - accuracy: 0.9066\n",
            "Epoch 283/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.2310 - accuracy: 0.9105\n",
            "Epoch 284/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2324 - accuracy: 0.9111\n",
            "Epoch 285/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2250 - accuracy: 0.9128\n",
            "Epoch 286/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2234 - accuracy: 0.9094\n",
            "Epoch 287/400\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.2280 - accuracy: 0.9134\n",
            "Epoch 288/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2187 - accuracy: 0.9185\n",
            "Epoch 289/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2277 - accuracy: 0.9071\n",
            "Epoch 290/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.2197 - accuracy: 0.9179\n",
            "Epoch 291/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2289 - accuracy: 0.9048\n",
            "Epoch 292/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2144 - accuracy: 0.9242\n",
            "Epoch 293/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2217 - accuracy: 0.9134\n",
            "Epoch 294/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2232 - accuracy: 0.9111\n",
            "Epoch 295/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.2196 - accuracy: 0.9219\n",
            "Epoch 296/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2212 - accuracy: 0.9157\n",
            "Epoch 297/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2085 - accuracy: 0.9225\n",
            "Epoch 298/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2174 - accuracy: 0.9134\n",
            "Epoch 299/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.2124 - accuracy: 0.9214\n",
            "Epoch 300/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2122 - accuracy: 0.9191\n",
            "Epoch 301/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2187 - accuracy: 0.9157\n",
            "Epoch 302/400\n",
            "55/55 [==============================] - 5s 97ms/step - loss: 0.2212 - accuracy: 0.9191\n",
            "Epoch 303/400\n",
            "55/55 [==============================] - 5s 90ms/step - loss: 0.2096 - accuracy: 0.9197\n",
            "Epoch 304/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.2098 - accuracy: 0.9191\n",
            "Epoch 305/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2226 - accuracy: 0.9105\n",
            "Epoch 306/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2116 - accuracy: 0.9197\n",
            "Epoch 307/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2156 - accuracy: 0.9140\n",
            "Epoch 308/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2199 - accuracy: 0.9105\n",
            "Epoch 309/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.2011 - accuracy: 0.9276\n",
            "Epoch 310/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2062 - accuracy: 0.9231\n",
            "Epoch 311/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2107 - accuracy: 0.9157\n",
            "Epoch 312/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.2070 - accuracy: 0.9202\n",
            "Epoch 313/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1997 - accuracy: 0.9225\n",
            "Epoch 314/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.2100 - accuracy: 0.9174\n",
            "Epoch 315/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.2069 - accuracy: 0.9259\n",
            "Epoch 316/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.2047 - accuracy: 0.9208\n",
            "Epoch 317/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2010 - accuracy: 0.9254\n",
            "Epoch 318/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.2069 - accuracy: 0.9197\n",
            "Epoch 319/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1934 - accuracy: 0.9282\n",
            "Epoch 320/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1991 - accuracy: 0.9276\n",
            "Epoch 321/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.2009 - accuracy: 0.9231\n",
            "Epoch 322/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1945 - accuracy: 0.9254\n",
            "Epoch 323/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1997 - accuracy: 0.9299\n",
            "Epoch 324/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1984 - accuracy: 0.9168\n",
            "Epoch 325/400\n",
            "55/55 [==============================] - 4s 74ms/step - loss: 0.2072 - accuracy: 0.9145\n",
            "Epoch 326/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1974 - accuracy: 0.9248\n",
            "Epoch 327/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1921 - accuracy: 0.9236\n",
            "Epoch 328/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1958 - accuracy: 0.9248\n",
            "Epoch 329/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1958 - accuracy: 0.9282\n",
            "Epoch 330/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1865 - accuracy: 0.9293\n",
            "Epoch 331/400\n",
            "55/55 [==============================] - 5s 83ms/step - loss: 0.1872 - accuracy: 0.9316\n",
            "Epoch 332/400\n",
            "55/55 [==============================] - 6s 107ms/step - loss: 0.1942 - accuracy: 0.9197\n",
            "Epoch 333/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1897 - accuracy: 0.9305\n",
            "Epoch 334/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1866 - accuracy: 0.9248\n",
            "Epoch 335/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1901 - accuracy: 0.9305\n",
            "Epoch 336/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1844 - accuracy: 0.9293\n",
            "Epoch 337/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.1997 - accuracy: 0.9225\n",
            "Epoch 338/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1905 - accuracy: 0.9299\n",
            "Epoch 339/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1956 - accuracy: 0.9231\n",
            "Epoch 340/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1843 - accuracy: 0.9311\n",
            "Epoch 341/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1849 - accuracy: 0.9225\n",
            "Epoch 342/400\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.1863 - accuracy: 0.9305\n",
            "Epoch 343/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1897 - accuracy: 0.9248\n",
            "Epoch 344/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.1848 - accuracy: 0.9328\n",
            "Epoch 345/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1941 - accuracy: 0.9271\n",
            "Epoch 346/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1982 - accuracy: 0.9236\n",
            "Epoch 347/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1841 - accuracy: 0.9293\n",
            "Epoch 348/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1892 - accuracy: 0.9259\n",
            "Epoch 349/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1837 - accuracy: 0.9356\n",
            "Epoch 350/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1841 - accuracy: 0.9345\n",
            "Epoch 351/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1846 - accuracy: 0.9288\n",
            "Epoch 352/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1794 - accuracy: 0.9368\n",
            "Epoch 353/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.1787 - accuracy: 0.9316\n",
            "Epoch 354/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1858 - accuracy: 0.9299\n",
            "Epoch 355/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.1780 - accuracy: 0.9299\n",
            "Epoch 356/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1796 - accuracy: 0.9345\n",
            "Epoch 357/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1801 - accuracy: 0.9328\n",
            "Epoch 358/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1799 - accuracy: 0.9356\n",
            "Epoch 359/400\n",
            "55/55 [==============================] - 6s 102ms/step - loss: 0.1813 - accuracy: 0.9328\n",
            "Epoch 360/400\n",
            "55/55 [==============================] - 5s 92ms/step - loss: 0.1742 - accuracy: 0.9345\n",
            "Epoch 361/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.1706 - accuracy: 0.9379\n",
            "Epoch 362/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1637 - accuracy: 0.9368\n",
            "Epoch 363/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1644 - accuracy: 0.9299\n",
            "Epoch 364/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1698 - accuracy: 0.9333\n",
            "Epoch 365/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1746 - accuracy: 0.9379\n",
            "Epoch 366/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1695 - accuracy: 0.9350\n",
            "Epoch 367/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1750 - accuracy: 0.9333\n",
            "Epoch 368/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1615 - accuracy: 0.9402\n",
            "Epoch 369/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1566 - accuracy: 0.9419\n",
            "Epoch 370/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1608 - accuracy: 0.9430\n",
            "Epoch 371/400\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.1722 - accuracy: 0.9356\n",
            "Epoch 372/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1696 - accuracy: 0.9385\n",
            "Epoch 373/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1705 - accuracy: 0.9350\n",
            "Epoch 374/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.1622 - accuracy: 0.9345\n",
            "Epoch 375/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1711 - accuracy: 0.9373\n",
            "Epoch 376/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1640 - accuracy: 0.9430\n",
            "Epoch 377/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1772 - accuracy: 0.9339\n",
            "Epoch 378/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1651 - accuracy: 0.9362\n",
            "Epoch 379/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1700 - accuracy: 0.9339\n",
            "Epoch 380/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1601 - accuracy: 0.9453\n",
            "Epoch 381/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.1626 - accuracy: 0.9390\n",
            "Epoch 382/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1552 - accuracy: 0.9425\n",
            "Epoch 383/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1674 - accuracy: 0.9402\n",
            "Epoch 384/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1593 - accuracy: 0.9385\n",
            "Epoch 385/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.1540 - accuracy: 0.9447\n",
            "Epoch 386/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1554 - accuracy: 0.9442\n",
            "Epoch 387/400\n",
            "55/55 [==============================] - 6s 114ms/step - loss: 0.1542 - accuracy: 0.9487\n",
            "Epoch 388/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.1639 - accuracy: 0.9470\n",
            "Epoch 389/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1588 - accuracy: 0.9436\n",
            "Epoch 390/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1585 - accuracy: 0.9373\n",
            "Epoch 391/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1513 - accuracy: 0.9459\n",
            "Epoch 392/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1692 - accuracy: 0.9356\n",
            "Epoch 393/400\n",
            "55/55 [==============================] - 4s 80ms/step - loss: 0.1670 - accuracy: 0.9390\n",
            "Epoch 394/400\n",
            "55/55 [==============================] - 5s 82ms/step - loss: 0.1518 - accuracy: 0.9499\n",
            "Epoch 395/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1621 - accuracy: 0.9402\n",
            "Epoch 396/400\n",
            "55/55 [==============================] - 4s 79ms/step - loss: 0.1579 - accuracy: 0.9413\n",
            "Epoch 397/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1501 - accuracy: 0.9407\n",
            "Epoch 398/400\n",
            "55/55 [==============================] - 4s 78ms/step - loss: 0.1539 - accuracy: 0.9442\n",
            "Epoch 399/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.1505 - accuracy: 0.9470\n",
            "Epoch 400/400\n",
            "55/55 [==============================] - 4s 81ms/step - loss: 0.1565 - accuracy: 0.9402\n",
            "28/28 [==============================] - 1s 20ms/step - loss: 0.6217 - accuracy: 0.8084\n",
            "Model evaluation  [0.6216966509819031, 0.8084378838539124]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UBNbmAZRMbxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scg0DQ8Wj7tR",
        "outputId": "a5bebc40-9d62-4e47-85a7-3b5d96773110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(193, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/SER\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL8bZuH6MCGt",
        "outputId": "3555d9c7-d277-415e-fe7f-58fb2c9a4c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/SER/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_erli = np.expand_dims(X_erli, axis=2)\n",
        "\n",
        "loss, acc = model.evaluate(X_erli, y_erli)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ekzx8StOY9xt",
        "outputId": "5a5f8884-0043-4fd0-db05-df6e46d39149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 1s 31ms/step - loss: 29.8130 - accuracy: 0.6000\n",
            "Accuracy: 60.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "n_split=3\n",
        "\n",
        "for train_index,test_index in KFold(n_split).split(X):\n",
        "  x_train,x_test=X[train_index],X[test_index]\n",
        "  y_train,y_test=y[train_index],y[test_index]\n",
        "  \n",
        "\n",
        "\n",
        "  mlp = MLPClassifier(hidden_layer_sizes=(400,),random_state=50,batch_size=200,\n",
        "                      max_iter=1000,epsilon=1e-08,learning_rate='adaptive')\n",
        "      \n",
        "  mlp.fit(x_train,y_train)\n",
        "  print('Predictios' )\n",
        "  mlp_pred = mlp.predict(x_test)\n",
        "  mlp.score(x_test,y_test)\n",
        "  print(accuracy_score(y_true=y_test,y_pred=mlp_pred))\n",
        "  print(classification_report(y_test,mlp_pred)) \n",
        "  print(confusion_matrix(y_test, mlp_pred) )\n",
        "\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ukCM60OoO8A",
        "outputId": "f0dce324-eaff-4bdf-b65f-316458c5751d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictios\n",
            "0.7665148063781321\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.84       270\n",
            "           1       0.71      0.76      0.74       240\n",
            "           2       0.85      0.55      0.66       130\n",
            "           3       0.74      0.78      0.76       238\n",
            "\n",
            "    accuracy                           0.77       878\n",
            "   macro avg       0.78      0.74      0.75       878\n",
            "weighted avg       0.77      0.77      0.76       878\n",
            "\n",
            "[[233  29   1   7]\n",
            " [ 32 183   5  20]\n",
            " [  6  16  71  37]\n",
            " [ 16  29   7 186]]\n",
            "Predictios\n",
            "0.7730900798175598\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.82      0.82       240\n",
            "           1       0.94      0.65      0.77       268\n",
            "           2       0.65      0.78      0.71       134\n",
            "           3       0.69      0.87      0.77       235\n",
            "\n",
            "    accuracy                           0.77       877\n",
            "   macro avg       0.78      0.78      0.77       877\n",
            "weighted avg       0.80      0.77      0.77       877\n",
            "\n",
            "[[196  11  11  22]\n",
            " [ 31 174  21  42]\n",
            " [  3   0 104  27]\n",
            " [  7   1  23 204]]\n",
            "Predictios\n",
            "0.814139110604333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.86      0.87       242\n",
            "           1       0.90      0.77      0.83       244\n",
            "           2       0.67      0.62      0.64       112\n",
            "           3       0.75      0.90      0.82       279\n",
            "\n",
            "    accuracy                           0.81       877\n",
            "   macro avg       0.80      0.78      0.79       877\n",
            "weighted avg       0.82      0.81      0.81       877\n",
            "\n",
            "[[207  10   6  19]\n",
            " [ 20 188  11  25]\n",
            " [  0   4  69  39]\n",
            " [  5   7  17 250]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_pred = mlp.predict(X_erli)\n",
        "mlp.score(X_erli,y_erli)\n",
        "print(accuracy_score(y_true=y_erli,y_pred=mlp_pred))\n",
        "print(classification_report(y_erli,mlp_pred)) \n",
        "print(confusion_matrix(y_erli, mlp_pred) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_V8sDlApmjU",
        "outputId": "253cfc28-3b98-4cff-f5ac-0cfd71824949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5642857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.86      0.72       127\n",
            "           1       0.41      0.34      0.37        71\n",
            "           2       0.26      0.13      0.17        79\n",
            "           3       0.64      0.66      0.65       143\n",
            "\n",
            "    accuracy                           0.56       420\n",
            "   macro avg       0.48      0.50      0.48       420\n",
            "weighted avg       0.52      0.56      0.53       420\n",
            "\n",
            "[[109  18   0   0]\n",
            " [ 45  24   0   2]\n",
            " [  9   8  10  52]\n",
            " [ 11   9  29  94]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "n_split=3\n",
        "\n",
        "for train_index,test_index in KFold(n_split).split(X):\n",
        "  x_train,x_test=X[train_index],X[test_index]\n",
        "  y_train,y_test=y[train_index],y[test_index]\n",
        "  \n",
        "\n",
        "\n",
        "  rfc = RandomForestClassifier(n_estimators=300,max_features='sqrt',random_state=25)\n",
        "  rfc.fit(x_train,y_train)\n",
        "\n",
        "  rfc_predict = rfc.predict(x_test)\n",
        "\n",
        "  print(accuracy_score(y_true=y_test,y_pred=rfc_predict))\n",
        "  print(classification_report(y_test,rfc_predict)) \n",
        "  # creating a confusion matrix \n",
        "  print(confusion_matrix(y_test, rfc_predict) )\n",
        "\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvhUQFkyrOH-",
        "outputId": "674e1717-280f-4f3b-c725-1bc64db97d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7744874715261959\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.83      0.86       270\n",
            "           1       0.72      0.75      0.73       240\n",
            "           2       0.85      0.62      0.72       130\n",
            "           3       0.69      0.83      0.75       238\n",
            "\n",
            "    accuracy                           0.77       878\n",
            "   macro avg       0.79      0.76      0.77       878\n",
            "weighted avg       0.79      0.77      0.78       878\n",
            "\n",
            "[[223  34   1  12]\n",
            " [ 19 179   5  37]\n",
            " [  0   9  81  40]\n",
            " [  6  27   8 197]]\n",
            "0.7616875712656784\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.77      0.79       240\n",
            "           1       0.81      0.72      0.77       268\n",
            "           2       0.90      0.69      0.78       134\n",
            "           3       0.64      0.83      0.72       235\n",
            "\n",
            "    accuracy                           0.76       877\n",
            "   macro avg       0.79      0.76      0.77       877\n",
            "weighted avg       0.78      0.76      0.76       877\n",
            "\n",
            "[[185  19   4  32]\n",
            " [ 32 194   1  41]\n",
            " [  0   4  93  37]\n",
            " [ 12  22   5 196]]\n",
            "0.7628278221208666\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.80      0.80       242\n",
            "           1       0.73      0.80      0.76       244\n",
            "           2       0.85      0.54      0.66       112\n",
            "           3       0.75      0.78      0.77       279\n",
            "\n",
            "    accuracy                           0.76       877\n",
            "   macro avg       0.78      0.73      0.75       877\n",
            "weighted avg       0.77      0.76      0.76       877\n",
            "\n",
            "[[194  31   2  15]\n",
            " [ 28 195   4  17]\n",
            " [  1   9  61  41]\n",
            " [ 22  33   5 219]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc_predict = rfc.predict(X_erli)\n",
        "\n",
        "print(accuracy_score(y_true=y_erli,y_pred=rfc_predict))\n",
        "print(classification_report(y_erli,rfc_predict)) \n",
        "# creating a confusion matrix \n",
        "print(confusion_matrix(y_erli, rfc_predict) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXU3Xtrsrh4b",
        "outputId": "f6af1222-9265-41cb-a87d-7ce55ffc81de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3047619047619048\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.99      0.49       127\n",
            "           1       0.06      0.03      0.04        71\n",
            "           2       0.00      0.00      0.00        79\n",
            "           3       0.00      0.00      0.00       143\n",
            "\n",
            "    accuracy                           0.30       420\n",
            "   macro avg       0.10      0.26      0.13       420\n",
            "weighted avg       0.11      0.30      0.15       420\n",
            "\n",
            "[[126   1   0   0]\n",
            " [ 69   2   0   0]\n",
            " [ 68  11   0   0]\n",
            " [123  20   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_model = keras.models.load_model(\"/content/drive/MyDrive/SER\")"
      ],
      "metadata": {
        "id": "XjxQEuWVARK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('dataset7.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "MZRAhT5oAtrO",
        "outputId": "af55227e-384d-4714-e3db-1d71db9bddd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0           0          1          2          3         4  \\\n",
              "0           0 -524.339844  58.945076  11.774967  26.318909  0.261554   \n",
              "1           1 -269.140574  11.484386   8.767346   6.243472  2.747863   \n",
              "2           2 -366.166321  61.372746 -14.820083  21.295778 -8.899424   \n",
              "3           3 -231.392576  29.672213   1.565719   5.466136 -4.319672   \n",
              "4           4 -536.010803  69.903397 -16.303288  32.916740  2.925880   \n",
              "\n",
              "          5          6         7          8  ...       184       185  \\\n",
              "0  5.660612  -3.377984 -3.362769  -9.245324  ... -0.000091  0.007732   \n",
              "1  0.709594  -0.614465 -1.588504  -3.817834  ... -0.000729  0.002335   \n",
              "2 -7.860835  -2.845897 -0.053523 -10.914480  ... -0.030637 -0.010813   \n",
              "3 -7.645862  -0.795612  0.830001  -6.118091  ... -0.032956  0.001459   \n",
              "4  0.171463 -12.861864 -5.886380 -12.273261  ... -0.007125 -0.016768   \n",
              "\n",
              "         186        187        188        189        190        191  \\\n",
              "0  21.961529  15.875564  19.082055  14.696499  16.397359  16.391151   \n",
              "1  15.468811  13.326386  14.867802  12.761607  13.529643  13.522223   \n",
              "2  22.978009  17.598611  20.942201  18.762070  18.259227  17.844183   \n",
              "3  17.083159  15.874668  18.546013  16.412194  15.331840  14.713892   \n",
              "4  23.791126  19.190114  20.781159  18.825651  19.712703  20.324445   \n",
              "\n",
              "         192   labels  \n",
              "0  29.530816  disgust  \n",
              "1  13.355271  disgust  \n",
              "2  30.877108    angry  \n",
              "3  13.618339    angry  \n",
              "4  29.268788  neutral  \n",
              "\n",
              "[5 rows x 195 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67cdfb03-b4b1-4c3a-a1ca-cf3e91e0a79a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-524.339844</td>\n",
              "      <td>58.945076</td>\n",
              "      <td>11.774967</td>\n",
              "      <td>26.318909</td>\n",
              "      <td>0.261554</td>\n",
              "      <td>5.660612</td>\n",
              "      <td>-3.377984</td>\n",
              "      <td>-3.362769</td>\n",
              "      <td>-9.245324</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000091</td>\n",
              "      <td>0.007732</td>\n",
              "      <td>21.961529</td>\n",
              "      <td>15.875564</td>\n",
              "      <td>19.082055</td>\n",
              "      <td>14.696499</td>\n",
              "      <td>16.397359</td>\n",
              "      <td>16.391151</td>\n",
              "      <td>29.530816</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-269.140574</td>\n",
              "      <td>11.484386</td>\n",
              "      <td>8.767346</td>\n",
              "      <td>6.243472</td>\n",
              "      <td>2.747863</td>\n",
              "      <td>0.709594</td>\n",
              "      <td>-0.614465</td>\n",
              "      <td>-1.588504</td>\n",
              "      <td>-3.817834</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000729</td>\n",
              "      <td>0.002335</td>\n",
              "      <td>15.468811</td>\n",
              "      <td>13.326386</td>\n",
              "      <td>14.867802</td>\n",
              "      <td>12.761607</td>\n",
              "      <td>13.529643</td>\n",
              "      <td>13.522223</td>\n",
              "      <td>13.355271</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-366.166321</td>\n",
              "      <td>61.372746</td>\n",
              "      <td>-14.820083</td>\n",
              "      <td>21.295778</td>\n",
              "      <td>-8.899424</td>\n",
              "      <td>-7.860835</td>\n",
              "      <td>-2.845897</td>\n",
              "      <td>-0.053523</td>\n",
              "      <td>-10.914480</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.030637</td>\n",
              "      <td>-0.010813</td>\n",
              "      <td>22.978009</td>\n",
              "      <td>17.598611</td>\n",
              "      <td>20.942201</td>\n",
              "      <td>18.762070</td>\n",
              "      <td>18.259227</td>\n",
              "      <td>17.844183</td>\n",
              "      <td>30.877108</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-231.392576</td>\n",
              "      <td>29.672213</td>\n",
              "      <td>1.565719</td>\n",
              "      <td>5.466136</td>\n",
              "      <td>-4.319672</td>\n",
              "      <td>-7.645862</td>\n",
              "      <td>-0.795612</td>\n",
              "      <td>0.830001</td>\n",
              "      <td>-6.118091</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.032956</td>\n",
              "      <td>0.001459</td>\n",
              "      <td>17.083159</td>\n",
              "      <td>15.874668</td>\n",
              "      <td>18.546013</td>\n",
              "      <td>16.412194</td>\n",
              "      <td>15.331840</td>\n",
              "      <td>14.713892</td>\n",
              "      <td>13.618339</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-536.010803</td>\n",
              "      <td>69.903397</td>\n",
              "      <td>-16.303288</td>\n",
              "      <td>32.916740</td>\n",
              "      <td>2.925880</td>\n",
              "      <td>0.171463</td>\n",
              "      <td>-12.861864</td>\n",
              "      <td>-5.886380</td>\n",
              "      <td>-12.273261</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007125</td>\n",
              "      <td>-0.016768</td>\n",
              "      <td>23.791126</td>\n",
              "      <td>19.190114</td>\n",
              "      <td>20.781159</td>\n",
              "      <td>18.825651</td>\n",
              "      <td>19.712703</td>\n",
              "      <td>20.324445</td>\n",
              "      <td>29.268788</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 195 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67cdfb03-b4b1-4c3a-a1ca-cf3e91e0a79a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67cdfb03-b4b1-4c3a-a1ca-cf3e91e0a79a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67cdfb03-b4b1-4c3a-a1ca-cf3e91e0a79a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.loc[data['labels'].isin(['angry', 'sad' , 'neutral' , 'happy'])]\n",
        "#angry = 0, neutral=2 happy=1 , sad = 3\n",
        "X = data.iloc[:,1:-1].values\n",
        "y = data.iloc[:,-1].values\n",
        "print(y)\n",
        "'''\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n",
        "print(y)'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "dBz86IPaBGri",
        "outputId": "e202ccb9-2b82-41a7-a65f-764cf7dee02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['angry' 'angry' 'neutral' ... 'angry' 'angry' 'angry']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.preprocessing import LabelEncoder\\nencoder = LabelEncoder()\\ny = encoder.fit_transform(y)\\nprint(y)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y[10])\n",
        "print(y[30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTnJyUbpBnXk",
        "outputId": "0322b265-efd6-4788-af55-f24a2c425615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sad\n",
            "happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJYWG3KGBvxm",
        "outputId": "3ea3f6a3-e5f6-46fe-a1a0-ccea5a617739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 2 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y[10])\n",
        "print(y[30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr4HwIN4Bx2k",
        "outputId": "0cb310fa-02d7-4200-d120-ea7395cbfea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = split_scale(X,y)\n",
        "\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "X_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN8UjF3jD-TN",
        "outputId": "ec4c23ca-38c7-46fb-e9c5-3334b70a0abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1974, 193, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = reconstructed_model.predict(X_test)"
      ],
      "metadata": {
        "id": "SMtYK2xvB6-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEx-N3VpELVK",
        "outputId": "5b60148b-60d0-4c67-a99b-997de8ca8c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.0000000e+00, 1.7562174e-14, 4.9074312e-32, 5.2507967e-35],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}